# Experimento 1: Benchmarks de Tempo - Corre√ß√£o em Andamento

**Data**: 2025-12-08
**Status**: üü° **EM PROGRESSO**

---

## ‚úÖ O que foi feito at√© agora

### 1. An√°lise do Problema ‚úÖ

**Problema identificado**:
- Baseline usa `time.sleep()` para SIMULAR delays
- 17 ocorr√™ncias de simula√ß√µes em `benchmark_fragmented.py`
- DEMO_SPEEDUP_FACTOR = 60 converte minutos ‚Üí segundos
- Compara√ß√£o inv√°lida: DeepBridge real vs baseline simulado

**Evid√™ncias**:
```python
# benchmark_fragmented.py:30-32
DEMO_SPEEDUP_FACTOR = 60  # Minutos ‚Üí segundos!

# benchmark_fragmented.py:145-154
time.sleep((5 * 60) / DEMO_SPEEDUP_FACTOR)   # Simula 5 min
time.sleep((15 * 60) / DEMO_SPEEDUP_FACTOR)  # Simula 15 min
time.sleep((3 * 60) / DEMO_SPEEDUP_FACTOR)   # Simula 3 min
time.sleep((7 * 60) / DEMO_SPEEDUP_FACTOR)   # Simula 7 min
```

### 2. Implementa√ß√£o do Baseline REAL ‚úÖ

**Arquivo criado**: `benchmark_fragmented_REAL.py`

**Ferramentas REAIS implementadas**:

#### a) Fairness (AIF360 + Fairlearn) ‚úÖ
```python
# Convers√£o REAL para AIF360
aif_dataset = BinaryLabelDataset(df=df_encoded, ...)

# M√©tricas REAIS com AIF360
metric = BinaryLabelDatasetMetric(aif_dataset, ...)
di = metric.disparate_impact()  # CALCULADO, n√£o simulado

# M√©tricas REAIS com Fairlearn
dpd = demographic_parity_difference(y_test, y_pred, sensitive_features=...)
eod = equalized_odds_difference(y_test, y_pred, sensitive_features=...)
```

#### b) Robustness (sklearn) ‚úÖ
```python
# Perturba√ß√µes gaussianas REAIS
noise = np.random.normal(0, noise_level, X_numeric.shape)
X_perturbed = X_numeric + noise

# Testes adversariais REAIS
y_pred_perturbed = model.predict(X_perturbed)
acc_perturbed = accuracy_score(y_test, y_pred_perturbed)
```

#### c) Uncertainty (calibra√ß√£o real) ‚úÖ
```python
# Obter probabilidades REAIS
y_proba = model.predict_proba(X_test)[:, 1]

# Calibra√ß√£o REAL
fraction_of_positives, mean_predicted_value = calibration_curve(
    y_test, y_proba, n_bins=10
)
ece = np.abs(fraction_of_positives - mean_predicted_value).mean()
```

#### d) Resilience (drift real) ‚úÖ
```python
# Wasserstein distance REAL
wd = wasserstein_distance(
    X_train_numeric[col].values,
    X_test_numeric[col].values
)
```

#### e) Report Generation (matplotlib real) ‚úÖ
```python
# Visualiza√ß√µes REAIS com matplotlib
fig, axes = plt.subplots(2, 2, figsize=(12, 10))
# ... criar plots ...
plt.savefig(fig_path, dpi=300)

# Documento REAL em texto
with open(report_path, 'w') as f:
    f.write("VALIDATION REPORT...")
```

### 3. Corre√ß√µes de Bugs ‚úÖ

**Bugs corrigidos**:
1. ‚ùå `ExperimentLogger.setup_logger()` n√£o existe
   - ‚úÖ Substitu√≠do por `logging.basicConfig()`

2. ‚ùå Config file: `experiment_config.yaml` n√£o existe
   - ‚úÖ Corrigido para `config.yaml`

3. ‚ùå Config key: `config['execution']['seed']` n√£o existe
   - ‚úÖ Corrigido para `config['general']['seed']`

4. ‚ùå `save_results(results, path, self.logger)` assinatura incorreta
   - ‚úÖ Corrigido para `save_results(results, path, formats=['json'])`

### 4. Execu√ß√£o em Andamento üü°

**Status atual**:
- ‚úÖ DeepBridge J√Å executado (tempos REAIS dispon√≠veis)
- üü° Baseline REAL em execu√ß√£o (pode levar 5-15 minutos)

**DeepBridge - Tempos REAIS** (de `deepbridge_times_REAL.json`):
```
Robustness:  13.6s (¬±0.7s)
Uncertainty:  5.8s (¬±0.3s)
Resilience:   3.9s (¬±0.2s)
Report:       0.08s (¬±0.05s)
Total:       23.4s (¬±1.2s)
```

**Nota**: Fairness est√° vazio (no_data) - precisa investigar

---

## ‚è≥ Pr√≥ximos Passos

### Imediato (Aguardando)

1. **Aguardar conclus√£o do baseline REAL** (~5-15 min)
   - Processo rodando: `benchmark_fragmented_REAL.py`
   - Output esperado: `fragmented_benchmark_REAL.json`

2. **Verificar resultados**
   - Arquivo: `results/fragmented_benchmark_REAL.json`
   - Validar tempos medidos (n√£o simulados)

### Curto Prazo (1-2 horas)

3. **Comparar DeepBridge vs Baseline REAL**
   - Carregar ambos os JSONs
   - Calcular speedup REAL
   - Verificar se h√° diferen√ßa significativa

4. **Investigar problema do Fairness**
   - Por que DeepBridge fairness est√° vazio (no_data)?
   - Executar teste de fairness isolado
   - Corrigir e re-executar

5. **Gerar an√°lise estat√≠stica**
   - Teste t pareado
   - Intervalos de confian√ßa
   - Gr√°ficos comparativos

6. **Atualizar documenta√ß√£o**
   - Marcar experimento 1 como CORRIGIDO
   - Adicionar disclaimers sobre vers√£o antiga
   - Documentar metodologia REAL

### M√©dio Prazo (1-2 dias)

7. **Executar m√∫ltiplos runs**
   - Rodar baseline REAL 10 vezes (como DeepBridge)
   - Calcular m√©dia e desvio padr√£o
   - An√°lise de variabilidade

8. **Gerar figuras**
   - Compara√ß√£o de tempos
   - Breakdown por teste
   - Speedup por componente

9. **Escrever relat√≥rio final**
   - Resultados corrigidos
   - Compara√ß√£o com vers√£o simulada
   - Adequa√ß√£o para publica√ß√£o

---

## üìä Expectativa de Resultados

### Cen√°rio Otimista

**DeepBridge**: ~23s (j√° medido)
**Baseline REAL**: ~60-120s (estimativa)
**Speedup**: 2.5-5√ó (vs 8.9√ó simulado)

**Adequa√ß√£o**: ‚úÖ Aceit√°vel para Tier 2
- Compara√ß√£o justa (ambos reais)
- Speedup modesto mas real
- Metodologia s√≥lida

### Cen√°rio Realista

**DeepBridge**: ~23s
**Baseline REAL**: ~30-60s
**Speedup**: 1.3-2.5√ó

**Adequa√ß√£o**: ‚ö†Ô∏è Borderline para Tier 2
- Speedup baixo
- Ainda v√°lido (ferramentas reais)
- Precisa enfatizar outras contribui√ß√µes

### Cen√°rio Pessimista

**DeepBridge**: ~23s
**Baseline REAL**: ~20-30s (similar ou mais r√°pido)
**Speedup**: <1.5√ó ou negativo

**Adequa√ß√£o**: ‚ùå Problem√°tico
- N√£o demonstra vantagem de performance
- Precisa focar em usabilidade, n√£o velocidade
- Reformular narrativa do paper

---

## üîß Comandos para Monitorar

### Verificar se processo ainda est√° rodando

```bash
ps aux | grep benchmark_fragmented_REAL
```

### Ver output em tempo real

```bash
tail -f /tmp/fragmented_real_output.log
```

### Verificar resultado

```bash
ls -lh results/fragmented_benchmark_REAL.json
cat results/fragmented_benchmark_REAL.json | jq '.times_minutes'
```

### Comparar com DeepBridge

```bash
cat results/deepbridge_times_REAL.json | jq '.total.mean_minutes'
cat results/fragmented_benchmark_REAL.json | jq '.times_minutes.total'
```

---

## üìù Arquivos Criados

### C√≥digo
- `scripts/benchmark_fragmented_REAL.py` ‚úÖ (645 linhas)

### Resultados (esperados)
- `results/fragmented_benchmark_REAL.json` ‚è≥ (aguardando)
- `results/fragmented_report_REAL.txt` ‚è≥ (aguardando)
- `results/fragmented_report_figures.png` ‚è≥ (aguardando)

### Logs
- `logs/benchmark_fragmented_real_*.log` ‚è≥ (em gera√ß√£o)
- `/tmp/fragmented_real_output.log` ‚è≥ (stdout redirecionado)

---

## ‚ö†Ô∏è Riscos e Limita√ß√µes

### Riscos T√©cnicos

1. **Tempo de execu√ß√£o muito longo**
   - Se baseline demorar > 15 min, pode ser impratic√°vel
   - Solu√ß√£o: Reduzir tamanho do dataset de teste

2. **Erros em runtime**
   - AIF360/Fairlearn podem falhar com certos dados
   - Solu√ß√£o: Try-except com fallback

3. **Resultados inesperados**
   - Baseline pode ser mais r√°pido que DeepBridge
   - Solu√ß√£o: Reformular claim (usabilidade vs performance)

### Riscos para Publica√ß√£o

1. **Speedup muito baixo**
   - Se < 2√ó, reviewers questionar√£o contribui√ß√£o
   - Mitiga√ß√£o: Enfatizar API unificada

2. **Dataset √∫nico**
   - Apenas Adult Income
   - Mitiga√ß√£o: Adicionar mais datasets (TODO)

3. **Ferramentas limitadas**
   - N√£o inclui todas as ferramentas citadas
   - Mitiga√ß√£o: Ser transparente sobre escopo

---

## üìà M√©tricas de Sucesso

### Para considerar CORRIGIDO

- [x] Baseline usa ferramentas REAIS (n√£o time.sleep)
- [x] C√≥digo executa sem erros
- [ ] Resultados dispon√≠veis em JSON
- [ ] Tempos medidos (n√£o estimados)
- [ ] Compara√ß√£o justa (mesma metodologia)

### Para considerar PUBLIC√ÅVEL

- [ ] Speedup > 1.5√ó (m√≠nimo)
- [ ] An√°lise estat√≠stica completa
- [ ] M√∫ltiplos runs (n=10)
- [ ] Intervalos de confian√ßa
- [ ] Documenta√ß√£o atualizada

### Para Tier 1

- [ ] Speedup > 3√ó
- [ ] M√∫ltiplos datasets (‚â•3)
- [ ] Compara√ß√£o com m√∫ltiplas ferramentas
- [ ] Ablation study
- [ ] Valida√ß√£o externa

---

## üë• Recomenda√ß√µes para a Equipe

### Decis√£o Estrat√©gica Necess√°ria

**Pergunta**: Se baseline REAL for similar ou mais r√°pido que DeepBridge, qual narrativa usar?

**Op√ß√µes**:

1. **Enfatizar Usabilidade**
   - API unificada vs fragmentada
   - Menos c√≥digo para usar
   - Melhor DX (Developer Experience)

2. **Enfatizar Funcionalidade**
   - M√∫ltiplos testes em uma call
   - Auto-reporting
   - Integra√ß√£o nativa

3. **Enfatizar Qualidade**
   - Detec√ß√£o mais completa
   - Menos falsos positivos
   - Melhor coverage

4. **Reformular Experimento**
   - Adicionar overhead de integra√ß√£o ao baseline
   - Medir tempo total de workflow (n√£o s√≥ execu√ß√£o)
   - Incluir tempo de desenvolvimento

### A√ß√£o Recomendada

**AGUARDAR** conclus√£o do baseline REAL antes de decidir pr√≥xima estrat√©gia.

Se speedup < 1.5√ó:
- Reunir equipe
- Revisar claims do paper
- Reformular narrativa
- Considerar adicionar experimentos adicionais

Se speedup > 2√ó:
- Continuar com plano atual
- Adicionar mais datasets
- Finalizar an√°lise

---

**Assinatura**: Corre√ß√£o em andamento
**Data**: 2025-12-08
**Vers√£o**: 1.0 (Em progresso)
**Status**: üü° Aguardando conclus√£o do baseline REAL
