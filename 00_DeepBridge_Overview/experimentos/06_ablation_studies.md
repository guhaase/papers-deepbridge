# Experimento 6: Ablation Studies

## Objetivo

Comprovar a decomposi√ß√£o dos ganhos de tempo (Se√ß√£o 6.3) atrav√©s de estudos de abla√ß√£o sistem√°ticos:

- **API unificada**: 50% do ganho
- **Paraleliza√ß√£o**: 30% do ganho
- **Caching**: 10% do ganho
- **Automa√ß√£o de relat√≥rios**: 10% do ganho

## Afirma√ß√µes a Comprovar

### Decomposi√ß√£o dos Ganhos (Se√ß√£o 6.3)

| Componente | Contribui√ß√£o | Ganho Absoluto | Status |
|------------|--------------|----------------|--------|
| API Unificada | 50% | ~66 min | ‚è≥ Pendente |
| Paraleliza√ß√£o | 30% | ~40 min | ‚è≥ Pendente |
| Caching | 10% | ~13 min | ‚è≥ Pendente |
| Automa√ß√£o Relat√≥rios | 10% | ~13 min | ‚è≥ Pendente |
| **Total** | **100%** | **~133 min** | - |

**Ganho Total**: 150 min (fragmentado) - 17 min (DeepBridge) = **133 min**

## Metodologia

### 1. Configura√ß√µes de Abla√ß√£o

Criar vers√µes do DeepBridge com componentes desabilitados:

```python
# Configura√ß√£o 0: DeepBridge COMPLETO (baseline)
config_full = {
    'unified_api': True,
    'parallel_execution': True,
    'caching': True,
    'automated_reporting': True
}
# Tempo esperado: 17 min

# Configura√ß√£o 1: SEM API unificada
config_no_api = {
    'unified_api': False,  # Usar convers√µes manuais
    'parallel_execution': True,
    'caching': True,
    'automated_reporting': True
}
# Tempo esperado: 17 + 66 = 83 min

# Configura√ß√£o 2: SEM paraleliza√ß√£o
config_no_parallel = {
    'unified_api': True,
    'parallel_execution': False,  # Execu√ß√£o sequencial
    'caching': True,
    'automated_reporting': True
}
# Tempo esperado: 17 + 40 = 57 min

# Configura√ß√£o 3: SEM caching
config_no_cache = {
    'unified_api': True,
    'parallel_execution': True,
    'caching': False,  # Recomputar predi√ß√µes
    'automated_reporting': True
}
# Tempo esperado: 17 + 13 = 30 min

# Configura√ß√£o 4: SEM automa√ß√£o de relat√≥rios
config_no_auto_report = {
    'unified_api': True,
    'parallel_execution': True,
    'caching': True,
    'automated_reporting': False  # Gera√ß√£o manual
}
# Tempo esperado: 17 + 13 = 30 min

# Configura√ß√£o 5: NADA (fragmentado completo)
config_none = {
    'unified_api': False,
    'parallel_execution': False,
    'caching': False,
    'automated_reporting': False
}
# Tempo esperado: ~150 min
```

### 2. Medi√ß√£o de Tempo por Configura√ß√£o

Para cada configura√ß√£o, executar valida√ß√£o completa:

```python
import time
from deepbridge import DBDataset, Experiment

def measure_ablation_time(config, dataset, num_runs=10):
    times = []

    for run in range(num_runs):
        start = time.time()

        if config['unified_api']:
            # DeepBridge API unificada
            exp = Experiment(dataset, tests='all', config=config)
            results = exp.run_tests()
        else:
            # Workflow fragmentado (convers√µes manuais)
            results = run_fragmented_workflow(dataset)

        if config['automated_reporting']:
            exp.save_pdf('report.pdf')
        else:
            generate_manual_report(results)

        elapsed = time.time() - start
        times.append(elapsed)

    return {
        'mean': np.mean(times),
        'std': np.std(times),
        'min': np.min(times),
        'max': np.max(times)
    }
```

### 3. Dataset de Teste

Usar dataset padr√£o para todas configura√ß√µes:

**Adult Income Dataset**
- Amostras: 48.842
- Features: 14
- Protected attributes: gender, race, age

### 4. C√°lculo de Contribui√ß√µes

```python
# Baseline: DeepBridge completo
time_full = 17  # min

# Sem API unificada
time_no_api = measure_ablation_time(config_no_api)
contribution_api = time_no_api - time_full

# Sem paraleliza√ß√£o
time_no_parallel = measure_ablation_time(config_no_parallel)
contribution_parallel = time_no_parallel - time_full

# Sem caching
time_no_cache = measure_ablation_time(config_no_cache)
contribution_cache = time_no_cache - time_full

# Sem automa√ß√£o relat√≥rios
time_no_auto_report = measure_ablation_time(config_no_auto_report)
contribution_report = time_no_auto_report - time_full

# Total
total_gain = 150 - 17  # 133 min

# Percentuais
pct_api = (contribution_api / total_gain) * 100
pct_parallel = (contribution_parallel / total_gain) * 100
pct_cache = (contribution_cache / total_gain) * 100
pct_report = (contribution_report / total_gain) * 100
```

## Abla√ß√£o 1: API Unificada

### Afirma√ß√£o
**50% do ganho** (~66 min de 133 min)

### Implementa√ß√£o

**Com API Unificada** (DeepBridge):
```python
# Criar uma vez, usar em qualquer lugar
dataset = DBDataset(df, target='approved', model=model)

# Reutilizar em todas valida√ß√µes
fairness_results = run_fairness(dataset)  # ~5 min
robustness_results = run_robustness(dataset)  # ~7 min
uncertainty_results = run_uncertainty(dataset)  # ~3 min
```

**Sem API Unificada** (workflow fragmentado):
```python
# Convers√£o para AIF360
aif_dataset = BinaryLabelDataset(df=df, ...)  # 5 min
fairness_results = run_fairness_aif360(aif_dataset)  # 30 min

# Convers√£o para Alibi Detect
alibi_data = df.values.astype(np.float32)  # 3 min
robustness_results = run_robustness_alibi(alibi_data)  # 25 min

# Convers√£o para UQ360
uq_data = Dataset(df, ...)  # 4 min
uncertainty_results = run_uncertainty_uq360(uq_data)  # 20 min

# Total convers√µes: ~12 min
# Total execu√ß√£o: ~75 min
# Total: ~87 min vs. 15 min (DeepBridge sem relat√≥rio)
# Ganho: 87 - 15 = 72 min ‚âà 66 min (expectativa)
```

### Resultados Esperados

| M√©trica | Com API | Sem API | Ganho |
|---------|---------|---------|-------|
| Tempo (min) | 17 | 83 | 66 min |
| % do Ganho Total | - | - | 50% |

## Abla√ß√£o 2: Paraleliza√ß√£o

### Afirma√ß√£o
**30% do ganho** (~40 min de 133 min)

### Implementa√ß√£o

**Com Paraleliza√ß√£o**:
```python
from concurrent.futures import ThreadPoolExecutor

# Executar testes em paralelo
with ThreadPoolExecutor(max_workers=4) as executor:
    futures = {
        'fairness': executor.submit(run_fairness, dataset),
        'robustness': executor.submit(run_robustness, dataset),
        'uncertainty': executor.submit(run_uncertainty, dataset),
        'resilience': executor.submit(run_resilience, dataset)
    }

    results = {name: future.result() for name, future in futures.items()}

# Tempo total: max(5, 7, 3, 2) ‚âà 7 min (overlap)
```

**Sem Paraleliza√ß√£o** (sequencial):
```python
# Executar testes sequencialmente
results_fairness = run_fairness(dataset)  # 5 min
results_robustness = run_robustness(dataset)  # 7 min
results_uncertainty = run_uncertainty(dataset)  # 3 min
results_resilience = run_resilience(dataset)  # 2 min

# Tempo total: 5 + 7 + 3 + 2 = 17 min
```

**Ganho**: 17 - 7 = 10 min por execu√ß√£o
**Escalado**: Com todas otimiza√ß√µes, ganho ‚âà 40 min

### Medi√ß√£o de Speedup

```python
import time

# Medir tempo sequencial
start = time.time()
run_tests_sequential(dataset)
time_sequential = time.time() - start

# Medir tempo paralelo
start = time.time()
run_tests_parallel(dataset, n_workers=4)
time_parallel = time.time() - start

# Speedup
speedup = time_sequential / time_parallel
# Esperado: ~2-3√ó (n√£o linear devido a I/O, sincroniza√ß√£o)
```

### Resultados Esperados

| M√©trica | Paralelo | Sequencial | Ganho |
|---------|----------|------------|-------|
| Tempo (min) | 17 | 57 | 40 min |
| % do Ganho Total | - | - | 30% |
| Speedup | 3.4√ó | 1√ó | - |

## Abla√ß√£o 3: Caching

### Afirma√ß√£o
**10% do ganho** (~13 min de 133 min)

### Implementa√ß√£o

**Com Caching**:
```python
class DBDataset:
    def __init__(self, data, model, ...):
        self._predictions_cache = None

    @property
    def predictions(self):
        if self._predictions_cache is None:
            self._predictions_cache = self.model.predict(self.data)
        return self._predictions_cache

    @property
    def prediction_probabilities(self):
        if self._proba_cache is None:
            self._proba_cache = self.model.predict_proba(self.data)
        return self._proba_cache

# Predi√ß√µes computadas UMA VEZ e reutilizadas
dataset.predictions  # Computa e cacheia
dataset.predictions  # Retorna do cache (instant√¢neo)
```

**Sem Caching**:
```python
# Recomputar predi√ß√µes a cada teste
fairness_preds = model.predict(data)  # 2 min
robustness_preds = model.predict(data)  # 2 min
uncertainty_preds = model.predict_proba(data)  # 2 min
resilience_preds = model.predict(data)  # 2 min

# Tempo total desperdi√ßado: ~8 min
# Com overhead adicional: ~13 min
```

### Medi√ß√£o

```python
import time

# Com caching
start = time.time()
dataset = DBDataset(data, model, caching=True)
for _ in range(10):
    preds = dataset.predictions  # Cache hit ap√≥s primeira
time_with_cache = time.time() - start

# Sem caching
start = time.time()
dataset = DBDataset(data, model, caching=False)
for _ in range(10):
    preds = model.predict(data)  # Recomputa sempre
time_without_cache = time.time() - start

# Ganho
gain = time_without_cache - time_with_cache
```

### Resultados Esperados

| M√©trica | Com Cache | Sem Cache | Ganho |
|---------|-----------|-----------|-------|
| Tempo (min) | 17 | 30 | 13 min |
| % do Ganho Total | - | - | 10% |

## Abla√ß√£o 4: Automa√ß√£o de Relat√≥rios

### Afirma√ß√£o
**10% do ganho** (~13 min de 133 min)

### Implementa√ß√£o

**Com Automa√ß√£o**:
```python
# Gera√ß√£o autom√°tica de relat√≥rio PDF
exp = Experiment(dataset, tests='all')
results = exp.run_tests()
exp.save_pdf('report.pdf')  # <1 min

# Template-driven, visualiza√ß√µes autom√°ticas
```

**Sem Automa√ß√£o** (manual):
```python
from fpdf import FPDF
import matplotlib.pyplot as plt

# Criar PDF manualmente
pdf = FPDF()
pdf.add_page()

# Para CADA m√©trica:
# 1. Criar visualiza√ß√£o
fig, ax = plt.subplots()
ax.plot(...)  # 2 min por gr√°fico
plt.savefig('temp_fig.png')

# 2. Adicionar ao PDF
pdf.image('temp_fig.png')  # 0.5 min

# 3. Adicionar texto explicativo
pdf.cell(0, 10, 'An√°lise...', ln=True)  # 1 min

# Para 15 m√©tricas + 10 visualiza√ß√µes + formata√ß√£o:
# ~60 minutos total

pdf.output('report.pdf')
```

### Medi√ß√£o

```python
import time

# Automa√ß√£o
start = time.time()
exp.save_pdf('report_auto.pdf')
time_auto = time.time() - start

# Manual
start = time.time()
generate_manual_report(results)
time_manual = time.time() - start

# Ganho
gain = time_manual - time_auto
```

### Resultados Esperados

| M√©trica | Automa√ß√£o | Manual | Ganho |
|---------|-----------|--------|-------|
| Tempo (min) | <1 | 60 | ~60 min |
| % do Ganho (relat√≥rio) | - | - | 98% |
| % do Ganho Total | - | - | ~10% |

## An√°lise Combinada

### Todas Abla√ß√µes

```python
configs = {
    'Full': config_full,
    'No API': config_no_api,
    'No Parallel': config_no_parallel,
    'No Cache': config_no_cache,
    'No AutoReport': config_no_auto_report,
    'None (Fragmented)': config_none
}

results = {}
for name, config in configs.items():
    results[name] = measure_ablation_time(config, dataset, num_runs=10)
```

### Resultados Esperados

| Configura√ß√£o | Tempo (min) | Ganho vs. Full | % do Ganho Total |
|--------------|-------------|----------------|------------------|
| Full (DeepBridge) | 17 | 0 | - |
| No API | 83 | +66 | 50% |
| No Parallel | 57 | +40 | 30% |
| No Cache | 30 | +13 | 10% |
| No AutoReport | 30 | +13 | 10% |
| None (Fragmentado) | 150 | +133 | 100% |

### Verifica√ß√£o de Aditividade

Idealmente, contribui√ß√µes devem ser aproximadamente aditivas:

```python
# Configura√ß√£o com NENHUM componente
time_none = 150

# Somar contribui√ß√µes
estimated_time_none = (
    time_full +
    contribution_api +
    contribution_parallel +
    contribution_cache +
    contribution_report
)

# Verificar
difference = abs(time_none - estimated_time_none)
# Esperado: difference < 10 min (efeitos de intera√ß√£o)
```

## An√°lise Estat√≠stica

### ANOVA

Testar se diferen√ßas entre configura√ß√µes s√£o significativas:

```python
from scipy import stats

# Tempos para cada configura√ß√£o (10 runs cada)
times_full = [17.2, 16.8, 17.5, ...]
times_no_api = [82.5, 83.1, 84.2, ...]
times_no_parallel = [56.8, 57.3, 58.1, ...]
# etc.

# One-way ANOVA
f_stat, p_value = stats.f_oneway(
    times_full,
    times_no_api,
    times_no_parallel,
    times_no_cache,
    times_no_auto_report,
    times_none
)

# Esperado: p < 0.001 (diferen√ßas altamente significativas)
```

### Post-hoc (Tukey HSD)

```python
from statsmodels.stats.multicomp import pairwise_tukeyhsd

# Compara√ß√µes pareadas
tukey = pairwise_tukeyhsd(all_times, all_groups)
print(tukey)

# Esperado: todas compara√ß√µes significativas (p < 0.05)
```

## Visualiza√ß√µes

### Waterfall Chart

Mostrar contribui√ß√£o acumulada de cada componente:

```python
import matplotlib.pyplot as plt

components = ['Fragmentado', 'API', 'Paralelo', 'Cache', 'AutoReport', 'Full']
times = [150, 83, 57, 30, 30, 17]
contributions = [0, -67, -26, -27, 0, -13]

# Waterfall chart
# ...
```

### Stacked Bar Chart

```python
contributions = {
    'API Unificada': 66,
    'Paraleliza√ß√£o': 40,
    'Caching': 13,
    'Automa√ß√£o Relat√≥rios': 13
}

# Stacked bar
```

## Scripts

### Principal
`/experimentos/scripts/06_ablation_main.py`

### Por Componente
`/experimentos/scripts/06_ablation_api.py`
`/experimentos/scripts/06_ablation_parallel.py`
`/experimentos/scripts/06_ablation_cache.py`
`/experimentos/scripts/06_ablation_report.py`

### An√°lise
`/experimentos/notebooks/06_ablation_analysis.ipynb`

## Outputs

### Dados
- `results/06_ablation_all_configs.csv`
- `results/06_ablation_contributions.json`
- `results/06_ablation_anova.json`

### Figuras
- `figures/ablation_waterfall.pdf`
- `figures/ablation_stacked_bar.pdf`
- `figures/ablation_boxplot.pdf`
- `figures/ablation_contributions_pie.pdf`

### Tabelas
- `tables/ablation_results.tex`

## Checklist

- [ ] Implementar configura√ß√£o Full
- [ ] Implementar configura√ß√£o No API
- [ ] Implementar configura√ß√£o No Parallel
- [ ] Implementar configura√ß√£o No Cache
- [ ] Implementar configura√ß√£o No AutoReport
- [ ] Implementar configura√ß√£o None (Fragmentado)
- [ ] Executar 10 runs para cada configura√ß√£o
- [ ] Calcular contribui√ß√µes absolutas
- [ ] Calcular contribui√ß√µes percentuais
- [ ] Verificar aditividade
- [ ] Executar ANOVA
- [ ] Executar Tukey HSD
- [ ] Gerar waterfall chart
- [ ] Gerar stacked bar chart
- [ ] Formatar tabela LaTeX

## Prioridade

üü¢ **BAIXA** - √ötil para entender componentes, mas n√£o cr√≠tico

## Tempo Estimado

**1-2 semanas**:
- Semana 1: Implementa√ß√£o das configura√ß√µes e execu√ß√£o
- Semana 2: An√°lise estat√≠stica e visualiza√ß√µes
