# GPU Requirements - Experimentos DeepBridge

**Data:** 2025-12-06

---

## ğŸ“Š Resumo Executivo

**Resposta RÃ¡pida**: Apenas **1 de 6 experimentos** requer GPU (opcional):

| Experimento | GPU NecessÃ¡ria? | Tipo de ComputaÃ§Ã£o | Pode Rodar em CPU? |
|-------------|-----------------|--------------------|--------------------|
| 01 - Benchmarks | âŒ NÃƒO | Dados tabulares (XGBoost, Adult Income) | âœ… Sim |
| 02 - Casos de Uso | âŒ NÃƒO | Dados tabulares (6 domÃ­nios) | âœ… Sim |
| 03 - Usabilidade | âŒ NÃƒO | AnÃ¡lise estatÃ­stica (mock data) | âœ… Sim |
| **04 - HPM-KD** | âš ï¸ **OPCIONAL** | **PyTorch MLP** (student) | âš ï¸ Sim, mas lento |
| 05 - Conformidade | âŒ NÃƒO | Compliance tests | âœ… Sim |
| 06 - Ablation Studies | âŒ NÃƒO | AnÃ¡lise de componentes | âœ… Sim |

**ConclusÃ£o**: VocÃª pode executar **TODOS os experimentos em CPU**. GPU sÃ³ acelera o Experimento 04.

---

## ğŸ” AnÃ¡lise Detalhada por Experimento

### âœ… Experimento 01: Benchmarks de Tempo

**GPU NecessÃ¡ria?** âŒ **NÃƒO**

**Por quÃª?**
- Dataset: Adult Income (dados tabulares)
- Modelos: XGBoost, LightGBM (tree-based, otimizados para CPU)
- DeepBridge: Opera sobre modelos jÃ¡ treinados
- Workflow fragmentado: Usa bibliotecas tradicionais (AIF360, Fairlearn)

**Hardware Recomendado:**
- CPU: 4+ cores
- RAM: 8GB
- Tempo: ~30 minutos (10 runs)

**Status**: âœ… JÃ¡ executado com sucesso em CPU

---

### âœ… Experimento 02: Estudos de Caso

**GPU NecessÃ¡ria?** âŒ **NÃƒO**

**Por quÃª?**
- 6 domÃ­nios: CrÃ©dito, ContrataÃ§Ã£o, SaÃºde, Hipoteca, Seguros, Fraude
- Todos usam dados tabulares
- Modelos: XGBoost, Random Forest, LightGBM, Gradient Boosting
- 1.4M amostras processadas (mas em tree models, nÃ£o neural networks)

**Hardware Recomendado:**
- CPU: 8+ cores (para paralelizar 6 casos)
- RAM: 16GB
- Tempo: ~15 minutos (com dados sintÃ©ticos)

**Status**: âœ… JÃ¡ executado com sucesso em CPU

---

### âœ… Experimento 03: Usabilidade

**GPU NecessÃ¡ria?** âŒ **NÃƒO**

**Por quÃª?**
- AnÃ¡lise estatÃ­stica pura
- CÃ¡lculo de SUS, NASA TLX scores
- Testes de normalidade, correlaÃ§Ãµes
- GeraÃ§Ã£o de visualizaÃ§Ãµes (matplotlib)
- Nenhum treinamento de modelo

**Hardware Recomendado:**
- CPU: 2+ cores
- RAM: 4GB
- Tempo: ~3 minutos

**Status**: âœ… JÃ¡ executado com sucesso em CPU

---

### âš ï¸ **Experimento 04: HPM-KD** (ÃšNICO QUE USA DEEP LEARNING)

**GPU NecessÃ¡ria?** âš ï¸ **OPCIONAL** (recomendada para versÃ£o real)

**Por quÃª?**

#### Teachers (NÃƒO precisam de GPU):
- XGBoost (200 estimators)
- LightGBM (200 estimators)
- CatBoost (200 iterations)
- **Total**: ~2.4GB
- **Treinamento**: CPU suficiente (tree-based models)

#### **Student (PODE se beneficiar de GPU):**
- **MLP compacto PyTorch** (64, 32 hidden layers)
- **Framework**: PyTorch
- **Total**: ~230MB
- **Treinamento**: Knowledge Distillation

**AnÃ¡lise:**

| CenÃ¡rio | Hardware | Tempo Estimado (20 datasets) | ViÃ¡vel? |
|---------|----------|------------------------------|---------|
| **CPU Only** | 8+ cores, 16GB RAM | ~5-7 dias | âš ï¸ Lento mas viÃ¡vel |
| **GPU (RTX 3080)** | CUDA, 32GB RAM | ~3-4 semanas | âœ… Recomendado |

**DependÃªncias PyTorch:**
```python
torch>=2.0.0
torchvision>=0.15.0
```

**ObservaÃ§Ãµes:**
- MLP Ã© uma rede **pequena** (64, 32 neurons)
- Com CPU, treinar 1 student pode levar ~1-2 horas
- Com GPU, treinar 1 student leva ~5-10 minutos
- **Total de students**: 60 (20 datasets Ã— 3 mÃ©todos)

**RecomendaÃ§Ã£o:**
- **Mock/Demo**: CPU suficiente (poucos datasets, teste rÃ¡pido)
- **VersÃ£o Real (20 datasets)**: GPU altamente recomendada

**Status**: â³ Mock implementation (CPU viÃ¡vel)

---

### âœ… Experimento 05: Conformidade

**GPU NecessÃ¡ria?** âŒ **NÃƒO**

**Por quÃª?**
- Testes de compliance com regulaÃ§Ãµes (GDPR, EEOC, ECOA, etc.)
- ValidaÃ§Ã£o de mÃ©tricas de fairness
- AnÃ¡lise de documentaÃ§Ã£o e relatÃ³rios
- Nenhum treinamento de modelo pesado

**Hardware Recomendado:**
- CPU: 4+ cores
- RAM: 8GB

**Status**: ğŸ“‹ Planejado (nÃ£o requer GPU)

---

### âœ… Experimento 06: Ablation Studies

**GPU NecessÃ¡ria?** âŒ **NÃƒO**

**Por quÃª?**
- AnÃ¡lise de componentes do DeepBridge
- RemoÃ§Ã£o incremental de features
- MediÃ§Ã£o de impacto na performance
- Usa modelos jÃ¡ treinados (anÃ¡lise, nÃ£o treinamento)

**Hardware Recomendado:**
- CPU: 4+ cores
- RAM: 8GB

**Status**: ğŸ“‹ Planejado (nÃ£o requer GPU)

---

## ğŸ¯ RecomendaÃ§Ãµes PrÃ¡ticas

### Para VocÃª (Agora)

**Sua SituaÃ§Ã£o**: Tem acesso a GPU (servidor RunPod/Kaggle)

**RecomendaÃ§Ã£o**:
1. âœ… **Experimentos 01, 02, 03, 05, 06**: Execute em **CPU local**
   - RÃ¡pidos, leves, nÃ£o justificam custo de GPU
   - Total: ~1 hora de execuÃ§Ã£o combinada

2. âš ï¸ **Experimento 04 (HPM-KD)**:
   - **Mock/Demo**: CPU local (teste rÃ¡pido)
   - **VersÃ£o Real (20 datasets)**: GPU no RunPod/Kaggle
   - Economiza ~5 dias de CPU vs ~3-4 semanas em GPU

### ComparaÃ§Ã£o de Custo-BenefÃ­cio

#### CPU Local (Todos os Experimentos):
```
Exp 01:  ~30 min   âœ… ViÃ¡vel
Exp 02:  ~15 min   âœ… ViÃ¡vel
Exp 03:  ~3 min    âœ… ViÃ¡vel
Exp 04:  ~5-7 dias âš ï¸ Lento (versÃ£o real)
Exp 05:  ~20 min   âœ… ViÃ¡vel
Exp 06:  ~30 min   âœ… ViÃ¡vel
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TOTAL:   ~1.5h + 5-7 dias (Exp04 real)
```

#### GPU RunPod (Apenas Exp 04):
```
Exp 04 (GPU RTX 3080):  ~3-4 semanas
Custo estimado:         ~$50-100 USD
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Speedup vs CPU:         ~10-20Ã— mais rÃ¡pido
```

---

## ğŸ“‹ Checklist de DecisÃ£o

### Quando usar CPU?

- [x] VocÃª quer testar/validar a infraestrutura
- [x] VocÃª estÃ¡ trabalhando com mock/demo data
- [x] Experimentos 01, 02, 03, 05, 06
- [x] Experimento 04 com poucos datasets (â‰¤3)
- [x] Budget limitado

### Quando usar GPU?

- [ ] Experimento 04 com **20 datasets reais**
- [ ] VocÃª quer resultados em **semanas** ao invÃ©s de **meses**
- [ ] Treinamento de mÃºltiplos students (60 modelos)
- [ ] Budget disponÃ­vel (~$50-100 para RunPod)

---

## ğŸ’¡ Dicas de OtimizaÃ§Ã£o

### Se Usar CPU para Experimento 04:

1. **Paralelizar por Dataset** (nÃ£o por mÃ©todo):
   ```python
   # Processar datasets em paralelo (8 cores)
   from joblib import Parallel, delayed
   results = Parallel(n_jobs=8)(
       delayed(train_student)(dataset) for dataset in datasets
   )
   ```

2. **Reduzir Epochs**:
   ```python
   # Em vez de 200 epochs, usar 50-100
   epochs = 50  # Para teste
   ```

3. **ComeÃ§ar com Subset**:
   ```python
   # Testar com 3 datasets primeiro
   datasets = ['Adult', 'Bank', 'Credit']  # Ao invÃ©s de 20
   ```

### Se Usar GPU para Experimento 04:

1. **Batch Size Maior**:
   ```python
   batch_size = 512  # Aproveitar VRAM
   ```

2. **Mixed Precision Training**:
   ```python
   from torch.cuda.amp import autocast, GradScaler
   scaler = GradScaler()
   ```

3. **DataLoader com pin_memory**:
   ```python
   DataLoader(..., pin_memory=True, num_workers=4)
   ```

---

## ğŸ“Š Tabela Resumo Final

| Experimento | GPU? | Justificativa | Tempo CPU | Tempo GPU | Prioridade GPU |
|-------------|------|---------------|-----------|-----------|----------------|
| **01 - Benchmarks** | âŒ | Tree models | ~30 min | - | Nenhuma |
| **02 - Casos de Uso** | âŒ | Tree models | ~15 min | - | Nenhuma |
| **03 - Usabilidade** | âŒ | EstatÃ­stica | ~3 min | - | Nenhuma |
| **04 - HPM-KD** | âš ï¸ | PyTorch MLP | ~5-7 dias* | ~3-4 sem | **ALTA*** |
| **05 - Conformidade** | âŒ | AnÃ¡lise | ~20 min | - | Nenhuma |
| **06 - Ablation** | âŒ | AnÃ¡lise | ~30 min | - | Nenhuma |

\* Para versÃ£o real com 20 datasets

---

## ğŸš€ PrÃ³ximos Passos Recomendados

### Curto Prazo (Esta Semana):

1. âœ… Executar **Exp 01, 02, 03** em CPU local
   - JÃ¡ estÃ£o prontos e documentados
   - Total: ~1 hora

2. âœ… Testar **Exp 04 (mock)** em CPU local
   - 1-3 datasets apenas
   - Validar infraestrutura

### MÃ©dio Prazo (PrÃ³ximas 2-3 Semanas):

3. ğŸš€ Executar **Exp 04 (real)** em GPU RunPod/Kaggle
   - 20 datasets completos
   - Investimento justificado (~$50-100)

4. âœ… Executar **Exp 05, 06** em CPU local
   - ApÃ³s ter resultados do Exp 04

---

## âœ… ConclusÃ£o

**Resposta Direta**: Apenas o **Experimento 04 (HPM-KD)** usa PyTorch e pode se beneficiar de GPU, mas **TODOS podem rodar em CPU**.

**RecomendaÃ§Ã£o PrÃ¡tica**:
- Execute **5 de 6 experimentos em CPU** (rÃ¡pidos, ~1-2 horas total)
- Reserve **GPU apenas para Exp 04 versÃ£o real** (quando necessÃ¡rio)
- Para testes/demos, **CPU Ã© suficiente**

**Seu Caso (RunPod ativo agora)**:
- Se estÃ¡ rodando **Exp 1B do HPM-KD Framework** (CIFAR100): âœ… Ã“timo uso de GPU!
- Para **Exp 04 do DeepBridge Overview** (dados tabulares): âš ï¸ GPU nÃ£o Ã© crÃ­tico (MLP pequeno)

---

**Documento criado em**: 2025-12-06
**Status**: âœ… AnÃ¡lise Completa
**PrÃ³xima AÃ§Ã£o**: Decidir se mantÃ©m GPU para Exp 04 ou libera para outros experimentos
