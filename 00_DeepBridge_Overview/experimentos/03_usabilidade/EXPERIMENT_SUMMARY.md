# Experimento 03: Estudo de Usabilidade do DeepBridge

**Data de ExecuÃ§Ã£o:** 2025-12-06
**Autor:** DeepBridge Team
**Status:** âœ… COMPLETO (Mock Data)

---

## ğŸ“Š Resumo Executivo

Este experimento avalia a **usabilidade do framework DeepBridge** atravÃ©s de mÃ©tricas padronizadas (SUS e NASA TLX), taxa de sucesso em tarefas, tempo de conclusÃ£o e contagem de erros.

### Principais Resultados (Mock Data)

- **20 participantes** simulados (mock data)
- **SUS Score**: 52.75 Â± 8.58 (InterpretaÃ§Ã£o: "OK", Grade D)
- **NASA TLX**: 33.42 Â± 3.77 (InterpretaÃ§Ã£o: "Low Workload")
- **Taxa de Sucesso**: 95.0% (19/20 participantes)
- **Tempo MÃ©dio**: 15.42 Â± 2.59 minutos
- **Erros MÃ©dios**: 1.45 Â± 1.39 erros por participante

### Status dos Objetivos

| MÃ©trica | Target | Obtido | Status |
|---------|--------|--------|--------|
| SUS Score | â‰¥85 | 52.75 | âŒ NÃƒO ATINGIDO |
| NASA TLX | â‰¤30 | 33.42 | âŒ NÃƒO ATINGIDO |
| Taxa de Sucesso | â‰¥90% | 95.0% | âœ… ATINGIDO |
| Tempo MÃ©dio | â‰¤15 min | 15.42 min | âŒ NÃƒO ATINGIDO |
| Erros MÃ©dios | â‰¤2 | 1.45 | âœ… ATINGIDO |

**âš ï¸ IMPORTANTE**: Resultados baseados em dados simulados (mock). Valores reais dependerÃ£o de estudo com participantes reais.

---

## ğŸ¯ Objetivos

1. Avaliar usabilidade percebida atravÃ©s do **SUS (System Usability Scale)**
2. Medir carga cognitiva atravÃ©s do **NASA TLX (Task Load Index)**
3. Calcular **taxa de sucesso** em tarefas tÃ­picas
4. Mensurar **tempo de conclusÃ£o** de tarefas
5. Quantificar **erros cometidos** durante uso
6. Gerar tabela LaTeX e figuras para publicaÃ§Ã£o

---

## ğŸ‘¥ Perfil dos Participantes (Mock Data)

### Demografia

- **Total**: 20 participantes
- **ExperiÃªncia ML**:
  - JÃºnior: 6 (30%)
  - Pleno: 8 (40%)
  - SÃªnior: 6 (30%)
- **ExperiÃªncia Fairness**:
  - Baixa: 7 (35%)
  - MÃ©dia: 7 (35%)
  - Alta: 6 (30%)

### CaracterÃ­sticas

Dados simulados representando uma amostra tÃ­pica de:
- Cientistas de dados
- Engenheiros de ML
- Pesquisadores em fairness/robustez
- Profissionais de diferentes nÃ­veis de senioridade

---

## ğŸ“ˆ Resultados Detalhados

### 1. SUS Score (System Usability Scale)

**Score MÃ©dio**: 52.75 Â± 8.58

**DistribuiÃ§Ã£o**:
- MÃ­nimo: 35.0
- MÃ¡ximo: 70.0
- Mediana: 52.5
- Q1 (25%): 46.25
- Q3 (75%): 58.75

**InterpretaÃ§Ã£o**:
- **Grade**: D (OK)
- **Adjective Rating**: OK
- **Acceptability**: Marginal

**AnÃ¡lise EstatÃ­stica**:
- Teste t vs. mÃ©dia global (68): t=-7.9534, p<0.0001 (significativamente ABAIXO)
- Normalidade (Shapiro-Wilk): W=0.9656, p=0.6779 âœ… Normal

**âš ï¸ Alerta**: Score abaixo do esperado (target â‰¥85). Indica necessidade de melhorias na interface/UX.

### 2. NASA TLX (Task Load Index)

**Score MÃ©dio**: 33.42 Â± 3.77

**DimensÃµes**:
- Mental Demand: 30-45
- Physical Demand: 25-40
- Temporal Demand: 28-42
- Performance: 35-50
- Effort: 32-47
- Frustration: 20-35

**InterpretaÃ§Ã£o**:
- **Overall Rating**: Low Workload
- **Benchmarking**: Abaixo de 40 Ã© considerado baixo (positivo)

**AnÃ¡lise EstatÃ­stica**:
- Normalidade (Shapiro-Wilk): W=0.9713, p=0.7920 âœ… Normal
- ConsistÃªncia entre dimensÃµes: Alta (variaÃ§Ã£o controlada)

**âœ… Resultado Positivo**: Carga cognitiva dentro do aceitÃ¡vel, prÃ³ximo ao target.

### 3. Taxa de Sucesso

**Taxa Geral**: 95.0% (19/20 participantes completaram com sucesso)

**Por Tarefa**:
| Tarefa | Taxa de Sucesso |
|--------|-----------------|
| T1: Carregar dataset | 100% (20/20) |
| T2: Configurar atributos protegidos | 95% (19/20) |
| T3: Executar testes de fairness | 90% (18/20) |
| T4: Interpretar resultados | 95% (19/20) |
| T5: Gerar relatÃ³rio | 100% (20/20) |

**AnÃ¡lise**:
- Apenas 1 falha no total (Participante falhou em T2)
- Tarefas de configuraÃ§Ã£o ligeiramente mais desafiadoras
- Tarefas de carregamento e geraÃ§Ã£o de relatÃ³rio: 100% sucesso

**âœ… Target Atingido**: 95% â‰¥ 90%

### 4. Tempo de ConclusÃ£o

**Tempo MÃ©dio**: 15.42 Â± 2.59 minutos

**DistribuiÃ§Ã£o**:
- MÃ­nimo: 11.2 min
- MÃ¡ximo: 20.8 min
- Mediana: 15.3 min
- Q1 (25%): 13.5 min
- Q3 (75%): 17.1 min

**Por ExperiÃªncia ML**:
- JÃºnior: ~17-18 min
- Pleno: ~15-16 min
- SÃªnior: ~13-14 min

**AnÃ¡lise EstatÃ­stica**:
- Normalidade (Shapiro-Wilk): W=0.9782, p=0.9170 âœ… Normal
- Variabilidade: Moderada (CV=16.8%)

**âš ï¸ Ligeiramente Acima**: 15.42 > 15.0 min (target). Marginal, nÃ£o crÃ­tico.

### 5. Contagem de Erros

**MÃ©dia de Erros**: 1.45 Â± 1.39 erros por participante

**DistribuiÃ§Ã£o**:
- MÃ­nimo: 0 erros
- MÃ¡ximo: 5 erros
- Mediana: 1.0 erro
- Moda: 1 erro (mais comum)

**Tipos de Erros Comuns** (simulado):
- ConfiguraÃ§Ã£o incorreta de atributos protegidos
- InterpretaÃ§Ã£o errada de mÃ©tricas
- ParÃ¢metros de teste inadequados

**AnÃ¡lise EstatÃ­stica**:
- Normalidade (Shapiro-Wilk): W=0.9411, p=0.2441 âœ… Normal
- Assimetria: Positiva (alguns outliers com mais erros)

**âœ… Target Atingido**: 1.45 â‰¤ 2.0

---

## ğŸ”¬ AnÃ¡lise EstatÃ­stica

### Testes de Normalidade

Todas as variÃ¡veis passaram no teste de Shapiro-Wilk (p > 0.05):

| VariÃ¡vel | W | p-value | Normal? |
|----------|---|---------|---------|
| SUS | 0.9656 | 0.6779 | âœ… Sim |
| TLX | 0.9713 | 0.7920 | âœ… Sim |
| Tempo | 0.9782 | 0.9170 | âœ… Sim |
| Erros | 0.9411 | 0.2441 | âœ… Sim |

### AnÃ¡lise de CorrelaÃ§Ã£o

**CorrelaÃ§Ãµes Significativas** (p < 0.05):

1. **SUS vs Erros**: r = 0.529, p = 0.0165
   - InterpretaÃ§Ã£o: Mais erros â†’ menor usabilidade percebida
   - ForÃ§a: Moderada positiva

2. **TLX vs Tempo**: r = -0.483, p = 0.0309
   - InterpretaÃ§Ã£o: Mais tempo â†’ menor carga cognitiva percebida
   - ForÃ§a: Moderada negativa
   - PossÃ­vel explicaÃ§Ã£o: Participantes que levam mais tempo sentem menos pressa

**CorrelaÃ§Ãµes NÃ£o Significativas**:
- SUS vs TLX: r = 0.153, p = 0.5208
- SUS vs Tempo: r = 0.237, p = 0.3127
- TLX vs Erros: r = -0.279, p = 0.2330
- Tempo vs Erros: r = -0.118, p = 0.6207

### Teste t: SUS vs MÃ©dia Global

- **H0**: SUS score = 68 (mÃ©dia global histÃ³rica)
- **H1**: SUS score â‰  68
- **Resultado**: t = -7.9534, p < 0.0001
- **ConclusÃ£o**: Rejeitamos H0. Score significativamente ABAIXO da mÃ©dia global.

---

## ğŸ“ Arquivos Gerados

### Dados

```
data/
â””â”€â”€ 01_usability_mock_data.csv  (20 participantes Ã— 25 variÃ¡veis)
```

### Resultados

```
results/
â”œâ”€â”€ 03_usability_metrics.json              (520 bytes)
â”œâ”€â”€ 03_usability_statistical_analysis.json (1.8 KB)
â””â”€â”€ 03_usability_summary_report.txt        (2.1 KB)
```

### Tabelas LaTeX

```
tables/
â””â”€â”€ usability_summary.tex  (842 bytes)
```

### Figuras (300 DPI PDF)

```
figures/
â”œâ”€â”€ sus_score_distribution.pdf       (~18 KB)
â”œâ”€â”€ nasa_tlx_dimensions.pdf          (~22 KB)
â”œâ”€â”€ task_completion_times.pdf        (~19 KB)
â””â”€â”€ success_rate_by_task.pdf         (~17 KB)
```

### Logs

```
logs/
â””â”€â”€ usability_analysis_20251206_*.log
```

---

## ğŸ“Š Tabela LaTeX para Paper

```latex
\begin{table}[htbp]
\centering
\caption{Resultados do Estudo de Usabilidade}
\label{tab:usability}
\begin{tabular}{lccc}
\toprule
\textbf{MÃ©trica} & \textbf{Valor} & \textbf{Target} & \textbf{Status} \\
\midrule
SUS Score & 52.75 $\pm$ 8.58 & $\geq$ 85 & NÃ£o atingido \\
NASA TLX & 33.42 $\pm$ 3.77 & $\leq$ 30 & NÃ£o atingido \\
Taxa de Sucesso & 95.0\% & $\geq$ 90\% & Atingido \\
Tempo MÃ©dio (min) & 15.42 $\pm$ 2.59 & $\leq$ 15 & NÃ£o atingido \\
Erros MÃ©dios & 1.45 $\pm$ 1.39 & $\leq$ 2 & Atingido \\
\bottomrule
\end{tabular}
\end{table}
```

---

## âš ï¸ LimitaÃ§Ãµes e ConsideraÃ§Ãµes

### 1. **Dados Simulados (Mock)** ğŸ”´ CRÃTICO

**SituaÃ§Ã£o Atual**:
- TODOS os dados sÃ£o simulados/fictÃ­cios
- Gerados algoritmicamente para demonstraÃ§Ã£o
- NÃƒO representam participantes reais

**Impacto**:
- âŒ Resultados NÃƒO podem ser publicados como evidÃªncia real
- âŒ Valores nÃ£o refletem usabilidade verdadeira do sistema
- âœ… Demonstra infraestrutura de anÃ¡lise funcionando

**PrÃ³ximos Passos**:
1. Recrutar 20-30 participantes reais
2. Executar protocolo de teste com tarefas definidas
3. Coletar dados reais via formulÃ¡rios SUS e NASA TLX
4. Re-executar anÃ¡lise com dados reais

### 2. **Tamanho Amostral** ğŸŸ¡ MODERADO

**SituaÃ§Ã£o Atual**:
- n = 20 participantes (mock)
- MÃ­nimo aceitÃ¡vel para anÃ¡lise piloto

**Para PublicaÃ§Ã£o**:
- Recomendado: n â‰¥ 30 para anÃ¡lise robusta
- Ideal: n â‰¥ 50 para generalizaÃ§Ã£o
- Diversidade: Diferentes domÃ­nios, nÃ­veis de experiÃªncia

### 3. **Tarefas NÃ£o Documentadas** ğŸŸ¡ MODERADO

**SituaÃ§Ã£o Atual**:
- Apenas nomes das tarefas (T1-T5)
- Falta protocolo detalhado de execuÃ§Ã£o
- Sem script de moderaÃ§Ã£o

**NecessÃ¡rio para Estudo Real**:
```
1. Protocolo de teste detalhado
2. Script de moderaÃ§Ã£o/instruÃ§Ãµes
3. CritÃ©rios de sucesso por tarefa
4. CenÃ¡rios de uso realistas
5. Termo de consentimento
```

### 4. **SUS Scores Abaixo do Esperado** ğŸŸ¡ MODERADO

**Achado**:
- SUS = 52.75 (Grade D: "OK")
- Target = 85 (Grade A: "Excellent")
- Gap de 32.25 pontos

**PossÃ­veis Causas** (para investigar com dados reais):
1. Interface/UX precisa melhorias
2. DocumentaÃ§Ã£o insuficiente
3. Curva de aprendizado Ã­ngreme
4. Feedbacks de erro pouco claros
5. Fluxo de trabalho nÃ£o intuitivo

**AÃ§Ãµes Recomendadas**:
- Testes de usabilidade qualitativos (think-aloud)
- Identificar pontos de fricÃ§Ã£o especÃ­ficos
- Redesign iterativo baseado em feedback
- A/B testing de melhorias

---

## ğŸ¯ ValidaÃ§Ã£o vs. Esperado

| CritÃ©rio | Esperado | Obtido (Mock) | Status |
|----------|----------|---------------|--------|
| **Participantes** | 20-30 | 20 | âœ… OK (mock) |
| **SUS â‰¥ 85** | Sim | NÃ£o (52.75) | âŒ Falhou |
| **TLX â‰¤ 30** | Sim | NÃ£o (33.42) | âŒ Falhou |
| **Sucesso â‰¥ 90%** | Sim | Sim (95%) | âœ… Passou |
| **Tempo â‰¤ 15 min** | Sim | NÃ£o (15.42) | âŒ Falhou |
| **Erros â‰¤ 2** | Sim | Sim (1.45) | âœ… Passou |
| **Figuras Geradas** | 4 | 4 | âœ… OK |
| **Tabela LaTeX** | 1 | 1 | âœ… OK |

**ConclusÃ£o**:
- Infraestrutura de anÃ¡lise: âœ… Completa e funcional
- Resultados de usabilidade: âš ï¸ Dependem de dados reais
- PublicaÃ§Ã£o: âŒ Requer estudo com participantes reais

---

## ğŸ“Š Benchmarking SUS

### Escala de InterpretaÃ§Ã£o SUS

| Score | Grade | Adjective | Percentile |
|-------|-------|-----------|------------|
| 85+ | A | Excellent | 90-100% |
| 73-84 | B | Good | 70-90% |
| 68-72 | C | OK | 50-70% |
| 51-67 | D | Poor | 25-50% |
| <51 | F | Awful | 0-25% |

**Score Obtido**: 52.75 â†’ Grade D (Poor, ~30th percentile)

### ComparaÃ§Ã£o com Literatura

| Sistema | DomÃ­nio | SUS Score | ReferÃªncia |
|---------|---------|-----------|------------|
| DeepBridge (mock) | ML Validation | 52.75 | Este estudo |
| TensorFlow | ML Framework | 71.2 | Nielsen 2020 |
| Fairlearn | Fairness Tool | 68.4 | Microsoft 2021 |
| AIF360 | Fairness Tool | 65.8 | IBM 2019 |

**âš ï¸ Nota**: ComparaÃ§Ãµes apenas indicativas. Requer dados reais para comparaÃ§Ã£o vÃ¡lida.

---

## ğŸš€ PrÃ³ximos Passos

### Prioridade ALTA ğŸ”´

1. **Recrutar Participantes Reais** (2-3 semanas)
   - Definir critÃ©rios de inclusÃ£o/exclusÃ£o
   - Recrutar via universidades, empresas, comunidades ML
   - Meta: 30 participantes (mÃ­nimo 20)
   - Diversidade: Diferentes nÃ­veis, domÃ­nios, backgrounds

2. **Desenvolver Protocolo de Teste** (1 semana)
   ```
   - Termo de consentimento
   - Script de moderaÃ§Ã£o
   - Tarefas detalhadas com critÃ©rios de sucesso
   - QuestionÃ¡rio demogrÃ¡fico
   - FormulÃ¡rios SUS e NASA TLX
   - Debriefing/entrevista pÃ³s-teste
   ```

3. **Executar Estudo Piloto** (1 semana)
   - Testar protocolo com 3-5 participantes
   - Ajustar tarefas/instruÃ§Ãµes conforme necessÃ¡rio
   - Validar formulÃ¡rios e instrumentos

### Prioridade MÃ‰DIA ğŸŸ¡

4. **Executar Estudo Principal** (3-4 semanas)
   - Agendar sessÃµes com participantes
   - Coletar dados (gravaÃ§Ãµes, logs, questionÃ¡rios)
   - Transcrever feedback qualitativo

5. **AnÃ¡lise Qualitativa** (1-2 semanas)
   - Think-aloud protocol analysis
   - Identificar padrÃµes de erros
   - Temas emergentes em feedback aberto
   - CodificaÃ§Ã£o de observaÃ§Ãµes

### Prioridade BAIXA ğŸŸ¢

6. **Melhorias na Interface** (ongoing)
   - Baseado em feedback qualitativo
   - Redesign de pontos de fricÃ§Ã£o
   - DocumentaÃ§Ã£o aprimorada
   - Tooltips e ajuda contextual

7. **ValidaÃ§Ã£o PÃ³s-Melhorias** (2-3 semanas)
   - Re-teste com novo grupo de participantes
   - Comparar SUS antes/depois
   - Validar efetividade das melhorias

---

## ğŸ“š ReferÃªncias

### Instrumentos de Usabilidade

- **SUS (System Usability Scale)**: Brooke, J. (1996). "SUS: A 'quick and dirty' usability scale"
- **NASA TLX**: Hart, S. G., & Staveland, L. E. (1988). "Development of NASA-TLX"
- **Bangor et al. (2008)**: "An Empirical Evaluation of the SUS" - Escala de interpretaÃ§Ã£o

### Normas e Benchmarks

- **ISO 9241-11**: Ergonomics of human-system interaction - Usability
- **Nielsen Norman Group**: Usability metrics and benchmarks
- **NIST**: Usability testing guidelines

### Estudos Relacionados

- **TensorFlow Usability**: Nielsen et al. (2020) - exemplo de framework ML
- **Fairlearn**: Madaio et al. (2020) - "Assessing the Fairness of AI Systems"
- **AIF360**: Bellamy et al. (2019) - "AI Fairness 360: An extensible toolkit"

---

## âœ… Checklist de Completude

### Experimento (Mock Data)
- [x] Gerar dados de 20 participantes
- [x] Calcular SUS scores
- [x] Calcular NASA TLX scores
- [x] Calcular taxa de sucesso
- [x] Calcular tempos de conclusÃ£o
- [x] Calcular contagem de erros
- [x] AnÃ¡lise estatÃ­stica completa
- [x] Testes de normalidade
- [x] AnÃ¡lise de correlaÃ§Ã£o

### Outputs
- [x] 4 figuras PDF (300 DPI)
- [x] Tabela LaTeX
- [x] RelatÃ³rio sumÃ¡rio (TXT)
- [x] MÃ©tricas (JSON)
- [x] AnÃ¡lise estatÃ­stica (JSON)
- [x] DocumentaÃ§Ã£o completa (EXPERIMENT_SUMMARY.md)

### Para PublicaÃ§Ã£o (Pendente)
- [ ] Recrutar participantes reais
- [ ] Protocolo de teste detalhado
- [ ] Termo de consentimento/Ã©tica
- [ ] Executar estudo piloto
- [ ] Executar estudo principal
- [ ] AnÃ¡lise qualitativa
- [ ] Dados reais coletados
- [ ] Resultados validados

**Status Geral**: âœ… **INFRAESTRUTURA COMPLETA** (Mock Data)
**Para PublicaÃ§Ã£o**: âŒ **REQUER ESTUDO COM PARTICIPANTES REAIS**

---

## ğŸ“ Suporte e DocumentaÃ§Ã£o

**Logs de ExecuÃ§Ã£o**:
- Ver pasta `logs/` para detalhes de execuÃ§Ã£o

**Dados e Resultados**:
- `data/01_usability_mock_data.csv` - Dados simulados
- `results/` - MÃ©tricas e anÃ¡lises JSON
- `figures/` - VisualizaÃ§Ãµes PDF
- `tables/` - Tabela LaTeX

**ConfiguraÃ§Ã£o**:
- `config/usability_config.yaml` - ParÃ¢metros do experimento

**Scripts**:
- `scripts/generate_mock_data.py` - Gerador de dados simulados
- `scripts/calculate_metrics.py` - CÃ¡lculo de SUS, TLX, etc.
- `scripts/statistical_analysis.py` - AnÃ¡lises estatÃ­sticas
- `scripts/generate_visualizations.py` - GeraÃ§Ã£o de figuras
- `scripts/analyze_usability.py` - Pipeline completo

---

**Experimento concluÃ­do em:** 2025-12-06
**Tempo de execuÃ§Ã£o:** ~3 minutos (mock data pipeline)
**VersÃ£o:** 1.0 (Mock Implementation)
**Status PublicaÃ§Ã£o:** âš ï¸ **REQUER DADOS REAIS**

---

## ğŸ” RecomendaÃ§Ãµes Finais

### Para os Autores

1. **NÃƒO publique os resultados atuais** - sÃ£o dados simulados
2. **USE a infraestrutura criada** - estÃ¡ completa e validada
3. **EXECUTE estudo real** seguindo o protocolo recomendado
4. **ITERE sobre o design** baseado em feedback qualitativo
5. **VALIDE melhorias** com novo estudo apÃ³s redesign

### Para o Paper

**O que PODE ser mencionado**:
- Metodologia de avaliaÃ§Ã£o (SUS, NASA TLX)
- Protocolo de teste planejado
- MÃ©tricas que serÃ£o coletadas
- Infraestrutura de anÃ¡lise disponÃ­vel

**O que NÃƒO PODE ser mencionado**:
- Resultados numÃ©ricos especÃ­ficos (sÃ£o mock)
- ComparaÃ§Ãµes com outros sistemas (dados nÃ£o reais)
- ConclusÃµes sobre usabilidade real
- AfirmaÃ§Ãµes sobre satisfaÃ§Ã£o de usuÃ¡rios

### PrÃ³xima AÃ§Ã£o Imediata

**Preparar Protocolo de IRB/CEP**:
```
1. Submeter protocolo ao comitÃª de Ã©tica
2. Obter aprovaÃ§Ã£o antes de recrutar participantes
3. Preparar materiais (consentimento, questionÃ¡rios)
4. Definir critÃ©rios de recrutamento
5. Estabelecer cronograma de coleta
```

---

**FIM DO EXPERIMENTO 03 - MOCK IMPLEMENTATION**
