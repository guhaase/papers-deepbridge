% Seção 2: Background and Related Work
% DeepBridge: Framework Unificado para Validação de ML em Produção

\section{Background e Trabalhos Relacionados}
\label{sec:background}

Esta seção revisa o contexto de validação de modelos de ML, ferramentas existentes e trabalhos relacionados que fundamentam o desenvolvimento do DeepBridge.

% ========================================
% 2.1 ML Validation Landscape
% ========================================

\subsection{Dimensões de Validação de ML}
\label{subsec:validation_landscape}

A validação abrangente de modelos de ML requer avaliar múltiplas dimensões além da acurácia preditiva~\cite{breck2017ml,sculley2015hidden}. Revisamos cada dimensão e sua importância:

\subsubsection{Fairness (Equidade)}

Fairness em ML refere-se à ausência de viés discriminatório contra grupos protegidos definidos por atributos sensíveis como raça, gênero, idade ou religião~\cite{mehrabi2021survey,barocas2019fairness}. Três definições principais de fairness emergem na literatura:

\begin{itemize}
    \item \textbf{Individual Fairness}~\cite{dwork2012fairness}: Indivíduos similares devem receber tratamento similar
    \item \textbf{Group Fairness}~\cite{hardt2016equality}: Métricas de desempenho devem ser balanceadas entre grupos demográficos
    \item \textbf{Causal Fairness}~\cite{kusner2017counterfactual}: Decisões não devem ser causalmente influenciadas por atributos sensíveis
\end{itemize}

\textbf{Group Fairness} é o foco primário de requisitos regulatórios. Métricas comuns incluem:

\begin{itemize}
    \item \textbf{Statistical Parity}~\cite{dwork2012fairness}: $P(\hat{Y}=1|A=0) = P(\hat{Y}=1|A=1)$ onde $A$ é atributo sensível
    \item \textbf{Equal Opportunity}~\cite{hardt2016equality}: $P(\hat{Y}=1|Y=1,A=0) = P(\hat{Y}=1|Y=1,A=1)$ (igualdade de TPR)
    \item \textbf{Equalized Odds}~\cite{hardt2016equality}: Igualdade de TPR e FPR entre grupos
    \item \textbf{Disparate Impact}~\cite{feldman2015certifying}: $\frac{P(\hat{Y}=1|A=0)}{P(\hat{Y}=1|A=1)} \geq 0.80$ (regra dos 80\% da EEOC)
\end{itemize}

Regulamentações como EEOC~\cite{eeoc1978uniform} e ECOA~\cite{ecoa1974equal} exigem demonstração de fairness, tornando esta dimensão crítica para deployment em produção.

\subsubsection{Robustness (Robustez)}

Robustez refere-se à capacidade de um modelo manter desempenho sob perturbações dos dados de entrada~\cite{goodfellow2014explaining}. Duas abordagens principais existem:

\begin{itemize}
    \item \textbf{Perturbation Testing}~\cite{madry2018towards}: Avalia degradação sob ruído gaussiano, quantile perturbations ou data corruption
    \item \textbf{Adversarial Robustness}~\cite{goodfellow2014explaining,carlini2017towards}: Avalia resistência a ataques adversariais crafted
\end{itemize}

Recentemente, \textbf{slice-based testing}~\cite{eyuboglu2022domino,bareinboim2022sliceline} emergiu como abordagem para identificar \textbf{weakspots}: subgrupos onde o modelo falha sistematicamente. Google's Slice Finder~\cite{chung2019slice} e Microsoft's Spotlight~\cite{ghai2021spotlight} pioneiraram esta direção, mas carecem de integração com pipelines de validação holísticos.

\subsubsection{Uncertainty (Quantificação de Incerteza)}

Modelos de ML devem quantificar confiança em suas predições, especialmente em domínios críticos como saúde e veículos autônomos~\cite{guo2017calibration}. Técnicas incluem:

\begin{itemize}
    \item \textbf{Calibration}~\cite{guo2017calibration,kuleshov2018accurate}: Alinhamento entre probabilidades preditas e frequências observadas
    \item \textbf{Conformal Prediction}~\cite{vovk2005algorithmic,angelopoulos2021gentle}: Garantias matemáticas de coverage em prediction sets
    \item \textbf{Bayesian Methods}~\cite{gal2016dropout}: Modelagem de distribuições sobre parâmetros
\end{itemize}

\textbf{Conformal Prediction} é particularmente atraente por fornecer garantias \textit{distribution-free}: para qualquer nível de confiança $\alpha$, o coverage é garantido ser $\geq 1-\alpha$ sem assumir distribuições específicas~\cite{vovk2005algorithmic}.

\subsubsection{Resilience (Resiliência e Drift Detection)}

Modelos em produção enfrentam \textit{distribution shifts} ao longo do tempo~\cite{gama2014survey,rabanser2019failing}. Cinco tipos de drift são reconhecidos:

\begin{enumerate}
    \item \textbf{Data Drift} (Covariate Shift): $P(X) \neq P'(X)$ - distribuição de features muda
    \item \textbf{Concept Drift}: $P(Y|X) \neq P'(Y|X)$ - relação input-output muda
    \item \textbf{Label Drift}: $P(Y) \neq P'(Y)$ - distribuição de targets muda
    \item \textbf{Prediction Drift}: $P(\hat{Y}) \neq P'(\hat{Y})$ - distribuição de predições muda
    \item \textbf{Feature Drift}: Features individuais mudam de distribuição
\end{enumerate}

Métricas estatísticas para detecção incluem:
\begin{itemize}
    \item \textbf{Population Stability Index (PSI)}~\cite{siddiqi2006credit}: $PSI = \sum (\%_{actual} - \%_{expected}) \times \ln(\frac{\%_{actual}}{\%_{expected}})$
    \item \textbf{Kullback-Leibler Divergence}: $D_{KL}(P||Q) = \sum P(x) \log \frac{P(x)}{Q(x)}$
    \item \textbf{Wasserstein Distance}~\cite{ramdas2017wasserstein}: Distância de transporte ótima entre distribuições
    \item \textbf{Kolmogorov-Smirnov Test}~\cite{massey1951kolmogorov}: Teste não-paramétrico de distribuições
\end{itemize}

\subsubsection{Hyperparameter Sensitivity}

Compreender sensibilidade a hiperparâmetros é essencial para debugging e feature selection~\cite{probst2019tunability}. Cross-validation combinada com permutation importance permite identificar configurações críticas que requerem tuning cuidadoso.

% ========================================
% 2.2 Ferramentas Existentes
% ========================================

\subsection{Ferramentas de Validação Existentes}
\label{subsec:existing_tools}

Revisamos ferramentas especializadas para cada dimensão de validação:

\subsubsection{Ferramentas de Fairness}

\paragraph{AI Fairness 360 (IBM)}
\cite{bellamy2018ai} oferece aproximadamente 10 métricas de fairness e 11 algoritmos de mitigação. Suporta bias detection pré e pós-treinamento, mas:
\begin{itemize}
    \item Não verifica \textit{compliance} regulatório automaticamente
    \item Requer identificação manual de atributos sensíveis
    \item APIs complexas com múltiplas classes abstratas
\end{itemize}

\paragraph{Fairlearn (Microsoft)}
\cite{bird2020fairlearn} foca em mitigação de bias através de:
\begin{itemize}
    \item Reduction approaches (re-weighting, relabeling)
    \item Post-processing (threshold optimization)
    \item Aproximadamente 8 métricas de fairness
\end{itemize}

Limitação: Maior ênfase em mitigation do que em detection/reporting.

\paragraph{Aequitas}
\cite{saleiro2018aequitas} é compliance-focused mas limitada a:
\begin{itemize}
    \item Métricas básicas de group fairness
    \item Sem integração com outras dimensões de validação
\end{itemize}

\subsubsection{Ferramentas de Robustness e Drift}

\paragraph{Alibi Detect}
\cite{van2021alibi} oferece outlier detection, adversarial detection e drift detection, mas:
\begin{itemize}
    \item Foco em deep learning (CNNs, Transformers)
    \item Suporte limitado para dados tabulares
    \item Sem weakspot detection ou slice-based testing
\end{itemize}

\paragraph{Cleverhans}
\cite{papernot2018cleverhans} especializa-se em adversarial robustness para deep learning, não aplicável a modelos tabulares tradicionais.

\paragraph{Evidently AI}
Foca exclusivamente em drift detection com dashboards interativos, mas sem integração com fairness ou robustness.

\subsubsection{Ferramentas de Uncertainty}

\paragraph{UQ360 (IBM)}
\cite{wei2019uq360} oferece múltiplos métodos de quantificação de incerteza:
\begin{itemize}
    \item Conformal prediction
    \item Bayesian approximations
    \item Ensemble methods
\end{itemize}

Limitação: Standalone tool sem integração com validação holística.

\subsubsection{Ferramentas de Synthetic Data}

\paragraph{Synthetic Data Vault (SDV)}
\cite{patki2016synthetic} oferece métodos estatísticos e deep learning (CTGAN, TVAE) mas não escala além de datasets em memória.

\paragraph{CTGAN}
\cite{xu2019modeling} usa GANs para dados tabulares, mas:
\begin{itemize}
    \item Computacionalmente intensivo
    \item Limitado a datasets $<$ 10GB
    \item Sem garantias de qualidade
\end{itemize}

% ========================================
% 2.3 Tabela Comparativa
% ========================================

\subsubsection{Análise Comparativa}

A Tabela~\ref{tab:tool_comparison} resume a cobertura de features das ferramentas existentes versus DeepBridge.

\begin{table}[htbp]
\centering
\caption{Comparação de ferramentas de validação de ML}
\label{tab:tool_comparison}
\small
\begin{tabular}{@{}lccccccc@{}}
\toprule
\textbf{Ferramenta} & \textbf{Fair} & \textbf{Robust} & \textbf{Uncert} & \textbf{Resil} & \textbf{KD} & \textbf{Synth} & \textbf{API} \\
\midrule
AI Fairness 360    & $\sim$10 & \xmark & \xmark & \xmark & \xmark & \xmark & \xmark \\
Fairlearn          & $\sim$8  & \xmark & \xmark & \xmark & \xmark & \xmark & \xmark \\
Alibi Detect       & \xmark   & \cmark & $\triangle$ & \cmark & \xmark & \xmark & \xmark \\
UQ360              & \xmark   & \xmark & \cmark & \xmark & \xmark & \xmark & \xmark \\
Evidently AI       & $\triangle$ & \xmark & \xmark & \cmark & \xmark & \xmark & \xmark \\
SDV                & \xmark   & \xmark & \xmark & \xmark & \xmark & \cmark$^*$ & \xmark \\
\midrule
\textbf{DeepBridge} & \textbf{15} & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark \\
\bottomrule
\multicolumn{8}{l}{\footnotesize \cmark: Suporte completo; $\triangle$: Suporte parcial; \xmark: Não suportado; $^*$: Não escala >100GB} \\
\multicolumn{8}{l}{\footnotesize Fair: Fairness metrics; Robust: Robustness; Uncert: Uncertainty; Resil: Resilience;} \\
\multicolumn{8}{l}{\footnotesize KD: Knowledge Distillation; Synth: Synthetic Data; API: Unified API} \\
\end{tabular}
\end{table}

\textbf{Gap Identificado}: Nenhuma ferramenta existente integra múltiplas dimensões de validação em uma API unificada. DeepBridge preenche este gap.

% ========================================
% 2.4 Knowledge Distillation
% ========================================

\subsection{Knowledge Distillation}
\label{subsec:knowledge_distillation}

Knowledge distillation (KD) comprime modelos complexos (teachers) em modelos simples (students) mantendo performance~\cite{hinton2015distilling}.

\subsubsection{Estado da Arte em KD}

\paragraph{Hinton et al. (2015)}
\cite{hinton2015distilling} pioneiraram KD clássico com:
\begin{equation}
\mathcal{L}_{KD} = (1-\alpha) \mathcal{L}_{CE}(y, \hat{y}_{student}) + \alpha \mathcal{L}_{CE}(softmax(z_{teacher}/T), softmax(z_{student}/T))
\end{equation}
onde $T$ é temperatura, $\alpha$ é peso de distillation e $z$ são logits.

\paragraph{FitNets}
\cite{romero2014fitnets} introduz hint-based distillation: student aprende representações intermediárias do teacher além de predictions.

\paragraph{Deep Mutual Learning (DML)}
\cite{zhang2018deep} propõe peer learning: múltiplos students aprendem colaborativamente sem teacher pré-treinado.

\paragraph{Teacher Assistant KD (TAKD)}
\cite{mirzadeh2020improved} introduz destilação em 2 estágios: teacher $\rightarrow$ assistant $\rightarrow$ student. Melhora destilação para grande gap de capacidade.

\paragraph{Auto-KD e Meta-Learning}
Trabalhos recentes exploram auto-tuning de temperatura~\cite{park2019relational} e meta-learning de configurações~\cite{li2020learning}, mas focam em deep learning (CNNs, Transformers).

\subsubsection{Gap em Tabular KD}

Limitações do estado da arte para dados tabulares:
\begin{itemize}
    \item Foco primário em visão computacional e NLP
    \item Poucos trabalhos em tabular data distillation
    \item Configuração manual de hiperparâmetros (temperatura, alpha, model types)
    \item Sem frameworks automatizados para selection de configurações
\end{itemize}

\textbf{HPM-KD} (Seção~\ref{sec:hpmkd}) aborda esses gaps através de:
\begin{itemize}
    \item Meta-learning de configurações para tabular data
    \item Progressive distillation chain (simple $\rightarrow$ complex)
    \item Multi-teacher ensemble com atenção aprendida
    \item Adaptive temperature scheduling
\end{itemize}

% ========================================
% 2.5 Synthetic Data Generation
% ========================================

\subsection{Synthetic Data Generation}
\label{subsec:synthetic_data}

Geração de dados sintéticos é crítica para data augmentation, privacy-preserving sharing e testing~\cite{jordon2022synthetic}.

\subsubsection{Métodos Existentes}

\paragraph{Statistical Methods}
\begin{itemize}
    \item \textbf{Gaussian Copulas}~\cite{nelsen2007introduction}: Modela distribuições marginais e dependências separadamente. Preserva correlações mas assume gaussianidade após transformação.
    \item \textbf{SMOTE}~\cite{chawla2002smote}: Interpolação para balanceamento de classes, não para geração geral.
\end{itemize}

\paragraph{Deep Learning Methods}
\begin{itemize}
    \item \textbf{CTGAN}~\cite{xu2019modeling}: GAN condicional para tabular data com mode-specific normalization
    \item \textbf{TVAE}~\cite{xu2019modeling}: Variational Autoencoder para tabular
    \item \textbf{TableGAN}~\cite{park2018data}: GAN com discriminator semi-supervised
\end{itemize}

\subsubsection{Desafios de Escalabilidade}

Ferramentas existentes não escalam para big data:
\begin{itemize}
    \item SDV limita-se a datasets que cabem em memória
    \item CTGAN requer GPU e é computacionalmente intensivo
    \item Nenhuma solução para datasets > 100GB
\end{itemize}

\textbf{DeepBridge} implementa Gaussian Copula distribuído via Dask:
\begin{itemize}
    \item Processamento paralelo de chunks
    \item Streaming incremental (não carrega tudo em memória)
    \item Única solução para datasets > 100GB
\end{itemize}

% ========================================
% 2.6 ML System Design
% ========================================

\subsection{ML System Design e Technical Debt}
\label{subsec:ml_systems}

\subsubsection{Hidden Technical Debt}
Sculley et al.~\cite{sculley2015hidden} identificam que sistemas de ML acumulam \textit{technical debt} através de:
\begin{itemize}
    \item \textbf{Entanglement}: Mudanças em uma feature afetam todo o modelo (CACE principle)
    \item \textbf{Hidden Feedback Loops}: Modelos afetam o mundo que os treinou
    \item \textbf{Glue Code}: 95\%+ do código é integração entre ferramentas
    \item \textbf{Pipeline Jungles}: Pipelines complexos difíceis de manter
\end{itemize}

\subsubsection{ML Test Score}
Breck et al.~\cite{breck2017ml} (Google) propõem rubrica para production readiness:
\begin{itemize}
    \item Tests para features e data
    \item Model development tests
    \item ML infrastructure tests
    \item Monitoring tests
\end{itemize}

DeepBridge aborda esses desafios através de:
\begin{itemize}
    \item \textbf{Unified API}: Reduz glue code e entanglement
    \item \textbf{Standardized Testing}: Framework consistente para 5 dimensões
    \item \textbf{Production-Ready Reports}: Facilita monitoring
\end{itemize}

\subsubsection{Software Engineering for ML}
Amershi et al.~\cite{amershi2019software} (Microsoft) identificam que \textbf{engenharia consome 80\%+ do tempo} em projetos de ML. Desafios incluem:
\begin{itemize}
    \item Reprodutibilidade
    \item Versionamento de dados e modelos
    \item Collaboration entre data scientists e engineers
    \item Testing e validação
\end{itemize}

DeepBridge facilita collaboration através de:
\begin{itemize}
    \item APIs simples acessíveis a data scientists
    \item Relatórios standardizados compreensíveis por stakeholders não-técnicos
    \item Integração com ferramentas de produção (MLflow, databases)
\end{itemize}

% ========================================
% 2.7 Posicionamento do DeepBridge
% ========================================

\subsection{Posicionamento do DeepBridge no Ecossistema}
\label{subsec:deepbridge_positioning}

Com base na revisão, identificamos três gaps principais que DeepBridge aborda:

\paragraph{Gap 1: Fragmentação de Ferramentas}
\textbf{Problema}: Practitioners precisam integrar 5+ ferramentas especializadas (AI Fairness 360, Alibi Detect, UQ360, Evidently AI, SDV) para validação abrangente.

\textbf{Solução DeepBridge}: API unificada que integra fairness, robustness, uncertainty, resilience e hyperparameter analysis em workflow consistente.

\paragraph{Gap 2: Compliance Regulatório}
\textbf{Problema}: Ferramentas calculam métricas acadêmicas mas não verificam compliance EEOC/ECOA/GDPR automaticamente, forçando verificação manual propensa a erros.

\textbf{Solução DeepBridge}: Primeiro framework com \textit{Compliance Engine} que verifica automaticamente regra dos 80\%, Questão 21 (2\% representation) e gera relatórios audit-ready.

\paragraph{Gap 3: Knowledge Distillation para Tabular}
\textbf{Problema}: Estado da arte em KD foca em deep learning (CNNs, Transformers); poucos trabalhos abordam tabular data, e todos requerem configuração manual.

\textbf{Solução DeepBridge}: HPM-KD Framework automatiza selection de configurações via meta-learning, combina progressive distillation, multi-teacher ensemble e adaptive temperature.

\paragraph{Gap 4: Synthetic Data em Escala}
\textbf{Problema}: Ferramentas existentes (SDV, CTGAN) não escalam para datasets > 100GB.

\textbf{Solução DeepBridge}: Implementação Dask-based de Gaussian Copula para processamento distribuído.

\paragraph{Gap 5: Production Deployment}
\textbf{Problema}: Workflows fragmentados dificultam transição de notebooks para produção (80\%+ do tempo em engenharia vs. análise).

\textbf{Solução DeepBridge}: Sistema de relatórios multi-formato (HTML, PDF, JSON), templates customizáveis, integração com MLflow/databases.

\medskip

\textbf{Contribuição Única}: DeepBridge é o \textbf{primeiro framework a unificar} múltiplas dimensões de validação, compliance regulatório, knowledge distillation e synthetic data em uma biblioteca coesa e production-ready.
