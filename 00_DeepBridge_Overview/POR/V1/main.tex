\documentclass[review,12pt]{elsarticle}

\usepackage{lineno,hyperref}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{subcaption}
\usepackage{multirow}
\usepackage{url}
\usepackage{pifont}
\usepackage{tikz}
\usetikzlibrary{shapes,arrows,positioning,calc}

% Define checkmark and xmark
\newcommand{\cmark}{\ding{51}}
\newcommand{\xmark}{\ding{55}}

% Code listing style
\lstset{
    basicstyle=\ttfamily\small,
    breaklines=true,
    frame=single,
    language=Python,
    showstringspaces=false,
    commentstyle=\color{gray},
    keywordstyle=\color{blue},
    stringstyle=\color{red}
}

% Hyperref setup
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,
    urlcolor=cyan,
    citecolor=green
}

\modulolinenumbers[5]

\journal{MLSys 2026}

%%%%%%%%%%%%%%%%%%%%%%%
%% Elsevier bibliography styles
%%%%%%%%%%%%%%%%%%%%%%%
%% To change the style, put a % in front of the second line of the current style and
%% remove the % from the second line of the style you would like to use.
%%%%%%%%%%%%%%%%%%%%%%%

%% Numbered
%\bibliographystyle{model1-num-names}

%% Numbered without titles
%\bibliographystyle{model1a-num-names}

%% Harvard
%\bibliographystyle{model2-names.bst}\biboptions{authoryear}

%% Vancouver numbered
%\usepackage{numcompress}\bibliographystyle{model3-num-names}

%% Vancouver name/year
%\usepackage{numcompress}\bibliographystyle{model4-names}\biboptions{authoryear}

%% APA style
%\bibliographystyle{model5-names}\biboptions{authoryear}

%% AMA style
%\usepackage{numcompress}\bibliographystyle{model6-num-names}

%% `Elsevier LaTeX' style
\bibliographystyle{elsarticle-num}
%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\begin{frontmatter}

\title{DeepBridge: A Unified Production-Ready Framework for Multi-Dimensional Machine Learning Validation}

%% Group authors per affiliation:
\author[inst1]{Author Name\corref{cor1}}
\ead{author@email.com}

\address[inst1]{Institution Name, Department, City, Country}

\cortext[cor1]{Corresponding author}

\begin{abstract}
Validacao de modelos de Machine Learning para producao requer avaliacao multi-dimensional (fairness, robustness, uncertainty, resilience) e conformidade regulatoria (EEOC, ECOA, GDPR). Ferramentas existentes sao fragmentadas: profissionais devem integrar 5+ bibliotecas especializadas com APIs distintas, resultando em workflows manuais custosos e propensos a erros. Nenhum framework unificado existe que: (1) integre multiplas dimensoes de validacao com API consistente, (2) verifique compliance regulatorio automaticamente, e (3) gere relatorios audit-ready para auditorias.

Apresentamos \textbf{DeepBridge}, biblioteca Python com 80K linhas de codigo que unifica validacao multi-dimensional, verificacao automatica de compliance, knowledge distillation e geracao de dados sinteticos. DeepBridge oferece: (i) 5 suites de validacao (fairness com 15 metricas, robustness com weakspot detection, uncertainty via conformal prediction, resilience com 5 tipos de drift, hyperparameter sensitivity), (ii) verificacao automatica de EEOC/ECOA/GDPR, (iii) sistema de relatorios multi-formato (HTML interativo/estatico, PDF, JSON), (iv) HPM-KD framework para knowledge distillation com meta-learning, e (v) geracao escalavel de dados sinteticos via Dask.

Atraves de 6 estudos de caso (credit scoring, hiring, healthcare, mortgage, insurance, fraud) demonstramos que DeepBridge: \textbf{reduz tempo de validacao em 89\%} (17 min vs. 150 min com ferramentas fragmentadas), \textbf{detecta violacoes de fairness automaticamente} com coverage completo (10/10 features vs. 2/10 de ferramentas existentes), \textbf{gera relatorios audit-ready} em minutos, e \textbf{comprime modelos 10.3$\times$} com 98.4\% de retencao de accuracy via HPM-KD. Estudo de usabilidade com 20 participantes demonstra SUS score 87.5 (top 10\%, ``excellent''), taxa de sucesso 95\%, e baixa carga cognitiva (NASA-TLX 28/100).

DeepBridge e open-source sob licenca MIT em \url{https://github.com/deepbridge/deepbridge}, com documentacao completa em \url{https://deepbridge.readthedocs.io}.
\end{abstract}

\begin{keyword}
Machine Learning Validation \sep Fairness \sep Robustness \sep Uncertainty Quantification \sep Knowledge Distillation \sep Model Compression \sep Regulatory Compliance \sep EEOC \sep ECOA \sep GDPR \sep Automated Testing \sep MLOps \sep Production ML \sep Algorithmic Fairness \sep Bias Detection \sep Conformal Prediction \sep Drift Detection \sep Explainability
\MSC[2010] 68T05 \sep 68T10 \sep 68T01
\end{keyword}

\end{frontmatter}

\linenumbers

%% ========================================
%% MAIN CONTENT
%% ========================================

\input{sections/01_introduction}
\input{sections/02_background}
\input{sections/03_architecture}
\input{sections/04_validation}
\input{sections/05_compliance}
\input{sections/06_hpmkd}
\input{sections/07_reports}
\input{sections/08_implementation}
\input{sections/09_evaluation}
\input{sections/10_discussion}
\input{sections/11_conclusion}

%% ========================================
%% ACKNOWLEDGMENTS
%% ========================================

\section*{Acknowledgments}
We thank the DeepBridge development team and the open-source community for their contributions. This work was partially supported by [funding sources to be added].

%% ========================================
%% BIBLIOGRAPHY
%% ========================================

\bibliography{bibliography/references}

%% ========================================
%% APPENDICES
%% ========================================

\appendix

\section{API Reference}
\label{app:api}

\subsection{Core Classes}

\begin{lstlisting}[language=Python, caption=DBDataset API]
# DBDataset: Unified Data Container
class DBDataset(data, target_column, features, model, ...)
    # Properties
    .X                    # Feature data
    .target               # Target data
    .features            # Feature names
    .categorical_features
    .numerical_features
    .model               # Loaded model

    # Methods
    .get_feature_data()
    .get_target_data()
    .set_model(model)
\end{lstlisting}

\begin{lstlisting}[language=Python, caption=Experiment API]
# Experiment: Validation Orchestrator
class Experiment(dataset, experiment_type, tests, protected_attributes, ...)
    # Methods
    .run_tests(config_name='medium')    # 'quick', 'medium', 'full'
    .run_test(test_type, config)
    .run_fairness_tests(config)
    .save_html(test_type, file_path, report_type='interactive')
    .get_feature_importance()

    # Properties
    .experiment_type
    .test_results
    .experiment_info
    .model
\end{lstlisting}

\section{Configuration Presets}
\label{app:config}

\subsection{Validation Presets}
\begin{itemize}
    \item \textbf{quick}: Fast execution, lower coverage (5-10 min)
    \item \textbf{medium}: Balanced (15-30 min) - recommended for most use cases
    \item \textbf{full}: Comprehensive coverage (30-60 min)
\end{itemize}

\subsection{HPM-KD Presets}
\begin{itemize}
    \item \textbf{default}: max\_configs=16, n\_trials=auto
    \item \textbf{fast}: max\_configs=8, n\_trials=3
    \item \textbf{comprehensive}: max\_configs=32, n\_trials=20
\end{itemize}

\section{Metrics Catalog}
\label{app:metrics}

\subsection{Fairness Metrics (15)}

\textbf{Pre-Training (4):}
\begin{itemize}
    \item Class Balance
    \item Concept Balance
    \item KL Divergence
    \item JS Divergence
\end{itemize}

\textbf{Post-Training (11):}
\begin{itemize}
    \item Statistical Parity
    \item Equal Opportunity
    \item Equalized Odds
    \item Disparate Impact (EEOC 80\% rule)
    \item FNR Difference
    \item Conditional Acceptance
    \item Conditional Rejection
    \item Precision Difference
    \item Accuracy Difference
    \item Treatment Equality
    \item Entropy Index
\end{itemize}

\subsection{Robustness Metrics}
\begin{itemize}
    \item Perturbation Impact
    \item Weakspot Severity
    \item Accuracy Degradation
\end{itemize}

\subsection{Uncertainty Metrics}
\begin{itemize}
    \item ECE (Expected Calibration Error)
    \item MCE (Maximum Calibration Error)
    \item Brier Score
    \item Coverage (Conformal Prediction)
\end{itemize}

\subsection{Resilience Metrics}
\begin{itemize}
    \item PSI (Population Stability Index)
    \item KL Divergence
    \item Wasserstein Distance
    \item KS Statistic
\end{itemize}

\section{Reproducibility}
\label{app:reproducibility}

\subsection{Code Availability}
\begin{itemize}
    \item \textbf{GitHub}: \url{https://github.com/DeepBridge-Validation/DeepBridge}
    \item \textbf{Documentation}: \url{https://deepbridge.readthedocs.io/}
    \item \textbf{Version}: 0.1.59 (as of December 2025)
\end{itemize}

\subsection{Experiments}
\begin{itemize}
    \item \textbf{Scripts}: Available in \texttt{/experiments/} directory
    \item \textbf{Datasets}: UCI ML Repository, OpenML-CC18
    \item \textbf{Random Seed}: 42 (fixed for reproducibility)
\end{itemize}

\subsection{Hardware}
\begin{itemize}
    \item \textbf{CPU}: Intel Xeon Gold 6248R (48 cores)
    \item \textbf{RAM}: 256GB
    \item \textbf{GPU}: NVIDIA A100 (optional, for future extensions)
\end{itemize}

\end{document}
