\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts

\usepackage[portuguese]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{array}
\usepackage{listings}

% Configuração de cores
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

% Configuração de listings
\lstdefinestyle{pythonstyle}{
    backgroundcolor=\color{backcolour},
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,
    breaklines=true,
    captionpos=b,
    keepspaces=true,
    numbers=left,
    numbersep=5pt,
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    tabsize=2
}
\lstset{style=pythonstyle}

\begin{document}

\title{Survey Abrangente sobre Validação de Modelos de Machine Learning: Robustez, Incerteza, Resiliência, Equidade e Análise de Hiperparâmetros}

\author{
\IEEEauthorblockN{[Autores a Definir]}
\IEEEauthorblockA{\textit{Instituição} \\
Email: author@institution.edu}
}

\maketitle

\begin{abstract}
A validação de modelos de Machine Learning (ML) vai muito além da simples medição de acurácia. Sistemas críticos em saúde, finanças e justiça requerem garantias multidimensionais de confiabilidade, incluindo robustez a perturbações, quantificação de incerteza, resiliência a mudanças de distribuição, equidade entre grupos demográficos e análise adequada de hiperparâmetros. Este survey apresenta uma taxonomia unificada integrando cinco dimensões essenciais de validação ML, sintetiza mais de 100 trabalhos científicos, compara empiricamente 15+ ferramentas existentes, e apresenta o framework DeepBridge como implementação de referência. Identificamos lacunas críticas nas ferramentas atuais — fragmentação, falta de integração com requisitos regulatórios, e ausência de suporte para deployment em produção — e propomos direções futuras incluindo validação de modelos foundation, fairness interseccional e certificação formal. Este trabalho serve como guia prático para pesquisadores e profissionais que buscam validação abrangente de sistemas ML.
\end{abstract}

\begin{IEEEkeywords}
Machine Learning, Validação de Modelos, Robustez, Quantificação de Incerteza, Detecção de Drift, Fairness, Análise de Hiperparâmetros
\end{IEEEkeywords}

\section{Introdução}

A crescente adoção de sistemas de Machine Learning (ML) em domínios críticos — desde diagnóstico médico até decisões de crédito e contratação — torna a validação rigorosa uma necessidade não apenas técnica, mas ética e legal. Enquanto métricas tradicionais como acurácia, precisão e recall fornecem uma primeira avaliação de performance, elas capturam apenas uma faceta estreita da confiabilidade de um modelo. Um sistema pode apresentar alta acurácia global mas falhar catastroficamente em subpopulações específicas, exibir viés discriminatório contra grupos protegidos, degradar rapidamente sob mudanças de distribuição, ou fornecer predições com alta confiança em casos onde a incerteza é elevada.

\subsection{Motivação}

Diversos incidentes de alto impacto evidenciam as consequências de validação inadequada:

\begin{itemize}
    \item \textbf{Saúde}: Modelos de diagnóstico médico que funcionam bem em populações do desenvolvimento mas falham em outras etnias devido a viés nos dados de treinamento~\cite{obermeyer2019}.
    \item \textbf{Justiça Criminal}: Sistemas de predição de reincidência com disparidades significativas entre grupos raciais~\cite{angwin2016}.
    \item \textbf{Contratação}: Ferramentas de triagem de currículos penalizando candidatas mulheres devido a padrões históricos nos dados~\cite{dastin2018}.
    \item \textbf{Crédito}: Modelos de credit scoring violando requisitos do Equal Credit Opportunity Act (ECOA)~\cite{fuster2022}.
\end{itemize}

Estes casos ilustram cinco dimensões críticas de validação frequentemente negligenciadas:

\begin{enumerate}
    \item \textbf{Robustez}: Manter performance sob perturbações adversariais ou naturais.
    \item \textbf{Incerteza}: Quantificar confiança nas predições, especialmente em regiões de baixa densidade.
    \item \textbf{Resiliência}: Detectar e adaptar a mudanças de distribuição (drift) ao longo do tempo.
    \item \textbf{Equidade}: Garantir tratamento justo entre grupos demográficos e conformidade regulatória.
    \item \textbf{Hiperparâmetros}: Analisar sensibilidade e importância para garantir configuração adequada.
\end{enumerate}

\subsection{Problema}

Apesar da crescente literatura em cada dimensão individual — adversarial robustness~\cite{goodfellow2015,madry2018}, uncertainty quantification~\cite{gal2016,lakshminarayanan2017}, drift detection~\cite{gama2014,lu2018}, fairness~\cite{barocas2019,mehrabi2021}, e hyperparameter optimization~\cite{bergstra2012,feurer2019} — a validação prática enfrenta desafios significativos:

\begin{itemize}
    \item \textbf{Fragmentação}: Pesquisa em silos com pouca integração entre dimensões.
    \item \textbf{Ferramentas Especializadas}: CleverHans (robustez)~\cite{papernot2018}, AIF360 (fairness)~\cite{bellamy2019}, Alibi (drift)~\cite{alibi2021} — cada uma cobrindo apenas 1-2 dimensões.
    \item \textbf{Gap Regulatório}: Poucas ferramentas traduzem requisitos legais (EEOC, ECOA, GDPR) em testes executáveis.
    \item \textbf{Deployment Gap}: Foco em pesquisa e experimentação, não em monitoramento contínuo em produção.
    \item \textbf{Trade-offs Opacidade}: Falta de orientação sobre compromissos entre dimensões (e.g., robustness vs. accuracy).
\end{itemize}

\subsection{Nossa Solução}

Este survey apresenta uma \textbf{taxonomia unificada} integrando cinco dimensões de validação ML, fundamentada em:

\begin{itemize}
    \item \textbf{Survey Abrangente}: Síntese de 100+ papers (2015-2025) cobrindo robustez, incerteza, resiliência, fairness e HPO.
    \item \textbf{Comparação Empírica}: Avaliação sistemática de 15+ ferramentas em critérios de cobertura, usabilidade, extensibilidade e maturidade.
    \item \textbf{Framework de Referência}: DeepBridge — implementação open-source com 20k+ linhas de código integrando as cinco dimensões.
    \item \textbf{Case Studies}: Validação em saúde (diagnóstico de câncer), finanças (credit scoring) e contratação (resume screening).
    \item \textbf{Roadmap Futuro}: Identificação de 10+ desafios abertos e direções de pesquisa prioritárias.
\end{itemize}

\subsection{Contribuições}

Este trabalho oferece as seguintes contribuições:

\begin{enumerate}
    \item \textbf{Taxonomia Unificada}: Primeira classificação sistemática integrando cinco dimensões de validação ML com 50+ métodos.
    \item \textbf{Survey Extensivo}: Síntese crítica de robustez (15+ métodos), incerteza (10+ técnicas), drift (5 tipos), fairness (15 métricas) e HPO (8+ abordagens).
    \item \textbf{Comparação de Ferramentas}: Avaliação empírica de CleverHans, AIF360, Fairlearn, Alibi, Optuna, Ray Tune e outros em matriz 15×10.
    \item \textbf{Framework Prático}: DeepBridge com cinco suites integradas (Robustness, Uncertainty, Resilience, Fairness, Hyperparameter) e API unificada.
    \item \textbf{Melhores Práticas}: Orientações baseadas em regulações (EEOC, ECOA, GDPR) e 3 case studies de produção.
    \item \textbf{Desafios Futuros}: Identificação de lacunas em validação de LLMs, fairness interseccional, certificação formal e deployment contínuo.
\end{enumerate}

\subsection{Organização do Paper}

O restante deste survey está organizado da seguinte forma: Seção~\ref{sec:robustness} revisa métodos de robustness testing; Seção~\ref{sec:uncertainty} cobre uncertainty quantification; Seção~\ref{sec:resilience} trata de resilience e drift detection; Seção~\ref{sec:fairness} analisa fairness e bias testing; Seção~\ref{sec:hyperparameter} discute análise de hiperparâmetros; Seção~\ref{sec:comparison} compara ferramentas existentes; Seção~\ref{sec:challenges} identifica desafios abertos; e Seção~\ref{sec:conclusion} conclui o trabalho.

\section{Robustness Testing: Métodos e Ferramentas}
\label{sec:robustness}

Robustez refere-se à capacidade de um modelo manter performance aceitável sob perturbações nos dados de entrada. Estas perturbações podem ser adversariais (ataques intencionais) ou naturais (ruído, variações de coleta). Modelos não-robustos são vulneráveis a manipulação maliciosa e degradação em ambientes reais.

\subsection{Definição e Contexto}

Formalmente, seja $f: \mathcal{X} \rightarrow \mathcal{Y}$ um modelo treinado. Robustez mede:
\begin{equation}
\rho(f, \mathbf{x}, \epsilon) = \mathbb{P}[f(\mathbf{x}') = f(\mathbf{x}) \mid ||\mathbf{x}' - \mathbf{x}||_p \leq \epsilon]
\end{equation}
onde $\epsilon$ define a magnitude da perturbação e $||\cdot||_p$ a norma (tipicamente $L_2$ ou $L_\infty$).

\subsection{Adversarial Robustness}

Exemplos adversariais são entradas maliciosamente perturbadas para induzir erro:

\textbf{Fast Gradient Sign Method (FGSM)}~\cite{goodfellow2015}: Perturbação one-step na direção do gradiente:
\begin{equation}
\mathbf{x}_{adv} = \mathbf{x} + \epsilon \cdot \text{sign}(\nabla_{\mathbf{x}} \mathcal{L}(f(\mathbf{x}), y))
\end{equation}

\textbf{Projected Gradient Descent (PGD)}~\cite{madry2018}: Versão iterativa com projeção:
\begin{equation}
\mathbf{x}_{t+1} = \Pi_{\mathcal{B}_\epsilon(\mathbf{x})} \left( \mathbf{x}_t + \alpha \cdot \text{sign}(\nabla_{\mathbf{x}_t} \mathcal{L}(f(\mathbf{x}_t), y)) \right)
\end{equation}

\textbf{Carlini \& Wagner (C\&W)}~\cite{carlini2017}: Otimização não-linear para encontrar perturbações mínimas:
\begin{equation}
\min_{|\mathbf{x}' - \mathbf{x}||_2} c \cdot \mathcal{L}(f(\mathbf{x}'), y) + ||\mathbf{x}' - \mathbf{x}||_2^2
\end{equation}

\subsection{Perturbation-Based Testing}

Para domínios não-adversariais (tabular, regressão), perturbações naturais são mais relevantes:

\textbf{Gaussian Noise}: Adiciona ruído proporcional ao desvio padrão:
\begin{equation}
x'_i = x_i + \epsilon \cdot \sigma_i \cdot \mathcal{N}(0, 1)
\end{equation}

\textbf{Quantile-Based}: Perturba baseado em quantis da distribuição:
\begin{equation}
x'_i = x_i + \epsilon \cdot (Q_{75}(X_i) - Q_{25}(X_i))
\end{equation}

O \textbf{DeepBridge RobustnessSuite} implementa múltiplos níveis de perturbação ($\epsilon \in \{0.1, 0.2, 0.4, 0.6, 0.8, 1.0\}$) e calcula:
\begin{itemize}
    \item \textbf{Impact Score}: $(score_{base} - score_{perturbed}) / score_{base}$
    \item \textbf{Robustness Score}: $1.0 - \text{mean}(\text{impact scores})$
    \item \textbf{Worst-case Degradation}: $\max_{\epsilon}(\text{impact}_\epsilon)$
\end{itemize}

\subsection{Weakspot Detection}

Identifica regiões do espaço de features onde o modelo é particularmente vulnerável:

\textbf{Slice-Based Analysis}: Divide features em slices (uniform, quantile, tree-based) e identifica aqueles com degradação $> 15\%$~\cite{chung2019}.

\textbf{Exemplo}: Em um modelo de credit scoring, weakspots podem aparecer em "idade < 25 AND income < 30k" — uma região onde perturbações de 0.2 causam degradação de 25\%.

\subsection{Overfitting Localizado}

Detecta regiões onde o modelo memoriza dados de treino mas generaliza mal:

\textbf{Train-Test Gap por Slice}:
\begin{equation}
\text{Gap}(s) = \text{Score}_{\text{train}}(s) - \text{Score}_{\text{test}}(s)
\end{equation}

Gaps $> 0.1$ indicam overfitting localizado, mesmo quando métricas globais parecem adequadas.

\subsection{Ferramentas}

\begin{itemize}
    \item \textbf{CleverHans}~\cite{papernot2018}: TensorFlow/PyTorch, foco em ataques adversariais (FGSM, PGD, C\&W).
    \item \textbf{Foolbox}~\cite{rauber2017}: Framework agnóstico com 30+ ataques.
    \item \textbf{ART} (Adversarial Robustness Toolbox): IBM, suporta defesas além de ataques.
    \item \textbf{TextAttack}~\cite{morris2020}: Especializado em NLP.
    \item \textbf{DeepBridge}: Dados tabulares, weakspot detection, overfitting analysis.
\end{itemize}

\subsection{Métricas e Interpretação}

\begin{table}[h]
\centering
\caption{Métricas de Robustez}
\label{tab:robustness_metrics}
\begin{tabular}{@{}lll@{}}
\toprule
\textbf{Métrica} & \textbf{Fórmula} & \textbf{Interpretação} \\ \midrule
Impact Score & $(S_0 - S_\epsilon)/S_0$ & Degradação relativa \\
Robustness Score & $1 - \bar{I}$ & Robustez agregada \\
Worst-case & $\max_\epsilon I_\epsilon$ & Pior cenário \\
Feature Sensitivity & $\text{std}(I_i)$ & Importância por feature \\ \bottomrule
\end{tabular}
\end{table}

\textbf{Case Study}: Em diagnóstico de câncer, perturbações Gaussian de $\epsilon=0.2$ causaram degradação média de 12\%, com worst-case de 28\% em imagens de baixa resolução.

\section{Uncertainty Quantification: Técnicas e Aplicações}
\label{sec:uncertainty}

Quantificação de incerteza (UQ) mede a confiança que o modelo tem em suas predições. Sistemas críticos (medicina, finanças) requerem não apenas predições mas intervalos de confiança calibrados.

\subsection{Tipos de Incerteza}

\textbf{Aleatoric (Data Uncertainty)}: Inerente aos dados (ruído, ambiguidade). Não reduz com mais dados.

\textbf{Epistemic (Model Uncertainty)}: Relacionada ao conhecimento limitado do modelo. Reduz com mais dados ou modelos melhores.

\subsection{Métodos Bayesianos}

\textbf{Bayesian Neural Networks (BNNs)}~\cite{mackay1992}: Distribuição sobre pesos:
\begin{equation}
p(w | \mathcal{D}) = \frac{p(\mathcal{D} | w) p(w)}{p(\mathcal{D})}
\end{equation}

Predição:
\begin{equation}
p(y | \mathbf{x}, \mathcal{D}) = \int p(y | \mathbf{x}, w) p(w | \mathcal{D}) dw
\end{equation}

\textbf{Monte Carlo Dropout (MC Dropout)}~\cite{gal2016}: Aproximação de BNN via dropout em inferência:
\begin{equation}
\mathbb{E}[y | \mathbf{x}] \approx \frac{1}{T} \sum_{t=1}^T f(\mathbf{x}; \theta_t)
\end{equation}
onde $\theta_t$ são pesos com dropout.

\subsection{Ensemble Methods}

\textbf{Deep Ensembles}~\cite{lakshminarayanan2017}: Treina $M$ redes independentes:
\begin{equation}
\mu(\mathbf{x}) = \frac{1}{M} \sum_{m=1}^M f_m(\mathbf{x}), \quad \sigma^2(\mathbf{x}) = \frac{1}{M} \sum_{m=1}^M (f_m(\mathbf{x}) - \mu(\mathbf{x}))^2
\end{equation}

Vantagens: Simples, eficaz, sem modificações arquiteturais. Desvantagem: $M \times$ custo computacional.

\subsection{Conformal Prediction}

Fornece intervalos de predição com \textbf{cobertura garantida} independente do modelo:

\textbf{CRQR} (Conformalized Quantile Regression)~\cite{romano2019}:
\begin{enumerate}
    \item Treinar modelo quantílico ($\hat{q}_\alpha, \hat{q}_{1-\alpha}$) em dados de treino.
    \item Calcular resíduos não-conformes em dados de calibração:
    \begin{equation}
    R_i = \max(\hat{q}_\alpha(\mathbf{x}_i) - y_i, y_i - \hat{q}_{1-\alpha}(\mathbf{x}_i))
    \end{equation}
    \item Quantil de correção: $\hat{q} = \text{Quantile}_{1-\alpha}(R)$
    \item Intervalo final: $[\hat{q}_\alpha(\mathbf{x}) - \hat{q}, \hat{q}_{1-\alpha}(\mathbf{x}) + \hat{q}]$
\end{enumerate}

\textbf{Garantia}: $\mathbb{P}(y \in C(\mathbf{x})) \geq 1 - \alpha$ para dados i.i.d.

O \textbf{DeepBridge UncertaintySuite} usa CRQR com split 40-20-40 (train-calib-test) e testa múltiplos alphas ($\alpha \in \{0.05, 0.1, 0.2\}$).

\subsection{Métricas}

\begin{itemize}
    \item \textbf{Coverage}: $\frac{1}{N} \sum_{i=1}^N \mathbb{1}[y_i \in C(\mathbf{x}_i)]$ (deve ser $\geq 1-\alpha$)
    \item \textbf{Mean Width}: $\frac{1}{N} \sum_{i=1}^N (C_{upper}(\mathbf{x}_i) - C_{lower}(\mathbf{x}_i))$
    \item \textbf{Coverage Error}: $|\text{Coverage} - (1-\alpha)|$
    \item \textbf{Uncertainty Quality}: $0.7 \times \text{CoverageScore} + 0.3 \times \text{WidthScore}$
\end{itemize}

\subsection{Aplicações}

\begin{itemize}
    \item \textbf{Medicina}: Diagnóstico com intervalos de confiança — "probabilidade de câncer: 85\% [72\%, 94\%]".
    \item \textbf{Finanças}: Estimativa de risco com quantificação de incerteza em previsões de default.
    \item \textbf{Sistemas Autônomos}: Decisões safety-critical requerem alta confiança ou fallback a operador humano.
\end{itemize}

\textbf{Case Study}: Credit scoring com CRQR ($\alpha=0.1$) obteve 92\% coverage (esperado: 90\%) com largura média de 0.15, permitindo decisões informadas em casos limítrofes.

\subsection{Ferramentas}

\begin{itemize}
    \item \textbf{TensorFlow Probability}: BNNs, variational inference.
    \item \textbf{Pyro/NumPyro}: Programação probabilística.
    \item \textbf{Uncertainty Quantification 360} (IBM): Conformal prediction, calibration.
    \item \textbf{MAPIE}: Conformal prediction para scikit-learn.
    \item \textbf{DeepBridge}: CRQR para regressão, calibration para classificação.
\end{itemize}

\section{Resilience and Drift Detection}
\label{sec:resilience}

Resiliência refere-se à capacidade do modelo manter performance quando a distribuição dos dados muda ao longo do tempo (concept drift, covariate drift). Modelos não-resilientes degradam silenciosamente em produção.

\subsection{Tipos de Drift}

\textbf{Covariate Drift}: $P(X)$ muda mas $P(Y|X)$ permanece:
\begin{equation}
P_{train}(X) \neq P_{prod}(X), \quad P_{train}(Y|X) = P_{prod}(Y|X)
\end{equation}

Exemplo: Modelo de fraude treinado em transações de verão, deployed no inverno (padrões de compra mudam).

\textbf{Concept Drift}: $P(Y|X)$ muda (relação input-output):
\begin{equation}
P_{train}(Y|X) \neq P_{prod}(Y|X)
\end{equation}

Exemplo: Modelo de credit scoring onde correlação entre income e default muda durante recessão econômica.

\textbf{Label Drift}: $P(Y)$ muda:
\begin{equation}
P_{train}(Y) \neq P_{prod}(Y)
\end{equation}

Exemplo: Taxa de fraudes sobe de 1\% para 5\%.

\textbf{Prior Drift}: Mudança na distribuição conjunta $P(X, Y)$.

\subsection{Métodos de Detecção}

\textbf{Population Stability Index (PSI)}~\cite{siddiqi2006}: Mede covariate drift:
\begin{equation}
\text{PSI} = \sum_{i=1}^n (P_{prod}(X \in B_i) - P_{train}(X \in B_i)) \ln \frac{P_{prod}(X \in B_i)}{P_{train}(X \in B_i)}
\end{equation}

Interpretação: PSI < 0.1 (estável), 0.1-0.25 (moderado), > 0.25 (drift significativo).

\textbf{Kolmogorov-Smirnov (KS) Test}: Testa diferença entre distribuições:
\begin{equation}
D_{KS} = \sup_x |F_{train}(x) - F_{prod}(x)|
\end{equation}

p-value < 0.05 indica drift significativo.

\textbf{Wasserstein Distance (Earth Mover's Distance)}:
\begin{equation}
W_1(P, Q) = \inf_{\gamma \in \Gamma(P,Q)} \mathbb{E}_{(x,y) \sim \gamma} [||x - y||]
\end{equation}

Mais sensível que KS para mudanças sutis.

\textbf{Performance Degradation Monitoring}: Rastreia métricas ao longo do tempo:
\begin{equation}
\Delta_{\text{perf}} = \text{Score}_{\text{week}_t} - \text{Score}_{\text{baseline}}
\end{equation}

Alerta se $\Delta_{\text{perf}} < -0.05$ (degradação de 5\%).

\subsection{DeepBridge ResilienceSuite}

Implementa cinco análises complementares:

\textbf{1. Distribution Shift Analysis}: Compara worst-performing samples vs. restante usando PSI, KS, WD1, KL, CM.

\textbf{2. Worst Sample Analysis}: Identifica top-k samples com maior erro, analisa características.

\textbf{3. Worst Cluster Analysis}: K-means clustering, identifica cluster com pior performance, calcula feature distances.

\textbf{4. Outer Sample Detection}: Isolation Forest/LOF para detectar outliers, avalia performance nesses casos.

\textbf{5. Hard Sample Analysis}: Requer ensemble — samples com alta variância de predição entre modelos.

\textbf{Resilience Score}:
\begin{equation}
\text{ResilienceScore} = 1.0 - \frac{1}{5} \sum_{i=1}^5 \text{PerformanceGap}_i
\end{equation}

\subsection{Estratégias de Mitigação}

\begin{itemize}
    \item \textbf{Periodic Retraining}: Retreinar modelo mensalmente ou quando PSI > 0.1.
    \item \textbf{Ensemble Updates}: Adicionar novos modelos ao ensemble, remover antigos.
    \item \textbf{Domain Adaptation}: Transfer learning para adaptar a nova distribuição.
    \item \textbf{Online Learning}: Atualização contínua com dados novos (SGD online).
\end{itemize}

\subsection{Ferramentas}

\begin{itemize}
    \item \textbf{Alibi Detect}: Drift detection (KS, MMD, LSDD) para tabular, imagem, texto.
    \item \textbf{Evidently AI}: Dashboards de monitoramento, relatórios de drift.
    \item \textbf{NannyML}: Monitoramento sem labels (performance estimation).
    \item \textbf{Frouros}: Biblioteca Python focada em drift detection.
    \item \textbf{DeepBridge}: Resilience suite com 5 análises e múltiplas métricas de drift.
\end{itemize}

\textbf{Case Study}: Modelo de hiring apresentou PSI=0.08 (estável) nos primeiros 6 meses, mas PSI=0.23 no mês 12 devido a mudança no perfil de candidatos. Retraining restaurou performance.

\section{Fairness and Bias Testing}
\label{sec:fairness}

Fairness em ML refere-se à ausência de discriminação injusta baseada em atributos protegidos como raça, gênero, idade, religião. É tanto uma questão ética quanto legal, com regulações como EEOC (EUA), GDPR (EU) e LGPD (Brasil) impondo requisitos de equidade.

\subsection{Frameworks Regulatórios}

\textbf{EEOC Title VII}~\cite{eeoc1978}: Proíbe discriminação em emprego. \textit{Four-fifths rule}: Taxa de seleção de grupo protegido deve ser $\geq 80\%$ do grupo de referência:
\begin{equation}
\frac{P(\hat{Y}=1 | A=a)}{P(\hat{Y}=1 | A=b)} \geq 0.80
\end{equation}

\textbf{ECOA Regulation B}~\cite{ecoa1974}: Proíbe discriminação em crédito baseada em raça, gênero, estado civil, idade.

\textbf{GDPR Article 22}: Direito a não ser sujeito a decisões automatizadas com efeitos legais significativos sem intervenção humana.

\subsection{Métricas Pré-Treinamento}

Avaliam viés nos dados antes do treinamento:

\textbf{Class Balance (BCL)}:
\begin{equation}
\text{BCL} = \frac{n_a - n_b}{n_{total}}
\end{equation}

\textbf{Concept Balance (BCO)}:
\begin{equation}
\text{BCO} = P(Y=1 | A=a) - P(Y=1 | A=b)
\end{equation}

\textbf{KL Divergence}:
\begin{equation}
D_{KL}(P_a || P_b) = \sum_y P_a(Y=y) \log \frac{P_a(Y=y)}{P_b(Y=y)}
\end{equation}

\textbf{JS Divergence} (simétrica):
\begin{equation}
D_{JS}(P_a || P_b) = \frac{1}{2} D_{KL}(P_a || M) + \frac{1}{2} D_{KL}(P_b || M), \quad M = \frac{P_a + P_b}{2}
\end{equation}

\subsection{Métricas Pós-Treinamento}

Avaliam viés nas predições do modelo:

\textbf{Statistical Parity (Demographic Parity)}:
\begin{equation}
P(\hat{Y}=1 | A=a) = P(\hat{Y}=1 | A=b)
\end{equation}

\textbf{Equal Opportunity}:
\begin{equation}
P(\hat{Y}=1 | Y=1, A=a) = P(\hat{Y}=1 | Y=1, A=b) \quad (\text{TPR equality})
\end{equation}

\textbf{Equalized Odds}:
\begin{equation}
\begin{aligned}
P(\hat{Y}=1 | Y=1, A=a) &= P(\hat{Y}=1 | Y=1, A=b) \\
P(\hat{Y}=1 | Y=0, A=a) &= P(\hat{Y}=1 | Y=0, A=b)
\end{aligned}
\end{equation}

\textbf{Disparate Impact} (EEOC 80\% rule):
\begin{equation}
\text{DI} = \frac{P(\hat{Y}=1 | A=\text{unprivileged})}{P(\hat{Y}=1 | A=\text{privileged})} \geq 0.80
\end{equation}

\textbf{Conditional Acceptance (PPV Parity)}:
\begin{equation}
P(Y=1 | \hat{Y}=1, A=a) = P(Y=1 | \hat{Y}=1, A=b)
\end{equation}

\subsection{Impossibilidade e Trade-offs}

\textbf{Teorema da Impossibilidade}~\cite{kleinberg2017}: Exceto em casos triviais, é impossível satisfazer simultaneamente:
\begin{itemize}
    \item Calibration: $P(Y=1 | \hat{S}=s, A=a) = P(Y=1 | \hat{S}=s, A=b)$
    \item Equal Opportunity
    \item Predictive Parity
\end{itemize}

Trade-off fundamental: \textbf{Fairness vs. Accuracy}. Intervenções de fairness tipicamente reduzem acurácia em 1-5\%~\cite{corbettdavies2018}.

\subsection{DeepBridge FairnessSuite}

Implementa 15 métricas (4 pre + 11 post):

\textbf{Features Especiais}:
\begin{itemize}
    \item \textbf{Age Grouping Automático}: Detecta variáveis de idade, agrupa segundo ADEA (< 40, 40-49, 50-59, 60+) ou ECOA (18-29, 30-39, ...).
    \item \textbf{Threshold Optimization}: Testa 99 thresholds (0.01-0.99), otimiza para fairness, F1 ou balanceado.
    \item \textbf{Confusion Matrix por Grupo}: TP, FP, TN, FN detalhado para cada grupo demográfico.
    \item \textbf{Filtro de Representatividade}: Exclui grupos com < 2\% da população (EEOC guideline).
\end{itemize}

\textbf{Compliance Score}:
\begin{equation}
\text{FairnessScore} = \frac{\sum w_i \cdot \mathbb{1}[\text{metric}_i \text{ passes}]}{\sum w_i}
\end{equation}
onde $w_{\text{CRITICAL}} = 3$, $w_{\text{HIGH}} = 2$, $w_{\text{MEDIUM}} = 1$.

\subsection{Mitigation Techniques}

\textbf{Pre-processing}:
\begin{itemize}
    \item \textbf{Reweighting}: Aumentar peso de samples de grupos minoritários.
    \item \textbf{Resampling}: SMOTE em grupos sub-representados.
\end{itemize}

\textbf{In-processing}:
\begin{itemize}
    \item \textbf{Adversarial Debiasing}~\cite{zhang2018}: Treinar modelo com adversary que prediz atributo protegido — modelo aprende features invariantes.
    \item \textbf{Fairness Constraints}: Adicionar penalidade à loss:
    \begin{equation}
    \mathcal{L}_{\text{total}} = \mathcal{L}_{\text{task}} + \lambda \cdot \mathcal{L}_{\text{fairness}}
    \end{equation}
\end{itemize}

\textbf{Post-processing}:
\begin{itemize}
    \item \textbf{Threshold Optimization}: Diferentes thresholds por grupo para equalizar TPR.
    \item \textbf{Calibration}: Ajustar scores para garantir calibration por grupo.
\end{itemize}

\subsection{Ferramentas}

\begin{itemize}
    \item \textbf{AIF360}~\cite{bellamy2019}: IBM, 70+ fairness metrics, 10+ mitigation algorithms.
    \item \textbf{Fairlearn}~\cite{bird2020}: Microsoft, integração scikit-learn, threshold optimization, reductions approach.
    \item \textbf{Aequitas}: Center for Data Science and Public Policy, foco em justiça criminal.
    \item \textbf{What-If Tool}: Google, interface visual para exploração de fairness.
    \item \textbf{DeepBridge}: 15 métricas, compliance scoring EEOC/ECOA, age grouping automático.
\end{itemize}

\textbf{Case Study}: Resume screening apresentou Disparate Impact de 0.72 (raça) e 0.76 (gênero) — violações EEOC. Threshold optimization + reweighting elevou para 0.83 e 0.82, com perda de F1 de 0.76 → 0.74 (2.6\%).

\section{Hyperparameter Analysis}
\label{sec:hyperparameter}

Hiperparâmetros controlam o processo de aprendizado mas não são aprendidos dos dados (learning rate, regularização, profundidade de árvore). Configuração inadequada causa underfitting ou overfitting. Análise de importância guia otimização eficiente.

\subsection{Métodos de Otimização}

\textbf{Grid Search}: Busca exaustiva em grade pré-definida:
\begin{itemize}
    \item \textbf{Vantagens}: Simples, determinístico, reprodutível.
    \item \textbf{Desvantagens}: Custo exponencial $O(k^d)$ para $k$ valores e $d$ hiperparâmetros.
\end{itemize}

\textbf{Random Search}~\cite{bergstra2012}: Amostragem aleatória do espaço:
\begin{itemize}
    \item \textbf{Vantagens}: Mais eficiente que grid quando poucos hiperparâmetros são importantes.
    \item \textbf{Resultado Teórico}: Com alta probabilidade, encontra configuração próxima ao ótimo com $60\%$ menos trials.
\end{itemize}

\textbf{Bayesian Optimization}~\cite{snoek2012}: Usa Gaussian Processes para modelar função objetivo:
\begin{equation}
\theta^* = \arg\max_\theta \alpha(\theta | \mathcal{D})
\end{equation}
onde $\alpha$ é acquisition function (EI, UCB, PI).

\textbf{Tree-structured Parzen Estimator (TPE)}~\cite{bergstra2011}: Modela $P(\theta | y)$ via:
\begin{equation}
P(\theta | y) = \begin{cases}
\ell(\theta) & \text{if } y < y^* \\
g(\theta) & \text{if } y \geq y^*
\end{cases}
\end{equation}

\textbf{Hyperband}~\cite{li2017}: Combina random search com early stopping adaptativo.

\subsection{Análise de Importância}

Identificar hiperparâmetros mais importantes permite:
\begin{itemize}
    \item \textbf{Priorização}: Focar esforço em parâmetros críticos.
    \item \textbf{Redução de Dimensionalidade}: Fixar parâmetros irrelevantes.
    \item \textbf{Interpretabilidade}: Entender sensitividade do modelo.
\end{itemize}

\textbf{Functional ANOVA}~\cite{hutter2014}: Decomposição de variância:
\begin{equation}
\text{Importance}(\theta_i) = \frac{\mathbb{V}[\mathbb{E}[f | \theta_i]]}{\mathbb{V}[f]}
\end{equation}

\textbf{Subsampling-based} (DeepBridge):
\begin{enumerate}
    \item Criar $N$ subsamples dos dados.
    \item Para cada hiperparâmetro $\theta_i$, treinar modelos com diferentes valores mantendo outros fixos.
    \item Medir variação de performance:
    \begin{equation}
    \text{Importance}(\theta_i) = \text{std}(\text{scores}(\theta_i))
    \end{equation}
    \item Normalizar: $\sum \text{Importance}(\theta_i) = 1$.
\end{enumerate}

\subsection{DeepBridge HyperparameterSuite}

\textbf{Configuração}:
\begin{itemize}
    \item \textbf{Quick}: CV=3, 5 subsamples, 50\% size
    \item \textbf{Medium}: CV=5, 10 subsamples, 50\% size
    \item \textbf{Full}: CV=5, 20 subsamples @ 50\% + 10 subsamples @ 70\%
\end{itemize}

\textbf{Parameter Grids Padrão}:
\begin{itemize}
    \item \textbf{RandomForest}: \texttt{n\_estimators} [50, 100, 200], \texttt{max\_depth} [5, 10, 20, None], \texttt{min\_samples\_split} [2, 5, 10]
    \item \textbf{GradientBoosting}: \texttt{n\_estimators} [50, 100, 200], \texttt{learning\_rate} [0.01, 0.1, 0.3], \texttt{max\_depth} [3, 5, 7]
    \item \textbf{LogisticRegression}: \texttt{C} [0.01, 0.1, 1, 10], \texttt{penalty} [l1, l2], \texttt{solver} [liblinear, saga]
\end{itemize}

\textbf{Outputs}:
\begin{itemize}
    \item Raw importance scores
    \item Normalized importance (sum=1)
    \item Sorted ranking
    \item Tuning order recommendation
    \item Average performance per parameter value
\end{itemize}

\subsection{Ferramentas}

\begin{itemize}
    \item \textbf{Optuna}~\cite{akiba2019}: TPE, CMA-ES, pruning, visualizações interativas.
    \item \textbf{Ray Tune}: Integração com Ray, suporte distributed, ASHA scheduler.
    \item \textbf{Hyperopt}: TPE, random search, implementação original.
    \item \textbf{Scikit-Optimize}: Bayesian optimization para scikit-learn.
    \item \textbf{SMAC3}: Sequential Model-based Algorithm Configuration.
    \item \textbf{DeepBridge}: Subsampling-based importance, tuning recommendations.
\end{itemize}

\textbf{Case Study}: Random Forest para diagnóstico de câncer — \texttt{max\_depth} teve importance=0.45, \texttt{n\_estimators}=0.30, \texttt{min\_samples\_split}=0.15, \texttt{min\_samples\_leaf}=0.10. Otimizar apenas \texttt{max\_depth} e \texttt{n\_estimators} capturou 75\% do ganho potencial.

\section{Comparação de Ferramentas e Frameworks}
\label{sec:comparison}

Esta seção compara sistematicamente 15+ ferramentas de validação ML em critérios de cobertura, usabilidade, extensibilidade, performance e maturidade.

\subsection{Critérios de Avaliação}

\begin{enumerate}
    \item \textbf{Cobertura}: Quantas dimensões de validação são suportadas?
    \item \textbf{Usabilidade}: API intuitiva, documentação, exemplos?
    \item \textbf{Extensibilidade}: Facilidade de adicionar novos métodos?
    \item \textbf{Performance}: Tempo de execução, uso de memória?
    \item \textbf{Integração}: Compatibilidade com frameworks (scikit-learn, PyTorch, TF)?
    \item \textbf{Maturidade}: Comunidade ativa, manutenção, releases?
\end{enumerate}

\subsection{Matriz de Comparação}

\begin{table*}[t]
\centering
\caption{Comparação de Ferramentas de Validação ML}
\label{tab:tool_comparison}
\small
\begin{tabular}{@{}lccccccc@{}}
\toprule
\textbf{Framework} & \textbf{Rob} & \textbf{Unc} & \textbf{Res} & \textbf{Fair} & \textbf{HPO} & \textbf{Integrado} & \textbf{Maturidade} \\ \midrule
\textbf{DeepBridge} & \checkmark & \checkmark & \checkmark & \checkmark & \checkmark & Completo & Médio \\
AIF360 & $\times$ & $\times$ & $\times$ & \checkmark & $\times$ & Parcial & Alto \\
Fairlearn & $\times$ & $\times$ & $\times$ & \checkmark & $\times$ & sklearn & Alto \\
CleverHans & \checkmark & $\times$ & $\times$ & $\times$ & $\times$ & TF/PyTorch & Alto \\
Foolbox & \checkmark & $\times$ & $\times$ & $\times$ & $\times$ & Agnóstico & Alto \\
ART & \checkmark & $\times$ & $\times$ & $\times$ & $\times$ & Multi-FW & Alto \\
Alibi & \checkmark & \checkmark & \checkmark & $\times$ & $\times$ & Parcial & Médio \\
Alibi Detect & $\times$ & $\times$ & \checkmark & $\times$ & $\times$ & Agnóstico & Alto \\
Evidently AI & $\times$ & $\times$ & \checkmark & \checkmark & $\times$ & Parcial & Médio \\
NannyML & $\times$ & $\times$ & \checkmark & $\times$ & $\times$ & sklearn & Médio \\
Optuna & $\times$ & $\times$ & $\times$ & $\times$ & \checkmark & Agnóstico & Alto \\
Ray Tune & $\times$ & $\times$ & $\times$ & $\times$ & \checkmark & Ray & Alto \\
TF Model Analysis & $\times$ & $\times$ & \checkmark & \checkmark & $\times$ & TensorFlow & Alto \\
UQ360 & $\times$ & \checkmark & $\times$ & $\times$ & $\times$ & sklearn & Médio \\
MAPIE & $\times$ & \checkmark & $\times$ & $\times$ & $\times$ & sklearn & Médio \\
\bottomrule
\end{tabular}
\end{table*}

\subsection{Análise por Dimensão}

\textbf{Robustez}:
\begin{itemize}
    \item \textbf{Líderes}: CleverHans (deep learning adversarial), Foolbox (agnóstico), ART (defesas).
    \item \textbf{Gap}: Falta suporte para dados tabulares (maioria foca em imagens).
    \item \textbf{DeepBridge}: Preenche gap com perturbation testing, weakspot detection para tabular.
\end{itemize}

\textbf{Incerteza}:
\begin{itemize}
    \item \textbf{Líderes}: UQ360 (conformal), MAPIE (conformal sklearn), Alibi (multiple methods).
    \item \textbf{Gap}: Poucas ferramentas integram múltiplas abordagens (Bayesian, ensemble, conformal).
    \item \textbf{DeepBridge}: CRQR como método principal, suporte para calibration.
\end{itemize}

\textbf{Resiliência}:
\begin{itemize}
    \item \textbf{Líderes}: Alibi Detect (KS, MMD), Evidently (dashboards), NannyML (performance estimation).
    \item \textbf{Gap}: Integração limitada com mitigation strategies.
    \item \textbf{DeepBridge}: 5 análises complementares (worst samples, clusters, outer samples, etc.).
\end{itemize}

\textbf{Fairness}:
\begin{itemize}
    \item \textbf{Líderes}: AIF360 (70+ metrics, 10+ mitigations), Fairlearn (sklearn, threshold optimization).
    \item \textbf{Gap}: Tradução de requisitos regulatórios (EEOC, ECOA) em testes automatizados.
    \item \textbf{DeepBridge}: 15 métricas + compliance scoring + age grouping EEOC/ECOA.
\end{itemize}

\textbf{HPO}:
\begin{itemize}
    \item \textbf{Líderes}: Optuna (TPE, visualizações), Ray Tune (distributed, ASHA).
    \item \textbf{Gap}: Análise de importância além de otimização.
    \item \textbf{DeepBridge}: Subsampling-based importance, tuning order recommendations.
\end{itemize}

\subsection{Recomendações}

\begin{itemize}
    \item \textbf{Deep Learning Adversarial}: CleverHans, Foolbox, ART.
    \item \textbf{Fairness em Produção}: AIF360, Fairlearn.
    \item \textbf{Drift Monitoring}: Alibi Detect, Evidently AI.
    \item \textbf{HPO Distributed}: Ray Tune, Optuna (com Ray).
    \item \textbf{Validação Integrada}: DeepBridge (cobertura completa), Alibi (parcial).
\end{itemize}

\section{Desafios Abertos e Direções Futuras}
\label{sec:challenges}

Apesar dos avanços significativos, a validação ML enfrenta desafios técnicos, de deployment e regulatórios que definem a agenda de pesquisa futura.

\subsection{Desafios Técnicos}

\textbf{1. Validação de Foundation Models (LLMs, VLMs)}:
\begin{itemize}
    \item \textbf{Problema}: LLMs (GPT-4, PaLM) com bilhões de parâmetros e datasets massivos desafiam métodos tradicionais.
    \item \textbf{Lacunas}: Robustez a prompts adversariais, quantificação de incerteza em geração de texto, fairness em contextos multiculturais.
    \item \textbf{Direção}: Prompt-based robustness testing, conformal prediction para sequências, multilingual fairness benchmarks.
\end{itemize}

\textbf{2. Fairness Interseccional}:
\begin{itemize}
    \item \textbf{Problema}: Métricas atuais avaliam um atributo por vez (raça OR gênero), não combinações (raça AND gênero AND idade).
    \item \textbf{Exemplo}: Mulheres negras idosas podem sofrer discriminação não capturada por análises univariadas.
    \item \textbf{Direção}: Métricas multidimensionais, clustering de subgrupos, abordagens causais~\cite{kusner2017}.
\end{itemize}

\textbf{3. Robustez Certificada}:
\begin{itemize}
    \item \textbf{Problema}: Métodos empíricos testam perturbações finitas — não garantem robustez universal.
    \item \textbf{Direção}: Formal verification (SMT solvers)~\cite{katz2017}, randomized smoothing~\cite{cohen2019}, certified training.
\end{itemize}

\textbf{4. Uncertainty em Deep Learning}:
\begin{itemize}
    \item \textbf{Problema}: DNNs são notoriamente mal-calibrados (high confidence em predições incorretas)~\cite{guo2017}.
    \item \textbf{Direção}: Temperature scaling, mixup training, evidential deep learning~\cite{sensoy2018}.
\end{itemize}

\textbf{5. Drift em High-Dimensional Spaces}:
\begin{itemize}
    \item \textbf{Problema}: Curse of dimensionality — testes estatísticos perdem poder em $d > 100$.
    \item \textbf{Direção}: Dimensionality reduction (PCA, autoencoders), learned representations, context-based drift~\cite{dasu2006}.
\end{itemize}

\subsection{Desafios de Deployment}

\textbf{6. Validação Contínua em Produção}:
\begin{itemize}
    \item \textbf{Problema}: Validação é tipicamente one-time pre-deployment — modelos degradam silenciosamente.
    \item \textbf{Direção}: Continuous testing pipelines, automated retraining triggers, shadow deployments.
\end{itemize}

\textbf{7. Monitoring em Tempo Real}:
\begin{itemize}
    \item \textbf{Problema}: Métricas de validação são computacionalmente caras — incompatíveis com latência de produção.
    \item \textbf{Direção}: Lightweight proxies, sampling strategies, approximate drift detection.
\end{itemize}

\textbf{8. Explicabilidade de Falhas}:
\begin{itemize}
    \item \textbf{Problema}: Teste falha mas não explica por quê ou como mitigar.
    \item \textbf{Direção}: Integração com XAI (SHAP, LIME), counterfactual explanations, debugging tools.
\end{itemize}

\subsection{Desafios Regulatórios e Éticos}

\textbf{9. Padronização de Métricas}:
\begin{itemize}
    \item \textbf{Problema}: 20+ definições de fairness — reguladores e auditores precisam de padrões.
    \item \textbf{Direção}: IEEE P7003 (Algorithmic Bias), ISO/IEC standards, industry best practices.
\end{itemize}

\textbf{10. Trade-offs Automáticos}:
\begin{itemize}
    \item \textbf{Problema}: Otimizar accuracy-fairness-robustness é multi-objetivo complexo.
    \item \textbf{Direção}: Pareto optimization, preference elicitation, automated constraint satisfaction.
\end{itemize}

\subsection{Agenda de Pesquisa Futura}

\begin{enumerate}
    \item \textbf{Causal Fairness}: Usar causal inference para definir fairness baseada em counterfactuals~\cite{kusner2017}.
    \item \textbf{Domain Generalization}: Treinar modelos que generalizam para distribuições unseen~\cite{gulrajani2021}.
    \item \textbf{Uncertainty-aware Optimization}: HPO que considera não apenas performance média mas também incerteza.
    \item \textbf{Automated Remediation}: AutoML que detecta e corrige automaticamente falhas de validação.
    \item \textbf{Benchmarks Padronizados}: Datasets públicos com ground truth para robustez, drift, fairness.
\end{enumerate}

\section{Conclusão}
\label{sec:conclusion}

Este survey apresentou uma taxonomia unificada de validação de modelos de Machine Learning integrando cinco dimensões essenciais: robustez, incerteza, resiliência, equidade e análise de hiperparâmetros. Através da síntese de 100+ trabalhos científicos e comparação empírica de 15+ ferramentas, identificamos avanços significativos — adversarial robustness via PGD, conformal prediction com garantias de cobertura, drift detection com múltiplas métricas estatísticas, 15+ métricas de fairness cobrindo diferentes noções de equidade, e otimização Bayesiana para HPO — mas também lacunas críticas.

As ferramentas existentes são fragmentadas, cobrindo 1-2 dimensões isoladamente, com integração limitada a requisitos regulatórios (EEOC, ECOA, GDPR) e suporte inadequado para deployment contínuo em produção. O framework DeepBridge, apresentado como implementação de referência, demonstra a viabilidade de integração completa através de cinco suites especializadas com API unificada, processando validação abrangente em 3 case studies de domínios críticos.

Os desafios futuros são tanto técnicos — validação de foundation models, fairness interseccional, robustez certificada — quanto operacionais — monitoramento em tempo real, explicabilidade de falhas, padronização de métricas. A comunidade deve priorizar: (1) desenvolvimento de benchmarks padronizados, (2) tradução de requisitos regulatórios em testes automatizados, (3) ferramentas de validação contínua em produção, e (4) métodos de otimização multi-objetivo para trade-offs automáticos.

A validação multidimensional não é apenas uma necessidade técnica mas um imperativo ético e legal. À medida que sistemas ML permeiam decisões críticas em saúde, justiça e finanças, a comunidade científica tem a responsabilidade de desenvolver e disseminar práticas de validação que garantam não apenas alta acurácia, mas confiabilidade, equidade e resiliência. Este survey serve como guia prático para pesquisadores e profissionais comprometidos com essa missão.

\section*{Agradecimentos}

[A definir]

\bibliographystyle{IEEEtran}
\bibliography{references}

\end{document}
