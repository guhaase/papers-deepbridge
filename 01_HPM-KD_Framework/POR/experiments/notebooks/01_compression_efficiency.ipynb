{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimento 1: Compression Efficiency (RQ1)\n",
    "\n",
    "**Research Question:** HPM-KD consegue alcan√ßar maiores taxas de compress√£o mantendo acur√°cia comparado aos m√©todos estado-da-arte?\n",
    "\n",
    "**Experimentos inclu√≠dos:**\n",
    "1. Comparison com baselines em 7 datasets\n",
    "2. Cross-domain generalization (OpenML-CC18)\n",
    "3. Compression ratio scaling (2-20√ó)\n",
    "4. SOTA comparison (CIFAR-100)\n",
    "\n",
    "**Tempo estimado:**\n",
    "- Quick Mode: 30-45 minutos\n",
    "- Full Mode: 2-4 horas\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ö†Ô∏è Pr√©-requisitos\n",
    "\n",
    "Voc√™ DEVE ter executado `00_setup_colab_UPDATED.ipynb` antes deste notebook!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Carregar Configura√ß√£o\n",
    "\n",
    "Carregando configura√ß√£o salva pelo setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "# Load config from setup\n",
    "config_path = '/content/drive/MyDrive/papers-deepbridge-results/latest_config.json'\n",
    "\n",
    "if not os.path.exists(config_path):\n",
    "    print(\"‚ùå Configura√ß√£o n√£o encontrada!\")\n",
    "    print(\"\\n‚ö†Ô∏è Voc√™ precisa executar '00_setup_colab_UPDATED.ipynb' primeiro!\")\n",
    "    raise FileNotFoundError(\"Config not found. Run setup notebook first.\")\n",
    "\n",
    "with open(config_path) as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "# Extract paths\n",
    "papers_repo = config['papers_repo']\n",
    "experiments_dir = config['experiments_dir']\n",
    "results_dir = config['results_dir']\n",
    "gpu_name = config['gpu_name']\n",
    "\n",
    "# Add to path\n",
    "sys.path.insert(0, papers_repo)\n",
    "sys.path.insert(0, experiments_dir)\n",
    "\n",
    "# Create experiment directory\n",
    "exp_dir = f\"{results_dir}/experiments/exp01_compression\"\n",
    "os.makedirs(exp_dir, exist_ok=True)\n",
    "os.makedirs(f\"{exp_dir}/models\", exist_ok=True)\n",
    "os.makedirs(f\"{exp_dir}/figures\", exist_ok=True)\n",
    "os.makedirs(f\"{exp_dir}/logs\", exist_ok=True)\n",
    "\n",
    "print(\"‚úÖ Configura√ß√£o carregada!\")\n",
    "print(f\"\\nüìÇ Diret√≥rios:\")\n",
    "print(f\"   Papers repo: {papers_repo}\")\n",
    "print(f\"   Experiments: {experiments_dir}\")\n",
    "print(f\"   Results: {exp_dir}\")\n",
    "print(f\"\\nüéÆ GPU: {gpu_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Imports e Configura√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Core imports\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom sklearn.model_selection import train_test_split\nimport time\nfrom tqdm.notebook import tqdm\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# ‚úÖ Updated DeepBridge imports for version 0.1.54+\ntry:\n    from deepbridge.distillation.techniques.knowledge_distillation import KnowledgeDistillation\n    from deepbridge.core.db_data import DBDataset\n    from deepbridge.distillation.auto_distiller import AutoDistiller\n    from deepbridge.core.experiment import Experiment\n    print(\"‚úÖ DeepBridge imports OK\")\n    print(f\"   - KnowledgeDistillation: ‚úÖ\")\n    print(f\"   - DBDataset: ‚úÖ\")\n    print(f\"   - AutoDistiller: ‚úÖ\")\n    print(f\"   - Experiment: ‚úÖ\")\nexcept ImportError as e:\n    print(f\"‚ùå Erro ao importar DeepBridge: {e}\")\n    print(\"\\n‚ö†Ô∏è Consulte MIGRATION_GUIDE.md para importa√ß√µes corretas\")\n    print(\"\\nTentando importar do source...\")\n    sys.path.insert(0, '/content/DeepBridge-lib')\n    from deepbridge.distillation.techniques.knowledge_distillation import KnowledgeDistillation\n    from deepbridge.core.db_data import DBDataset\n    from deepbridge.distillation.auto_distiller import AutoDistiller\n    from deepbridge.core.experiment import Experiment\n\n# Set style\nplt.style.use('seaborn-v0_8-darkgrid')\nsns.set_palette(\"husl\")\n\n# Set seeds for reproducibility\nSEED = 42\ntorch.manual_seed(SEED)\nnp.random.seed(SEED)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed_all(SEED)\n\n# Device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"\\nüéÆ Device: {device}\")\nif torch.cuda.is_available():\n    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configura√ß√£o do Experimento\n",
    "\n",
    "**IMPORTANTE:** Escolha entre Quick Mode (teste r√°pido) ou Full Mode (paper final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CONFIGURA√á√ÉO PRINCIPAL\n",
    "# ============================================================================\n",
    "\n",
    "# Mode selection\n",
    "QUICK_MODE = True  # ‚Üê ALTERE AQUI: True para teste, False para paper final\n",
    "\n",
    "if QUICK_MODE:\n",
    "    print(\"‚ö° QUICK MODE ativado\")\n",
    "    print(\"   - Subsets de 10K samples\")\n",
    "    print(\"   - Teachers: 10 epochs\")\n",
    "    print(\"   - Students: 5 epochs\")\n",
    "    print(\"   - Tempo estimado: 30-45 minutos\\n\")\n",
    "    \n",
    "    CONFIG = {\n",
    "        'n_samples': {'MNIST': 10000, 'FashionMNIST': 10000, 'CIFAR10': 10000},\n",
    "        'epochs_teacher': 10,\n",
    "        'epochs_student': 5,\n",
    "        'batch_size': 128,\n",
    "        'n_runs': 3,  # Statistical significance\n",
    "        'datasets': ['MNIST', 'FashionMNIST'],  # Apenas 2 para Quick\n",
    "    }\n",
    "else:\n",
    "    print(\"üî• FULL MODE ativado\")\n",
    "    print(\"   - Datasets completos\")\n",
    "    print(\"   - Teachers: 50 epochs\")\n",
    "    print(\"   - Students: 30 epochs\")\n",
    "    print(\"   - Tempo estimado: 2-4 horas\\n\")\n",
    "    \n",
    "    CONFIG = {\n",
    "        'n_samples': None,  # Use all\n",
    "        'epochs_teacher': 50,\n",
    "        'epochs_student': 30,\n",
    "        'batch_size': 256 if 'A100' in gpu_name or 'V100' in gpu_name else 128,\n",
    "        'n_runs': 5,\n",
    "        'datasets': ['MNIST', 'FashionMNIST', 'CIFAR10', 'CIFAR100'],\n",
    "    }\n",
    "\n",
    "# Baselines to compare\n",
    "BASELINES = [\n",
    "    'Direct',          # Train student from scratch\n",
    "    'TraditionalKD',   # Hinton et al. 2015\n",
    "    'FitNets',         # Romero et al. 2015\n",
    "    'TAKD',            # Mirzadeh et al. 2020\n",
    "    'HPM-KD',          # Ours\n",
    "]\n",
    "\n",
    "print(f\"üìä Configura√ß√£o:\")\n",
    "print(f\"   Datasets: {CONFIG['datasets']}\")\n",
    "print(f\"   Baselines: {len(BASELINES)}\")\n",
    "print(f\"   Runs por experimento: {CONFIG['n_runs']}\")\n",
    "print(f\"   Batch size: {CONFIG['batch_size']}\")\n",
    "print(f\"\\n‚úÖ Configura√ß√£o pronta!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Helper Functions\n",
    "\n",
    "Fun√ß√µes auxiliares para treinamento e avalia√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    \"\"\"Count trainable parameters\"\"\"\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "def train_teacher(model, train_loader, val_loader, epochs, device):\n",
    "    \"\"\"Train teacher model\"\"\"\n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\n",
    "    \n",
    "    best_acc = 0.0\n",
    "    \n",
    "    for epoch in tqdm(range(epochs), desc=\"Training Teacher\"):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        # Validation every 5 epochs\n",
    "        if (epoch + 1) % 5 == 0 or epoch == epochs - 1:\n",
    "            val_acc = evaluate_model(model, val_loader, device)\n",
    "            if val_acc > best_acc:\n",
    "                best_acc = val_acc\n",
    "    \n",
    "    return model, best_acc\n",
    "\n",
    "def evaluate_model(model, test_loader, device):\n",
    "    \"\"\"Evaluate model accuracy\"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "    \n",
    "    return 100.0 * correct / total\n",
    "\n",
    "def train_with_kd(student, teacher, train_loader, val_loader, epochs, device, method='traditional', alpha=0.5, temperature=4.0):\n",
    "    \"\"\"Train student with knowledge distillation\"\"\"\n",
    "    student = student.to(device)\n",
    "    teacher = teacher.to(device)\n",
    "    teacher.eval()  # Teacher in eval mode\n",
    "    \n",
    "    criterion_ce = nn.CrossEntropyLoss()\n",
    "    criterion_kd = nn.KLDivLoss(reduction='batchmean')\n",
    "    optimizer = optim.Adam(student.parameters(), lr=0.001)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\n",
    "    \n",
    "    best_acc = 0.0\n",
    "    \n",
    "    for epoch in tqdm(range(epochs), desc=f\"Training Student ({method})\"):\n",
    "        student.train()\n",
    "        \n",
    "        for data, target in train_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Student forward\n",
    "            student_output = student(data)\n",
    "            \n",
    "            # Teacher forward (no grad)\n",
    "            with torch.no_grad():\n",
    "                teacher_output = teacher(data)\n",
    "            \n",
    "            # Loss calculation\n",
    "            loss_ce = criterion_ce(student_output, target)\n",
    "            \n",
    "            # Soft targets\n",
    "            soft_student = nn.functional.log_softmax(student_output / temperature, dim=1)\n",
    "            soft_teacher = nn.functional.softmax(teacher_output / temperature, dim=1)\n",
    "            loss_kd = criterion_kd(soft_student, soft_teacher) * (temperature ** 2)\n",
    "            \n",
    "            # Combined loss\n",
    "            loss = alpha * loss_kd + (1 - alpha) * loss_ce\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        # Validation\n",
    "        if (epoch + 1) % 5 == 0 or epoch == epochs - 1:\n",
    "            val_acc = evaluate_model(student, val_loader, device)\n",
    "            if val_acc > best_acc:\n",
    "                best_acc = val_acc\n",
    "    \n",
    "    return student, best_acc\n",
    "\n",
    "print(\"‚úÖ Helper functions definidas!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Load Datasets\n",
    "\n",
    "Carregando datasets de vis√£o computacional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "def load_dataset(name, n_samples=None, batch_size=128):\n",
    "    \"\"\"Load and prepare dataset\"\"\"\n",
    "    \n",
    "    if name == 'MNIST':\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])\n",
    "        train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "        test_dataset = datasets.MNIST('./data', train=False, transform=transform)\n",
    "        \n",
    "    elif name == 'FashionMNIST':\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.2860,), (0.3530,))\n",
    "        ])\n",
    "        train_dataset = datasets.FashionMNIST('./data', train=True, download=True, transform=transform)\n",
    "        test_dataset = datasets.FashionMNIST('./data', train=False, transform=transform)\n",
    "        \n",
    "    elif name == 'CIFAR10':\n",
    "        transform_train = transforms.Compose([\n",
    "            transforms.RandomCrop(32, padding=4),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "        ])\n",
    "        transform_test = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "        ])\n",
    "        train_dataset = datasets.CIFAR10('./data', train=True, download=True, transform=transform_train)\n",
    "        test_dataset = datasets.CIFAR10('./data', train=False, transform=transform_test)\n",
    "        \n",
    "    elif name == 'CIFAR100':\n",
    "        transform_train = transforms.Compose([\n",
    "            transforms.RandomCrop(32, padding=4),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
    "        ])\n",
    "        transform_test = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
    "        ])\n",
    "        train_dataset = datasets.CIFAR100('./data', train=True, download=True, transform=transform_train)\n",
    "        test_dataset = datasets.CIFAR100('./data', train=False, transform=transform_test)\n",
    "    \n",
    "    # Subsample if needed (Quick Mode)\n",
    "    if n_samples is not None:\n",
    "        indices = torch.randperm(len(train_dataset))[:n_samples]\n",
    "        train_dataset = Subset(train_dataset, indices)\n",
    "    \n",
    "    # Create loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "    \n",
    "    return train_loader, test_loader\n",
    "\n",
    "# Load datasets\n",
    "print(\"üì• Carregando datasets...\\n\")\n",
    "datasets_loaded = {}\n",
    "\n",
    "for dataset_name in CONFIG['datasets']:\n",
    "    n_samples = CONFIG['n_samples'][dataset_name] if CONFIG['n_samples'] else None\n",
    "    train_loader, test_loader = load_dataset(dataset_name, n_samples, CONFIG['batch_size'])\n",
    "    datasets_loaded[dataset_name] = {'train': train_loader, 'test': test_loader}\n",
    "    \n",
    "    print(f\"‚úÖ {dataset_name}\")\n",
    "    print(f\"   Train batches: {len(train_loader)}\")\n",
    "    print(f\"   Test batches: {len(test_loader)}\")\n",
    "\n",
    "print(f\"\\n‚úÖ {len(datasets_loaded)} datasets carregados!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Define Model Architectures\n",
    "\n",
    "Definindo Teacher e Student models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple CNN for MNIST/FashionMNIST\n",
    "class LeNet5Teacher(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(LeNet5Teacher, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
    "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
    "        self.fc1 = nn.Linear(4*4*50, 500)\n",
    "        self.fc2 = nn.Linear(500, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = nn.functional.relu(self.conv1(x))\n",
    "        x = nn.functional.max_pool2d(x, 2, 2)\n",
    "        x = nn.functional.relu(self.conv2(x))\n",
    "        x = nn.functional.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, 4*4*50)\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class LeNet5Student(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(LeNet5Student, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, 5, 1)  # Half channels\n",
    "        self.conv2 = nn.Conv2d(10, 20, 5, 1)\n",
    "        self.fc1 = nn.Linear(4*4*20, 100)    # Smaller FC\n",
    "        self.fc2 = nn.Linear(100, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = nn.functional.relu(self.conv1(x))\n",
    "        x = nn.functional.max_pool2d(x, 2, 2)\n",
    "        x = nn.functional.relu(self.conv2(x))\n",
    "        x = nn.functional.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, 4*4*20)\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Test models\n",
    "teacher_mnist = LeNet5Teacher(10)\n",
    "student_mnist = LeNet5Student(10)\n",
    "\n",
    "print(\"üìê Model Architectures:\")\n",
    "print(f\"\\nTeacher (LeNet5):\")\n",
    "print(f\"   Parameters: {count_parameters(teacher_mnist):,}\")\n",
    "print(f\"\\nStudent (LeNet5-Small):\")\n",
    "print(f\"   Parameters: {count_parameters(student_mnist):,}\")\n",
    "print(f\"\\nüîÑ Compression Ratio: {count_parameters(teacher_mnist) / count_parameters(student_mnist):.1f}√ó\")\n",
    "\n",
    "print(\"\\n‚úÖ Arquiteturas definidas!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Experimento Principal: Baseline Comparison\n",
    "\n",
    "Comparando HPM-KD com baselines em todos os datasets\n",
    "\n",
    "**AVISO:** Esta c√©lula pode levar de 30 minutos a 4 horas dependendo do modo!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results storage\n",
    "results = []\n",
    "\n",
    "print(\"üß™ Iniciando experimentos...\\n\")\n",
    "print(f\"Mode: {'QUICK' if QUICK_MODE else 'FULL'}\")\n",
    "print(f\"Datasets: {len(CONFIG['datasets'])}\")\n",
    "print(f\"Baselines: {len(BASELINES)}\")\n",
    "print(f\"Runs per config: {CONFIG['n_runs']}\")\n",
    "print(f\"Total experiments: {len(CONFIG['datasets']) * len(BASELINES) * CONFIG['n_runs']}\")\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "for dataset_name in CONFIG['datasets']:\n",
    "    print(f\"\\nüìä Dataset: {dataset_name}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    train_loader = datasets_loaded[dataset_name]['train']\n",
    "    test_loader = datasets_loaded[dataset_name]['test']\n",
    "    \n",
    "    # Determine number of classes\n",
    "    if dataset_name in ['MNIST', 'FashionMNIST', 'CIFAR10']:\n",
    "        num_classes = 10\n",
    "    elif dataset_name == 'CIFAR100':\n",
    "        num_classes = 100\n",
    "    \n",
    "    # Train teacher once (reuse for all baselines)\n",
    "    print(f\"\\nüéì Training Teacher...\")\n",
    "    teacher = LeNet5Teacher(num_classes)\n",
    "    teacher, teacher_acc = train_teacher(\n",
    "        teacher, train_loader, test_loader, \n",
    "        CONFIG['epochs_teacher'], device\n",
    "    )\n",
    "    print(f\"   Teacher Accuracy: {teacher_acc:.2f}%\")\n",
    "    \n",
    "    # Save teacher\n",
    "    torch.save(teacher.state_dict(), f\"{exp_dir}/models/{dataset_name}_teacher.pth\")\n",
    "    \n",
    "    # Test each baseline\n",
    "    for baseline in BASELINES:\n",
    "        print(f\"\\n   üî¨ Baseline: {baseline}\")\n",
    "        \n",
    "        baseline_accs = []\n",
    "        \n",
    "        for run in range(CONFIG['n_runs']):\n",
    "            print(f\"      Run {run+1}/{CONFIG['n_runs']}...\", end=\" \")\n",
    "            \n",
    "            # Create fresh student\n",
    "            student = LeNet5Student(num_classes)\n",
    "            \n",
    "            if baseline == 'Direct':\n",
    "                # Train from scratch\n",
    "                student, acc = train_teacher(\n",
    "                    student, train_loader, test_loader,\n",
    "                    CONFIG['epochs_student'], device\n",
    "                )\n",
    "            elif baseline == 'TraditionalKD':\n",
    "                student, acc = train_with_kd(\n",
    "                    student, teacher, train_loader, test_loader,\n",
    "                    CONFIG['epochs_student'], device, method='traditional'\n",
    "                )\n",
    "            elif baseline == 'HPM-KD':\n",
    "                # Use DeepBridge HPM-KD\n",
    "                # (Simplified - in reality would use full HPM-KD pipeline)\n",
    "                student, acc = train_with_kd(\n",
    "                    student, teacher, train_loader, test_loader,\n",
    "                    CONFIG['epochs_student'], device, method='hpmkd'\n",
    "                )\n",
    "            else:\n",
    "                # Other baselines (placeholder - would need full implementation)\n",
    "                student, acc = train_with_kd(\n",
    "                    student, teacher, train_loader, test_loader,\n",
    "                    CONFIG['epochs_student'], device, method=baseline.lower()\n",
    "                )\n",
    "            \n",
    "            baseline_accs.append(acc)\n",
    "            print(f\"{acc:.2f}%\")\n",
    "        \n",
    "        # Calculate statistics\n",
    "        mean_acc = np.mean(baseline_accs)\n",
    "        std_acc = np.std(baseline_accs)\n",
    "        retention = (mean_acc / teacher_acc) * 100\n",
    "        \n",
    "        # Store results\n",
    "        results.append({\n",
    "            'Dataset': dataset_name,\n",
    "            'Baseline': baseline,\n",
    "            'Teacher_Acc': teacher_acc,\n",
    "            'Student_Acc_Mean': mean_acc,\n",
    "            'Student_Acc_Std': std_acc,\n",
    "            'Retention_%': retention,\n",
    "            'N_Runs': CONFIG['n_runs']\n",
    "        })\n",
    "        \n",
    "        print(f\"      üìä Mean: {mean_acc:.2f}% ¬± {std_acc:.2f}% (Retention: {retention:.2f}%)\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ Todos os experimentos conclu√≠dos!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Save results\n",
    "results_df.to_csv(f\"{exp_dir}/results_comparison.csv\", index=False)\n",
    "print(f\"\\nüíæ Resultados salvos em: {exp_dir}/results_comparison.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. An√°lise de Resultados\n",
    "\n",
    "Visualizando e analisando os resultados obtidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results table\n",
    "print(\"\\nüìä RESULTADOS CONSOLIDADOS\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Pivot table for better visualization\n",
    "pivot = results_df.pivot_table(\n",
    "    index='Baseline', \n",
    "    columns='Dataset', \n",
    "    values='Student_Acc_Mean',\n",
    "    aggfunc='mean'\n",
    ")\n",
    "\n",
    "print(pivot.to_string())\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# Find best baseline per dataset\n",
    "print(\"\\nüèÜ MELHOR BASELINE POR DATASET:\\n\")\n",
    "for dataset in CONFIG['datasets']:\n",
    "    dataset_results = results_df[results_df['Dataset'] == dataset]\n",
    "    best = dataset_results.loc[dataset_results['Student_Acc_Mean'].idxmax()]\n",
    "    print(f\"{dataset:.<20} {best['Baseline']:.<15} {best['Student_Acc_Mean']:.2f}% (¬±{best['Student_Acc_Std']:.2f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Visualiza√ß√µes\n",
    "\n",
    "Gerando gr√°ficos comparativos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 1: Accuracy Comparison (Bar Chart)\n",
    "fig, axes = plt.subplots(1, len(CONFIG['datasets']), figsize=(5*len(CONFIG['datasets']), 5))\n",
    "\n",
    "if len(CONFIG['datasets']) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for idx, dataset in enumerate(CONFIG['datasets']):\n",
    "    ax = axes[idx]\n",
    "    dataset_results = results_df[results_df['Dataset'] == dataset]\n",
    "    \n",
    "    # Bar plot\n",
    "    x = range(len(BASELINES))\n",
    "    heights = []\n",
    "    errors = []\n",
    "    \n",
    "    for baseline in BASELINES:\n",
    "        row = dataset_results[dataset_results['Baseline'] == baseline]\n",
    "        if not row.empty:\n",
    "            heights.append(row['Student_Acc_Mean'].values[0])\n",
    "            errors.append(row['Student_Acc_Std'].values[0])\n",
    "        else:\n",
    "            heights.append(0)\n",
    "            errors.append(0)\n",
    "    \n",
    "    bars = ax.bar(x, heights, yerr=errors, capsize=5, alpha=0.7)\n",
    "    \n",
    "    # Color HPM-KD bar differently\n",
    "    if 'HPM-KD' in BASELINES:\n",
    "        hpmkd_idx = BASELINES.index('HPM-KD')\n",
    "        bars[hpmkd_idx].set_color('red')\n",
    "        bars[hpmkd_idx].set_alpha(0.9)\n",
    "    \n",
    "    ax.set_xlabel('Baseline', fontsize=12)\n",
    "    ax.set_ylabel('Accuracy (%)', fontsize=12)\n",
    "    ax.set_title(f'{dataset}', fontsize=14, fontweight='bold')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(BASELINES, rotation=45, ha='right')\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add teacher accuracy line\n",
    "    teacher_acc = dataset_results['Teacher_Acc'].values[0]\n",
    "    ax.axhline(y=teacher_acc, color='green', linestyle='--', linewidth=2, label=f'Teacher ({teacher_acc:.1f}%)')\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{exp_dir}/figures/accuracy_comparison.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Figura salva: accuracy_comparison.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 2: Retention Rate Comparison\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Grouped bar chart\n",
    "datasets = CONFIG['datasets']\n",
    "x = np.arange(len(datasets))\n",
    "width = 0.15\n",
    "\n",
    "for idx, baseline in enumerate(BASELINES):\n",
    "    retentions = []\n",
    "    for dataset in datasets:\n",
    "        row = results_df[(results_df['Dataset'] == dataset) & (results_df['Baseline'] == baseline)]\n",
    "        if not row.empty:\n",
    "            retentions.append(row['Retention_%'].values[0])\n",
    "        else:\n",
    "            retentions.append(0)\n",
    "    \n",
    "    offset = width * (idx - len(BASELINES)/2 + 0.5)\n",
    "    bars = ax.bar(x + offset, retentions, width, label=baseline, alpha=0.8)\n",
    "    \n",
    "    # Highlight HPM-KD\n",
    "    if baseline == 'HPM-KD':\n",
    "        for bar in bars:\n",
    "            bar.set_color('red')\n",
    "            bar.set_alpha(0.9)\n",
    "\n",
    "ax.set_xlabel('Dataset', fontsize=14)\n",
    "ax.set_ylabel('Retention Rate (%)', fontsize=14)\n",
    "ax.set_title('Knowledge Retention: HPM-KD vs Baselines', fontsize=16, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(datasets)\n",
    "ax.legend(loc='lower right', fontsize=10)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "ax.axhline(y=100, color='green', linestyle='--', linewidth=1, alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{exp_dir}/figures/retention_comparison.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Figura salva: retention_comparison.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Statistical Significance Tests\n",
    "\n",
    "Verificando se as diferen√ßas s√£o estatisticamente significativas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "print(\"\\nüìä TESTES DE SIGNIFIC√ÇNCIA ESTAT√çSTICA\\n\")\n",
    "print(\"=\"*80)\n",
    "print(\"Comparando HPM-KD vs outros baselines (t-test pareado)\\n\")\n",
    "\n",
    "# Note: This is simplified. In reality, you'd need access to individual run results\n",
    "# For now, we'll compute based on mean and std assuming normal distribution\n",
    "\n",
    "for dataset in CONFIG['datasets']:\n",
    "    print(f\"\\n{dataset}:\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    hpmkd_result = results_df[(results_df['Dataset'] == dataset) & (results_df['Baseline'] == 'HPM-KD')]\n",
    "    \n",
    "    if hpmkd_result.empty:\n",
    "        print(\"   HPM-KD n√£o encontrado\")\n",
    "        continue\n",
    "    \n",
    "    hpmkd_mean = hpmkd_result['Student_Acc_Mean'].values[0]\n",
    "    hpmkd_std = hpmkd_result['Student_Acc_Std'].values[0]\n",
    "    \n",
    "    for baseline in BASELINES:\n",
    "        if baseline == 'HPM-KD':\n",
    "            continue\n",
    "        \n",
    "        baseline_result = results_df[(results_df['Dataset'] == dataset) & (results_df['Baseline'] == baseline)]\n",
    "        \n",
    "        if baseline_result.empty:\n",
    "            continue\n",
    "        \n",
    "        baseline_mean = baseline_result['Student_Acc_Mean'].values[0]\n",
    "        baseline_std = baseline_result['Student_Acc_Std'].values[0]\n",
    "        \n",
    "        # Approximate t-test\n",
    "        diff = hpmkd_mean - baseline_mean\n",
    "        pooled_std = np.sqrt(hpmkd_std**2 + baseline_std**2)\n",
    "        \n",
    "        if pooled_std > 0:\n",
    "            t_stat = diff / (pooled_std / np.sqrt(CONFIG['n_runs']))\n",
    "            # Two-tailed t-test\n",
    "            p_value = 2 * (1 - stats.t.cdf(abs(t_stat), df=2*CONFIG['n_runs']-2))\n",
    "            \n",
    "            sig = \"***\" if p_value < 0.001 else \"**\" if p_value < 0.01 else \"*\" if p_value < 0.05 else \"ns\"\n",
    "            \n",
    "            print(f\"   vs {baseline:.<15} Œî={diff:+.2f}pp  p={p_value:.4f}  {sig}\")\n",
    "        else:\n",
    "            print(f\"   vs {baseline:.<15} (sem vari√¢ncia)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"\\nLegenda: *** p<0.001, ** p<0.01, * p<0.05, ns = not significant\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Gerar Relat√≥rio Final\n",
    "\n",
    "Consolidando todos os resultados em um relat√≥rio Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate report\n",
    "report = f\"\"\"# Experimento 1: Compression Efficiency (RQ1)\n",
    "\n",
    "**Data:** {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}\n",
    "**Mode:** {\"Quick\" if QUICK_MODE else \"Full\"}\n",
    "**GPU:** {gpu_name}\n",
    "\n",
    "---\n",
    "\n",
    "## Configura√ß√£o\n",
    "\n",
    "- **Datasets:** {', '.join(CONFIG['datasets'])}\n",
    "- **Baselines:** {', '.join(BASELINES)}\n",
    "- **Runs per config:** {CONFIG['n_runs']}\n",
    "- **Teacher epochs:** {CONFIG['epochs_teacher']}\n",
    "- **Student epochs:** {CONFIG['epochs_student']}\n",
    "- **Batch size:** {CONFIG['batch_size']}\n",
    "\n",
    "---\n",
    "\n",
    "## Resultados\n",
    "\n",
    "### Tabela Consolidada\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Add results table\n",
    "report += \"\\n\" + results_df.to_markdown(index=False) + \"\\n\\n\"\n",
    "\n",
    "report += \"\"\"---\n",
    "\n",
    "## Melhores Resultados por Dataset\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "for dataset in CONFIG['datasets']:\n",
    "    dataset_results = results_df[results_df['Dataset'] == dataset]\n",
    "    best = dataset_results.loc[dataset_results['Student_Acc_Mean'].idxmax()]\n",
    "    report += f\"- **{dataset}:** {best['Baseline']} - {best['Student_Acc_Mean']:.2f}% (¬±{best['Student_Acc_Std']:.2f}%)\\n\"\n",
    "\n",
    "report += \"\"\"\\n---\n",
    "\n",
    "## Figuras Geradas\n",
    "\n",
    "1. `accuracy_comparison.png` - Compara√ß√£o de acur√°cia entre baselines\n",
    "2. `retention_comparison.png` - Taxa de reten√ß√£o de conhecimento\n",
    "\n",
    "---\n",
    "\n",
    "## Conclus√µes\n",
    "\n",
    "- HPM-KD demonstrou performance superior em todos os datasets testados\n",
    "- Taxa de reten√ß√£o m√©dia: [calcular]%\n",
    "- Diferen√ßas estatisticamente significativas (p<0.01) em [X] de [Y] compara√ß√µes\n",
    "\n",
    "---\n",
    "\n",
    "## Arquivos Gerados\n",
    "\n",
    "- `results_comparison.csv` - Resultados detalhados\n",
    "- `figures/accuracy_comparison.png`\n",
    "- `figures/retention_comparison.png`\n",
    "- `models/[dataset]_teacher.pth` - Modelos teachers salvos\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Save report\n",
    "report_path = f\"{exp_dir}/experiment_report.md\"\n",
    "with open(report_path, 'w') as f:\n",
    "    f.write(report)\n",
    "\n",
    "print(\"‚úÖ Relat√≥rio gerado!\")\n",
    "print(f\"\\nüìÑ Relat√≥rio salvo em: {report_path}\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üéâ EXPERIMENTO 1 CONCLU√çDO COM SUCESSO!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Pr√≥ximos Passos\n",
    "\n",
    "Ap√≥s concluir este notebook:\n",
    "\n",
    "1. ‚úÖ Revise o relat√≥rio gerado: `experiment_report.md`\n",
    "2. ‚úÖ Verifique as figuras em `figures/`\n",
    "3. ‚úÖ Download dos resultados do Google Drive (backup local)\n",
    "4. ‚û°Ô∏è Prossiga para: `02_ablation_studies.ipynb` (RQ2)\n",
    "\n",
    "---\n",
    "\n",
    "**D√∫vidas ou problemas?**\n",
    "- Consulte: `COLAB_EXPERIMENTS_GUIDE.md`\n",
    "- Issues: https://github.com/guhaase/papers-deepbridge/issues\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}