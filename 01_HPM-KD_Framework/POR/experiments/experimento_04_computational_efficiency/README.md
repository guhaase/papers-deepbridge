# Experimento 4: Computational Efficiency

## ğŸ“‹ InformaÃ§Ãµes Gerais

| ParÃ¢metro | Valor |
|-----------|-------|
| **Experimento** | Experimento 4 - Computational Efficiency |
| **Research Question** | RQ4: Qual o overhead computacional do HPM-KD comparado aos baselines? |
| **Status** | ğŸ“‹ **PENDENTE** (Script criado, nÃ£o executado) |
| **Dataset** | CIFAR10 (Full Mode) / MNIST (Quick Mode) |
| **Modelos a Treinar** | ~8 modelos (maioria Ã© benchmarking) |
| **Tempo Estimado** | ~1h (Full Mode) |

---

## ğŸ¯ Objetivo

Validar a **Research Question 4 (RQ4)** do paper HPM-KD medindo o **overhead computacional** do mÃ©todo proposto comparado aos baselines.

### **Research Question:**
> Qual o overhead computacional do HPM-KD comparado aos baselines?

---

## ğŸ”¬ Sub-Experimentos

### **4.1. Time Breakdown**
**Objetivo:** Tempo de cada componente do HPM-KD

**MediÃ§Ãµes:**
- Total training time
- Per epoch time
- Per component time (ProgChain, AdaptConf, etc.)

**Modelos:** 1 mÃ©todo Ã— 5 runs = **5 modelos** (mediÃ§Ã£o de tempo)

---

### **4.2. Inference Latency**
**Objetivo:** LatÃªncia de inferÃªncia CPU/GPU com diferentes batch sizes

**Batch Sizes:**
- Batch=1 (latÃªncia mÃ­nima)
- Batch=32 (mÃ©dio)
- Batch=128 (throughput mÃ¡ximo)

**Plataformas:**
- CPU
- GPU

**Modelos:** 3 mÃ©todos Ã— 1 run = **3 modelos** (benchmarking)

---

### **4.3. Speedup Parallelization**
**Objetivo:** Ganhos com paralelizaÃ§Ã£o (multiple workers)

**Workers:** [1, 2, 4, 8, 16, 32]

**Modelos:** Reutiliza modelos existentes (sem treino adicional)

---

### **4.4. Cost-Benefit Analysis (Exp 14)**
**Objetivo:** Pareto frontier: accuracy vs time

**AnÃ¡lise:**
- Plotar accuracy vs training time
- Identificar sweet spot (melhor tradeoff)

**Modelos:** Reutiliza resultados de Experimento 1B

---

## âš™ï¸ ConfiguraÃ§Ã£o

### **Modos de ExecuÃ§Ã£o:**

| Modo | Dataset | Runs | Tempo |
|------|---------|------|-------|
| **Quick** | MNIST | 3 | ~30min |
| **Full** | CIFAR10 | 5 | ~1h |

### **Total de Modelos (Full Mode):**
```
Time Breakdown:             5 modelos
Inference Latency:          3 modelos
Speedup Parallelization:    0 (reutiliza)
Cost-Benefit Analysis:      0 (reutiliza)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TOTAL:                      8 modelos
```

---

## ğŸš€ Como Executar

### **Quick Mode:**
```bash
cd scripts/
python 04_computational_efficiency.py --mode quick --dataset MNIST
```

### **Full Mode:**
```bash
cd scripts/
python 04_computational_efficiency.py --mode full --dataset CIFAR10 --gpu 0
```

---

## ğŸ“ Estrutura de Arquivos

```
experimento_04_computational_efficiency/
â”œâ”€â”€ README.md                          â† Este arquivo
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ 04_computational_efficiency.py (script principal)
â””â”€â”€ results/
    â””â”€â”€ (resultados apÃ³s execuÃ§Ã£o)
```

---

## ğŸ“Š Resultados Esperados

### **HipÃ³teses:**

1. **Training Time:** HPM-KD overhead ~20-30% vs Traditional KD
2. **Inference:** Sem overhead (mesmo modelo student final)
3. **Parallelization:** Speedup linear atÃ© ~4 workers
4. **Cost-Benefit:** HPM-KD oferece melhor accuracy/time ratio em compression â‰¥5Ã—

### **MÃ©tricas:**

- **Training Time** (total, per epoch)
- **Inference Latency** (ms/sample)
- **Throughput** (samples/sec)
- **Memory Consumption** (GPU/CPU)
- **Speedup** (parallel workers)
- **Efficiency** (speedup/workers)

### **Se Confirmado:**
- âœ… RQ4 validada
- âœ… Overhead computacional aceitÃ¡vel
- âœ… Justifica uso de HPM-KD (benefÃ­cio > custo)

---

## ğŸ“š Relacionado

- **Experimento 1B:** `../experimento_01b_compression_ratios/` â­ **Execute primeiro!**
- **Experimento 2:** `../experimento_02_ablation_studies/`
- **Experimento 3:** `../experimento_03_generalization/`
- **DocumentaÃ§Ã£o Geral:** `../SUMARIO_COMPLETO_EXPERIMENTOS.md`

---

**Criado:** Dezembro 2025
**Status:** ğŸ“‹ Pendente
**Prioridade:** 4 (pode executar em paralelo com Experimento 3)
**Autor:** Gustavo Haase
