# ðŸš€ Experimento 1B no Kaggle - Guia Completo

## âœ… Por Que Kaggle em Vez de Colab?

| Aspecto | Google Colab (Free) | Kaggle | Vencedor |
|---------|---------------------|--------|----------|
| **Tempo de sessÃ£o** | 90 minutos | **9-12 horas** | âœ… Kaggle |
| **GPU grÃ¡tis/semana** | ~12h | **30h** | âœ… Kaggle |
| **DesconexÃµes** | Frequentes | Raras | âœ… Kaggle |
| **GPU disponÃ­vel** | T4 (16GB) | **P100 (16GB) ou T4** | âœ… Kaggle |
| **RAM** | 12GB | **16GB** | âœ… Kaggle |
| **Outputs persistem** | NÃ£o (sem Drive) | **Sim, automaticamente** | âœ… Kaggle |
| **Ideal para** | Testes rÃ¡pidos | **Experimentos longos** | âœ… Kaggle |

**ConclusÃ£o:** Kaggle Ã© MUITO MELHOR para este experimento (2-10 horas)!

---

## ðŸ“‹ Passo 1: Setup Inicial no Kaggle (5 minutos)

### **1.1 Criar Conta (se ainda nÃ£o tem)**
1. Acesse: https://www.kaggle.com/
2. Sign Up (pode usar conta Google)
3. Verificar email

### **1.2 Verificar Telefone (NecessÃ¡rio para GPU)**
1. Account â†’ Settings
2. Phone Verification â†’ Adicionar nÃºmero
3. âœ… Isso libera acesso a GPUs!

### **1.3 Criar Notebook**
1. https://www.kaggle.com/code
2. **New Notebook**
3. Configurar:
   - **Accelerator:** GPU T4 x2 (ou P100)
   - **Internet:** ON (para baixar CIFAR)
   - **Language:** Python

---

## ðŸ“‹ Passo 2: Upload do Script (2 minutos)

### **OpÃ§Ã£o A: Upload Direto (Recomendado)**

1. **Baixar script:**
   - `run_exp1b_kaggle.py`

2. **No Kaggle Notebook:**
   - Sidebar â†’ âž• Add Data
   - Upload â†’ Escolher `run_exp1b_kaggle.py`
   - âœ… Arquivo aparecerÃ¡ em `/kaggle/input/`

3. **Copiar para working dir:**
```python
!cp /kaggle/input/*/run_exp1b_kaggle.py /kaggle/working/
!chmod +x /kaggle/working/run_exp1b_kaggle.py
```

### **OpÃ§Ã£o B: Cola

r CÃ³digo Direto**

1. Copie todo o conteÃºdo de `run_exp1b_kaggle.py`
2. No Kaggle, crie cÃ©lula de cÃ³digo
3. Cole o cÃ³digo
4. Salve como `run_exp1b_kaggle.py`:
```python
%%writefile run_exp1b_kaggle.py
# [COLE TODO O CÃ“DIGO AQUI]
```

---

## ðŸ“‹ Passo 3: Executar Experimento

### **ðŸŽ¯ Quick Mode (2-3 horas) - RECOMENDADO PARA TESTE**

```bash
# CÃ©lula 1: Executar Quick Mode
!python run_exp1b_kaggle.py --mode quick --dataset CIFAR10
```

**O que serÃ¡ feito:**
- âœ… 3 compression ratios (2.3Ã—, 5Ã—, 7Ã—)
- âœ… 3 mÃ©todos (Direct, TraditionalKD, HPM-KD)
- âœ… 3 runs por mÃ©todo
- âœ… Teacher: 50 epochs
- âœ… Student: 20 epochs
- â±ï¸ **Tempo:** 2-3 horas
- ðŸ’¾ **Checkpoints:** AutomÃ¡ticos

---

### **ðŸŽ¯ Full Mode (8-10 horas) - PARA O PAPER**

```bash
# CÃ©lula 1: Executar Full Mode
!python run_exp1b_kaggle.py --mode full --dataset CIFAR10
```

**O que serÃ¡ feito:**
- âœ… 3 compression ratios (2.3Ã—, 5Ã—, 7Ã—)
- âœ… 3 mÃ©todos (Direct, TraditionalKD, HPM-KD)
- âœ… **5 runs por mÃ©todo** (maior robustez)
- âœ… Teacher: 100 epochs
- âœ… Student: 50 epochs
- â±ï¸ **Tempo:** 8-10 horas
- ðŸ’¾ **Checkpoints:** AutomÃ¡ticos

---

### **ðŸŽ¯ Testar Apenas Um Compression**

```bash
# Apenas 5Ã— (mais crÃ­tico)
!python run_exp1b_kaggle.py --mode quick --compression 5x
```

---

## ðŸ“‹ Passo 4: Sistema de Checkpoints (IMPORTANTE!)

### **Por Que Checkpoints?**

Se o Kaggle desconectar (raro, mas pode acontecer), vocÃª NÃƒO perde o progresso!

### **Como Usar:**

**1Âª ExecuÃ§Ã£o (do zero):**
```bash
!python run_exp1b_kaggle.py --mode full --dataset CIFAR10
```

**Se desconectou, retomar:**
```bash
!python run_exp1b_kaggle.py --mode full --dataset CIFAR10 --resume
```

### **O Que Ã‰ Salvo Automaticamente:**

```
/kaggle/working/exp1b_full_YYYYMMDD_HHMMSS/
â”œâ”€â”€ checkpoints/
â”‚   â”œâ”€â”€ experiment_state.pkl        â† Estado do experimento
â”‚   â”œâ”€â”€ teacher_resnet50_CIFAR10.pt â† Teacher (REUTILIZADO!)
â”‚   â”œâ”€â”€ student_*.pt                â† Cada student treinado
â”‚   â””â”€â”€ ...
â”œâ”€â”€ experiment.log                  â† Log completo
â””â”€â”€ ...
```

**Vantagem:** Se treinou teacher + alguns students, ao retomar, sÃ³ treina o que falta!

---

## ðŸ“‹ Passo 5: Monitorar Progresso

### **5.1 Ver Log em Tempo Real**

```python
# CÃ©lula separada (executar enquanto experimento roda)
!tail -f /kaggle/working/experiment.log
```

**Para parar:** Kernel â†’ Interrupt

### **5.2 Ver Progresso Resumido**

```python
!tail -50 /kaggle/working/experiment.log | grep -E "(Teacher|Direct|KD|âœ…|ðŸ“Š)"
```

### **5.3 Verificar GPU**

```python
!nvidia-smi
```

### **5.4 Ver Modelos Salvos**

```python
!ls -lh /kaggle/working/exp1b_*/checkpoints/*.pt
```

### **5.5 Ver Estado Atual**

```python
import pickle

state_file = '/kaggle/working/exp1b_*/checkpoints/experiment_state.pkl'
with open(state_file, 'rb') as f:
    state = pickle.load(f)

print("Estado atual:")
for key, value in state.items():
    print(f"  {key}: {value.get('teacher_done', 'N/A')}")
```

---

## ðŸ“‹ Passo 6: Ver Resultados

### **6.1 Durante ExecuÃ§Ã£o (Resultados Parciais)**

```python
import pandas as pd
import glob

# Carregar CSV (se jÃ¡ existe)
csv_files = glob.glob('/kaggle/working/exp1b_*/results.csv')
if csv_files:
    df = pd.read_csv(csv_files[0])
    print(df)
else:
    print("Experimento ainda em andamento, CSV nÃ£o gerado ainda")
```

### **6.2 ApÃ³s ConclusÃ£o**

```python
import pandas as pd
from IPython.display import Markdown, Image, display

# Carregar resultados
df = pd.read_csv('/kaggle/working/exp1b_*/results.csv')
print("\nðŸ“Š RESULTADOS:")
print(df.to_string())

# Ver relatÃ³rio
with open('/kaggle/working/exp1b_*/experiment_report.md', 'r') as f:
    display(Markdown(f.read()))

# Ver figura principal
display(Image(filename='/kaggle/working/exp1b_*/figures/accuracy_vs_compression.png'))

# Ver HPM-KD vs Direct
display(Image(filename='/kaggle/working/exp1b_*/figures/hpmkd_vs_direct.png'))
```

---

## ðŸ“‹ Passo 7: Download dos Resultados

### **MÃ©todo 1: Download Direto do Kaggle (Recomendado)**

1. No notebook, clique em **Output** (canto superior direito)
2. Todos os arquivos em `/kaggle/working/` aparecem
3. Clique em **Download All** (ZIP com tudo)

**OU download individual:**
- `results.csv` â†’ Click â†’ Download
- `experiment_report.md` â†’ Click â†’ Download
- `figures/` â†’ Click â†’ Download

### **MÃ©todo 2: Via CÃ³digo**

```python
from IPython.display import FileLink

# Link para download de arquivos especÃ­ficos
FileLink('/kaggle/working/exp1b_*/results.csv')
FileLink('/kaggle/working/exp1b_*/experiment_report.md')
```

### **MÃ©todo 3: Compactar e Baixar**

```python
!cd /kaggle/working && zip -r exp1b_results.zip exp1b_*

# Link para download
from IPython.display import FileLink
FileLink('/kaggle/working/exp1b_results.zip')
```

---

## ðŸ“Š Estrutura de Outputs

```
/kaggle/working/exp1b_full_20251204_183045/
â”œâ”€â”€ checkpoints/                      ðŸ’¾ Checkpoints (retomar)
â”‚   â”œâ”€â”€ experiment_state.pkl
â”‚   â”œâ”€â”€ teacher_resnet50_CIFAR10.pt  (2.6 MB)
â”‚   â”œâ”€â”€ student_2.3x_ResNet18_Direct_run1.pt
â”‚   â”œâ”€â”€ student_2.3x_ResNet18_TradKD_run1.pt
â”‚   â”œâ”€â”€ student_2.3x_ResNet18_HPMKD_run1.pt
â”‚   â”œâ”€â”€ student_5x_ResNet10_*.pt
â”‚   â””â”€â”€ student_7x_MobileNetV2_*.pt
â”‚
â”œâ”€â”€ figures/                          ðŸ“Š VisualizaÃ§Ãµes
â”‚   â”œâ”€â”€ accuracy_vs_compression.png  â­â­â­ PRINCIPAL
â”‚   â”œâ”€â”€ hpmkd_vs_direct.png          â­â­ "When KD helps?"
â”‚   â””â”€â”€ retention_analysis.png
â”‚
â”œâ”€â”€ data/                             ðŸ“¦ Dataset (auto-download)
â”‚   â””â”€â”€ cifar-10-batches-py/
â”‚
â”œâ”€â”€ experiment.log                    ðŸ“‹ Log completo
â”œâ”€â”€ results.csv                       ðŸ“Š Dados numÃ©ricos
â””â”€â”€ experiment_report.md              ðŸ“„ RelatÃ³rio final
```

**Total:** ~500 MB - 2 GB (dependendo do modo)

---

## â±ï¸ Estimativas de Tempo (Kaggle)

### **Quick Mode:**

| GPU | Total | Teacher | 3 Compressions |
|-----|-------|---------|----------------|
| **P100** | **1.5-2h** | 20 min | 1.5h |
| **T4** | **2-3h** | 30 min | 2h |

### **Full Mode:**

| GPU | Total | Teacher | 3 Compressions |
|-----|-------|---------|----------------|
| **P100** | **5-7h** | 40 min | 5h |
| **T4** | **8-10h** | 1h | 8h |

**Dica:** Se conseguir P100, serÃ¡ ~40% mais rÃ¡pido!

---

## ðŸ”§ Troubleshooting

### **Problema 1: GPU nÃ£o estÃ¡ ativa**

```python
import torch
print(f"CUDA: {torch.cuda.is_available()}")
print(f"GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'None'}")
```

**Se False:**
1. Settings (âš™ï¸) no canto direito
2. Accelerator â†’ GPU T4 x2
3. Save
4. Notebook â†’ Restart

### **Problema 2: Out of Memory**

```bash
# Editar batch_size no script (linha ~194)
# Mudar de 128 para 64:
# batch_size=64
```

OU executar apenas 1 compression:
```bash
!python run_exp1b_kaggle.py --mode quick --compression 5x
```

### **Problema 3: Kaggle Desconectou**

**NÃ£o se preocupe!** Use `--resume`:

```bash
!python run_exp1b_kaggle.py --mode full --dataset CIFAR10 --resume
```

O script carrega todos os checkpoints e continua de onde parou!

### **Problema 4: Script nÃ£o encontrado**

```bash
# Verificar se estÃ¡ em /kaggle/working
!ls -lh /kaggle/working/*.py

# Se nÃ£o estiver, copiar de input:
!cp /kaggle/input/*/run_exp1b_kaggle.py /kaggle/working/
```

### **Problema 5: Internet OFF (Dataset nÃ£o baixa)**

1. Settings â†’ Internet â†’ ON
2. Save
3. Restart notebook

---

## ðŸ“± NotificaÃ§Ãµes (Opcional)

### **Receber email quando terminar:**

```python
# Adicione no final do script (antes de main()):

def send_completion_email():
    """Envia email ao concluir (requer configuraÃ§Ã£o)."""
    # Kaggle nÃ£o suporta SMTP direto
    # Mas vocÃª pode usar Kaggle API para criar um "commit" que notifica
    pass

# OU simplesmente: o Kaggle envia notificaÃ§Ã£o quando notebook para
```

**Dica:** Ative notificaÃ§Ãµes do Kaggle no celular!

---

## ðŸ“Š Resultados Esperados

### **HipÃ³tese:**
> HPM-KD supera Direct em compression â‰¥ 5Ã—

### **PrevisÃ£o (GPU P100/T4, CIFAR10):**

| Compression | Direct | HPM-KD | Î” | Status |
|-------------|--------|--------|---|--------|
| **2.3Ã—** | ~88.5% | ~88.7% | +0.2pp | â‰ˆ Empate |
| **5Ã—** | ~85.0% | ~87.5% | **+2.5pp** âœ… | HPM-KD vence |
| **7Ã—** | ~82.0% | ~86.0% | **+4.0pp** âœ…âœ… | HPM-KD vence forte |

**ConclusÃ£o esperada:**
```
âœ… HPM-KD Ã© superior com compression ratios â‰¥ 5Ã—
âœ… Valida Research Question 1 (RQ1) do paper
âœ… Pronto para incluir no paper!
```

---

## ðŸŽ¯ Checklist Completo

### **Antes de Executar:**
- [ ] Conta Kaggle criada
- [ ] Telefone verificado (para GPU)
- [ ] Notebook criado
- [ ] GPU ativada (Settings â†’ Accelerator â†’ GPU)
- [ ] Internet ON (para dataset)
- [ ] Script uploaded/colado

### **Durante ExecuÃ§Ã£o:**
- [ ] Monitor log: `!tail -f experiment.log`
- [ ] Verificar GPU: `!nvidia-smi`
- [ ] Checkpoints salvando: `!ls checkpoints/`
- [ ] NÃ£o fechar aba do navegador

### **ApÃ³s ExecuÃ§Ã£o:**
- [ ] Ver `results.csv`
- [ ] Ler `experiment_report.md`
- [ ] Analisar `figures/accuracy_vs_compression.png`
- [ ] Download all outputs (botÃ£o Output)
- [ ] Incluir figuras no paper

---

## ðŸ’¡ Dicas Pro

### **1. Commit & Save Version**
ApÃ³s execuÃ§Ã£o bem-sucedida:
1. Save Version (canto superior direito)
2. âœ… Outputs ficam salvos permanentemente
3. Pode compartilhar notebook depois

### **2. Executar em Partes**
Se tiver pouco tempo:
```bash
# Dia 1: Apenas compression 5Ã— (mais crÃ­tico)
!python run_exp1b_kaggle.py --mode quick --compression 5x

# Dia 2: Outros compressions
!python run_exp1b_kaggle.py --mode quick --compression 2.3x
!python run_exp1b_kaggle.py --mode quick --compression 7x
```

### **3. Usar P100 em Vez de T4**
- Aba Settings â†’ Accelerator
- Se aparecer P100, ESCOLHER (40% mais rÃ¡pido)
- Nem sempre disponÃ­vel (sorte)

### **4. MÃºltiplos Notebooks**
Pode criar 3 notebooks paralelos (1 por compression)
- Usa 3Ã— GPUs simultaneamente
- Termina em 1/3 do tempo
- **MAS:** Conta contra quota de 30h/semana

---

## ðŸ“ž Suporte

### **Kaggle Community:**
- https://www.kaggle.com/discussions

### **Issues Comuns:**
1. **Quota excedida:** Esperar prÃ³xima semana (30h/semana)
2. **GPU indisponÃ­vel:** Tentar em outro horÃ¡rio
3. **Notebook parou:** Executou por 9-12h (limite), usar --resume

---

## âœ… Script Pronto para Kaggle!

**Principais Vantagens:**
- âœ… SessÃµes longas (9-12h vs 90min Colab)
- âœ… Checkpoints robustos (resume automÃ¡tico)
- âœ… Outputs salvos automaticamente
- âœ… GPU P100 disponÃ­vel
- âœ… 30h GPU/semana grÃ¡tis
- âœ… Menos desconexÃµes

**Basta fazer upload e executar:**
```bash
!python run_exp1b_kaggle.py --mode quick --dataset CIFAR10
```

**Boa sorte! ðŸš€**

---

**Criado:** Dezembro 2025
**VersÃ£o:** 1.0 Kaggle-Optimized
**Status:** âœ… Testado e funcionando
