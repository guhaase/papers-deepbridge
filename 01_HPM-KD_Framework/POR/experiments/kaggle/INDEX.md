# üìÅ Experimento 1B - Arquivos Kaggle

## üìä Resumo

Estrutura completa para executar o Experimento 1B no **Kaggle** (melhor que Colab para experimentos longos).

**Por que Kaggle?**
- ‚úÖ Sess√µes de 9-12 horas (vs 90min Colab)
- ‚úÖ 30h GPU/semana gr√°tis (vs 12h Colab)
- ‚úÖ Outputs salvos automaticamente
- ‚úÖ Sistema robusto de checkpoints
- ‚úÖ GPU P100 (16GB) ou T4 (16GB)

---

## üìÇ Arquivos Criados

### **1. Script Principal (810 linhas)**
üìÑ **`run_exp1b_kaggle.py`**
- Script Python completo e autocontido
- Sistema robusto de checkpoints
- Resume autom√°tico se desconectar
- Otimizado para Kaggle (`/kaggle/working/`)
- Implementa 3 m√©todos: Direct, TraditionalKD, HPM-KD
- Testa 3 compression ratios: 2.3√ó, 5√ó, 7√ó

**Uso:**
```bash
!python run_exp1b_kaggle.py --mode quick --dataset CIFAR10
```

---

### **2. Guia Completo (516 linhas)**
üìñ **`README_KAGGLE.md`**
- Passo-a-passo completo
- Setup inicial no Kaggle
- Upload do script
- Execu√ß√£o e monitoramento
- Sistema de checkpoints
- Download de resultados
- Troubleshooting
- Estimativas de tempo

**Leia primeiro:** Documenta√ß√£o completa de como usar.

---

### **3. Quick Start (186 linhas)**
‚ö° **`QUICK_START_KAGGLE.md`**
- Guia r√°pido (3 passos)
- Comandos essenciais
- Copy-paste para Kaggle
- Resumo de troubleshooting

**Leia se:** Quer come√ßar r√°pido sem ler tudo.

---

## üöÄ Como Usar (3 Passos)

### **Passo 1: Ativar GPU**
```
Kaggle Notebook ‚Üí Settings ‚Üí Accelerator ‚Üí GPU T4 x2 ‚Üí Save
```

### **Passo 2: Upload Script**
1. Baixe `run_exp1b_kaggle.py`
2. Kaggle ‚Üí Add Data ‚Üí Upload
3. Copie para working:
```bash
!cp /kaggle/input/*/run_exp1b_kaggle.py /kaggle/working/
```

### **Passo 3: Executar**
```bash
# Quick Mode (2-3h)
!python /kaggle/working/run_exp1b_kaggle.py --mode quick --dataset CIFAR10

# Full Mode (8-10h)
!python /kaggle/working/run_exp1b_kaggle.py --mode full --dataset CIFAR10
```

---

## üìã Modos de Execu√ß√£o

### **Quick Mode (2-3 horas)**
- Teacher: 50 epochs
- Student: 20 epochs
- 3 runs por m√©todo
- 3 compression ratios
- **Para:** Testar pipeline

### **Full Mode (8-10 horas)**
- Teacher: 100 epochs
- Student: 50 epochs
- **5 runs por m√©todo** (maior robustez)
- 3 compression ratios
- **Para:** Resultados do paper

### **Compression Espec√≠fico**
```bash
# Apenas 5√ó (mais cr√≠tico, ~1h)
!python run_exp1b_kaggle.py --mode quick --compression 5x
```

---

## üíæ Sistema de Checkpoints

**Se o Kaggle desconectar (raro):**
```bash
# Retomar de onde parou
!python run_exp1b_kaggle.py --mode full --resume
```

**O que √© salvo:**
- ‚úÖ Teacher treinado (reutilizado!)
- ‚úÖ Cada student treinado
- ‚úÖ Estado completo do experimento
- ‚úÖ Logs e m√©tricas

**Vantagem:** Pode executar em m√∫ltiplas sess√µes!

---

## üìä Outputs Gerados

```
/kaggle/working/exp1b_full_YYYYMMDD_HHMMSS/
‚îú‚îÄ‚îÄ results.csv                       üìä Dados num√©ricos
‚îú‚îÄ‚îÄ experiment_report.md              üìÑ Relat√≥rio completo
‚îú‚îÄ‚îÄ experiment.log                    üìã Log de execu√ß√£o
‚îú‚îÄ‚îÄ figures/
‚îÇ   ‚îú‚îÄ‚îÄ accuracy_vs_compression.png  ‚≠ê‚≠ê‚≠ê PRINCIPAL
‚îÇ   ‚îú‚îÄ‚îÄ hpmkd_vs_direct.png          ‚≠ê‚≠ê "When KD helps?"
‚îÇ   ‚îî‚îÄ‚îÄ retention_analysis.png
‚îú‚îÄ‚îÄ checkpoints/                      üíæ Para retomar
‚îÇ   ‚îú‚îÄ‚îÄ experiment_state.pkl
‚îÇ   ‚îú‚îÄ‚îÄ teacher_resnet50_CIFAR10.pt
‚îÇ   ‚îî‚îÄ‚îÄ student_*.pt (27 modelos)
‚îî‚îÄ‚îÄ data/                             üì¶ CIFAR10 (auto-download)
```

**Download:** Output tab ‚Üí Download All (ZIP ~500MB-2GB)

---

## ‚è±Ô∏è Tempo de Execu√ß√£o (Kaggle)

| Modo | GPU P100 | GPU T4 |
|------|----------|--------|
| **Quick** | 1.5-2h | 2-3h |
| **Full** | 5-7h | 8-10h |
| **5√ó only** | 30-45 min | 45-60 min |

**Limite Kaggle:** 9-12h por sess√£o (suficiente para Full Mode)

---

## üéØ Resultados Esperados

### **Hip√≥tese a Validar:**
> HPM-KD supera Direct training em compression ratios ‚â• 5√ó

### **Previs√£o:**

| Compression | Direct | HPM-KD | Œî | Conclus√£o |
|-------------|--------|--------|---|-----------|
| **2.3√ó** | ~88.5% | ~88.7% | +0.2pp | ‚âà Empate |
| **5√ó** | ~85.0% | ~87.5% | **+2.5pp** ‚úÖ | HPM-KD vence |
| **7√ó** | ~82.0% | ~86.0% | **+4.0pp** ‚úÖ‚úÖ | HPM-KD vence |

**Se confirmado:** ‚úÖ Valida RQ1 do paper!

---

## üìñ Documenta√ß√£o

| Arquivo | Linhas | Descri√ß√£o |
|---------|--------|-----------|
| `run_exp1b_kaggle.py` | 810 | Script principal (autocontido) |
| `README_KAGGLE.md` | 516 | Guia completo detalhado |
| `QUICK_START_KAGGLE.md` | 186 | Guia r√°pido (3 passos) |
| `INDEX.md` | Este arquivo | √çndice e resumo |

**Total:** 1512 linhas de c√≥digo + documenta√ß√£o

---

## üîß Features Implementadas

### **Script Python:**
- ‚úÖ Detec√ß√£o autom√°tica de ambiente Kaggle
- ‚úÖ Paths corretos (`/kaggle/working/`)
- ‚úÖ Sistema robusto de checkpoints
- ‚úÖ Resume autom√°tico (`--resume`)
- ‚úÖ Progress bars detalhados (tqdm)
- ‚úÖ Logging completo (arquivo + console)
- ‚úÖ Gera√ß√£o autom√°tica de figuras
- ‚úÖ Relat√≥rio markdown autom√°tico
- ‚úÖ Salvamento incremental
- ‚úÖ Otimizado para GPUs Kaggle (P100/T4)

### **Checkpoints:**
- ‚úÖ Estado do experimento (pickle)
- ‚úÖ Todos os modelos (.pt)
- ‚úÖ Teacher reutilizado entre runs
- ‚úÖ Resume granular (por m√©todo/run)

### **Visualiza√ß√µes:**
- ‚úÖ Accuracy vs Compression Ratio
- ‚úÖ HPM-KD vs Direct
- ‚úÖ Retention Analysis
- ‚úÖ PNG em alta resolu√ß√£o (300 DPI)

---

## üéØ Fluxo de Trabalho

```mermaid
graph TD
    A[Criar Notebook Kaggle] --> B[Ativar GPU]
    B --> C[Upload run_exp1b_kaggle.py]
    C --> D[Executar Script]
    D --> E{Modo?}
    E -->|Quick| F[2-3h execu√ß√£o]
    E -->|Full| G[8-10h execu√ß√£o]
    F --> H[Checkpoints salvos]
    G --> H
    H --> I{Desconectou?}
    I -->|N√£o| J[Ver Resultados]
    I -->|Sim| K[--resume]
    K --> D
    J --> L[Download Outputs]
    L --> M[Incluir no Paper]
```

---

## üí° Dicas Pro

### **1. P100 > T4**
- P100: 40% mais r√°pido que T4
- Nem sempre dispon√≠vel (sorte)
- Tentar em hor√°rios menos concorridos

### **2. Executar em Partes**
```bash
# 3 sess√µes de 1h cada
!python run_exp1b_kaggle.py --mode quick --compression 5x  # Sess√£o 1
!python run_exp1b_kaggle.py --mode quick --compression 2.3x # Sess√£o 2
!python run_exp1b_kaggle.py --mode quick --compression 7x  # Sess√£o 3
```

### **3. Save Version**
Ap√≥s execu√ß√£o bem-sucedida:
- Save Version (canto superior direito)
- Outputs ficam salvos permanentemente
- Pode compartilhar depois

### **4. Monitor GPU**
```python
!watch -n 5 nvidia-smi  # Atualiza a cada 5s
```

---

## üö® Troubleshooting R√°pido

| Problema | Solu√ß√£o |
|----------|---------|
| GPU n√£o ativa | Settings ‚Üí Accelerator ‚Üí GPU |
| Out of Memory | Reduzir batch_size (128‚Üí64) |
| Desconectou | Usar `--resume` |
| Script n√£o encontrado | `!cp /kaggle/input/*/run*.py /kaggle/working/` |
| Internet OFF | Settings ‚Üí Internet ‚Üí ON |

**Ver mais:** `README_KAGGLE.md` se√ß√£o Troubleshooting

---

## ‚úÖ Pronto para Usar!

**Todos os arquivos foram criados e testados.**

**Para come√ßar:**
1. Leia `QUICK_START_KAGGLE.md` (5 minutos)
2. Siga os 3 passos
3. Execute e monitore
4. Download dos resultados
5. Incluir no paper!

---

## üìû Suporte

**Documenta√ß√£o completa:** `README_KAGGLE.md`
**Guia r√°pido:** `QUICK_START_KAGGLE.md`
**Script:** `run_exp1b_kaggle.py`

**Kaggle Community:** https://www.kaggle.com/discussions

---

## üéâ Vantagens do Kaggle

| Aspecto | Valor |
|---------|-------|
| **Custo** | 100% GR√ÅTIS |
| **GPU** | P100 (16GB) ou T4 (16GB) |
| **Sess√£o** | 9-12 horas (vs 90min Colab) |
| **Quota** | 30h GPU/semana |
| **Outputs** | Salvos automaticamente |
| **Checkpoints** | Sistema robusto |
| **Desconex√µes** | Raras |
| **Ideal para** | Experimentos longos (2-10h) |

**Conclus√£o:** Kaggle √© a MELHOR op√ß√£o para este experimento! üöÄ

---

**Criado:** Dezembro 2025
**Vers√£o:** 1.0 Kaggle-Optimized
**Status:** ‚úÖ Pronto para uso
**Autor:** Gustavo Haase
