# ğŸš€ Guia de ExecuÃ§Ã£o - Experimentos HPM-KD

## ğŸ“‹ VisÃ£o Geral

Este diretÃ³rio contÃ©m **4 experimentos** que validam o framework HPM-KD (Hierarchical Progressive Multi-teacher Knowledge Distillation) usando a **biblioteca DeepBridge**.

## ğŸ“‚ Scripts DisponÃ­veis

### Scripts Individuais:
1. **01_compression_efficiency.py** - Compara HPM-KD vs 5 baselines (RQ1)
2. **02_ablation_studies.py** - Analisa cada componente do HPM-KD (RQ2)
3. **03_generalization.py** - Testa robustez em condiÃ§Ãµes adversas (RQ3)
4. **04_computational_efficiency.py** - Mede overhead computacional (RQ4)

### Scripts de ExecuÃ§Ã£o:
- **run_all_experiments.py** - Executa todos os experimentos automaticamente
- **RUN_COLAB.py** - VersÃ£o simplificada para Google Colab

---

## ğŸ¯ ExecuÃ§Ã£o no Google Colab (RECOMENDADO)

### OpÃ§Ã£o 1: ExecuÃ§Ã£o Simplificada (Mais FÃ¡cil) â­

```python
# No Google Colab, execute:

# 1. Clone ou faÃ§a upload dos scripts
!git clone <seu-repositorio>
%cd papers/01_HPM-KD_Framework/POR/experiments/scripts

# 2. Instale dependÃªncias
!pip install deepbridge torch torchvision scikit-learn seaborn tqdm

# 3. Execute TODOS os experimentos (modo rÃ¡pido)
!python RUN_COLAB.py

# OU modo completo (mais demorado)
!python RUN_COLAB.py --full

# OU customizar dataset
!python RUN_COLAB.py --dataset CIFAR10
```

**Tempo estimado:**
- Modo `quick`: 3-4 horas
- Modo `full`: 8-10 horas

### OpÃ§Ã£o 2: ExecuÃ§Ã£o AvanÃ§ada

```python
# Mais controle sobre os parÃ¢metros
!python run_all_experiments.py --mode quick --datasets MNIST --gpu 0

# Executar apenas experimentos especÃ­ficos
!python run_all_experiments.py --mode quick --only 1 2 --dataset MNIST

# Pular experimentos
!python run_all_experiments.py --mode quick --skip 4 --dataset MNIST

# MÃºltiplos datasets (apenas Exp 1 suporta)
!python run_all_experiments.py --mode full --datasets MNIST CIFAR10 --gpu 0
```

---

## ğŸ’» ExecuÃ§Ã£o Local

### PrÃ©-requisitos:

```bash
pip install deepbridge torch torchvision scikit-learn seaborn tqdm matplotlib pandas numpy
```

### ExecuÃ§Ã£o:

```bash
# Modo rÃ¡pido (recomendado para testes)
python run_all_experiments.py --mode quick --dataset MNIST --gpu 0

# Modo completo (para resultados finais do paper)
python run_all_experiments.py --mode full --dataset CIFAR10 --gpu 0

# CPU (sem GPU)
python run_all_experiments.py --mode quick --dataset MNIST
```

---

## ğŸ“Š Estrutura de Resultados

ApÃ³s a execuÃ§Ã£o, vocÃª terÃ¡:

```
results_quick_20250307_123456/
â”œâ”€â”€ exp_01_compression_efficiency/
â”‚   â”œâ”€â”€ results/
â”‚   â”‚   â”œâ”€â”€ baseline_comparison.csv
â”‚   â”‚   â””â”€â”€ statistical_tests.csv
â”‚   â”œâ”€â”€ figures/
â”‚   â”‚   â”œâ”€â”€ accuracy_comparison.png
â”‚   â”‚   â”œâ”€â”€ retention_rates.png
â”‚   â”‚   â””â”€â”€ training_time.png
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ teacher.pth
â”‚   â”‚   â”œâ”€â”€ hpmkd_student.pth
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ report.md
â”‚
â”œâ”€â”€ exp_02_ablation_studies/
â”‚   â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ figures/
â”‚   â””â”€â”€ report.md
â”‚
â”œâ”€â”€ exp_03_generalization/
â”‚   â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ figures/
â”‚   â””â”€â”€ report.md
â”‚
â”œâ”€â”€ exp_04_computational_efficiency/
â”‚   â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ figures/
â”‚   â””â”€â”€ report.md
â”‚
â”œâ”€â”€ run_all_experiments.log
â”œâ”€â”€ results.json
â””â”€â”€ RELATORIO_FINAL.md  â­ RELATÃ“RIO CONSOLIDADO
```

---

## ğŸ“ˆ Experimentos Detalhados

### Exp 1: Compression Efficiency (RQ1)
**Objetivo:** HPM-KD alcanÃ§a maiores taxas de compressÃ£o mantendo acurÃ¡cia?

**Baselines comparados:**
- Direct (train from scratch)
- Traditional KD (Hinton et al. 2015)
- FitNets (Romero et al. 2015)
- Attention Transfer (Zagoruyko & Komodakis 2017)
- TAKD (Mirzadeh et al. 2020)
- **HPM-KD (DeepBridge)** â­

**Tempo:** Quick: 45min | Full: 4h

---

### Exp 2: Ablation Studies (RQ2)
**Objetivo:** Qual a contribuiÃ§Ã£o individual de cada componente?

**Componentes testados:**
- ProgChain (Progressive chaining)
- AdaptConf (Adaptive confidence)
- MultiTeach (Multi-teacher ensemble)
- MetaTemp (Meta-learned temperature)
- Parallel (Parallel paths)
- Memory (Memory-augmented)

**Experimentos:**
- Component ablation (5)
- Component interactions (6)
- Hyperparameter sensitivity (7)
- Chain length (8)
- Number of teachers (9)

**Tempo:** Quick: 1h | Full: 2h

---

### Exp 3: Generalization (RQ3)
**Objetivo:** HPM-KD generaliza melhor em condiÃ§Ãµes adversas?

**CenÃ¡rios:**
- Class Imbalance (ratios 10:1, 50:1, 100:1)
- Label Noise (10%, 20%, 30%)
- t-SNE Visualization + Silhouette Score

**Tempo:** Quick: 1.5h | Full: 3h

---

### Exp 4: Computational Efficiency (RQ4)
**Objetivo:** Qual o overhead computacional do HPM-KD?

**MÃ©tricas:**
- Training time breakdown
- Inference latency (CPU/GPU, batch 1-128)
- Memory consumption
- Throughput (samples/sec)
- Speedup com paralelizaÃ§Ã£o
- Cost-benefit analysis (Pareto frontier)

**Tempo:** Quick: 30min | Full: 1h

---

## ğŸ”§ ParÃ¢metros DisponÃ­veis

### run_all_experiments.py

```bash
--mode {quick,full}           # Modo de execuÃ§Ã£o (padrÃ£o: quick)
--datasets [MNIST ...]        # Datasets a usar (padrÃ£o: MNIST)
--dataset MNIST               # Dataset Ãºnico (alias)
--gpu GPU_ID                  # ID da GPU (None = CPU)
--output OUTPUT_DIR           # DiretÃ³rio de saÃ­da
--skip [1 2 ...]              # Pular experimentos especÃ­ficos
--only [1 2 ...]              # Executar apenas experimentos especÃ­ficos
```

### Scripts individuais

```bash
--mode {quick,full}           # Modo de execuÃ§Ã£o
--dataset MNIST               # Dataset (scripts 2, 3, 4)
--datasets MNIST CIFAR10      # MÃºltiplos datasets (script 1)
--gpu GPU_ID                  # ID da GPU
--output OUTPUT_DIR           # DiretÃ³rio de saÃ­da
```

---

## âš ï¸ Requerimentos Importantes

1. **DeepBridge Library** - OBRIGATÃ“RIA
   ```bash
   pip install deepbridge
   ```
   âŒ Scripts **FALHAM** se DeepBridge nÃ£o estiver instalado (sem fallback)

2. **GPU Recomendada**
   - Modo quick: funciona em CPU (lento)
   - Modo full: GPU altamente recomendada

3. **EspaÃ§o em disco**
   - ~2-5 GB para resultados completos (modelos, figuras, logs)

4. **RAM**
   - MÃ­nimo: 8 GB
   - Recomendado: 16 GB+

---

## ğŸ“Š Datasets Suportados

| Dataset | Classes | Samples | Tamanho | Tempo (quick) |
|---------|---------|---------|---------|---------------|
| MNIST | 10 | 60k | 28x28 | RÃ¡pido (~30min) |
| FashionMNIST | 10 | 60k | 28x28 | RÃ¡pido (~30min) |
| CIFAR10 | 10 | 50k | 32x32x3 | MÃ©dio (~1h) |
| CIFAR100 | 100 | 50k | 32x32x3 | Lento (~2h) |

**RecomendaÃ§Ã£o:**
- **Testes rÃ¡pidos:** MNIST (quick)
- **Resultados paper:** CIFAR10 (full)

---

## ğŸ“ CitaÃ§Ã£o

Se vocÃª usar estes experimentos, por favor cite:

```bibtex
@article{hpmkd2025,
  title={HPM-KD: Hierarchical Progressive Multi-teacher Knowledge Distillation},
  author={Seu Nome et al.},
  journal={ConferÃªncia},
  year={2025}
}
```

---

## ğŸ› Troubleshooting

### Erro: "DeepBridge library nÃ£o estÃ¡ disponÃ­vel"
**SoluÃ§Ã£o:**
```bash
pip install deepbridge
```

### Erro: "CUDA out of memory"
**SoluÃ§Ãµes:**
1. Use dataset menor (MNIST)
2. Use modo `quick`
3. Reduza batch size (edite configs nos scripts)
4. Use CPU (remove `--gpu`)

### Scripts muito lentos
**SoluÃ§Ãµes:**
1. Use `--mode quick`
2. Use GPU: `--gpu 0`
3. Use dataset pequeno: `--dataset MNIST`
4. Execute apenas alguns experimentos: `--only 1 2`

### No Google Colab: Session timeout
**SoluÃ§Ãµes:**
1. Use Google Colab Pro (mais tempo de sessÃ£o)
2. Execute experimentos individualmente
3. Use `--only` para executar poucos de cada vez

---

## ğŸ“ Suporte

Para dÃºvidas ou problemas:
1. Verifique os logs em `run_all_experiments.log`
2. Leia os relatÃ³rios individuais em cada `exp_XX/report.md`
3. Consulte a documentaÃ§Ã£o do DeepBridge

---

## âœ… Checklist de ExecuÃ§Ã£o

Antes de executar:
- [ ] DeepBridge instalado
- [ ] PyTorch + torchvision instalados
- [ ] GPU disponÃ­vel (opcional mas recomendado)
- [ ] EspaÃ§o em disco suficiente (~5 GB)
- [ ] Tempo disponÃ­vel (3-10 horas)

Para executar no Colab:
```python
!python RUN_COLAB.py
```

Para executar localmente:
```bash
python run_all_experiments.py --mode quick --dataset MNIST --gpu 0
```

**Boa sorte! ğŸš€**
