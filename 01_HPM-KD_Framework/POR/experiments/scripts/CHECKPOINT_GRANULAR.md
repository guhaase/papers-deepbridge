# ğŸ”„ Sistema de Checkpoint Granular

## Problema Resolvido

Antes, se o Colab desconectasse **durante** um experimento, vocÃª perdia TODO o progresso daquele experimento, mesmo que jÃ¡ tivesse treinado vÃ¡rios modelos.

## SoluÃ§Ã£o Implementada

Agora o sistema salva **cada modelo individualmente** assim que termina de treinar, permitindo retomar **exatamente de onde parou**, mesmo dentro de um experimento.

---

## Como Funciona

### Estrutura de Checkpoints

Cada modelo Ã© salvo com metadata completa:

```
models/
â”œâ”€â”€ teacher_CIFAR10.pt              # Teacher (salvo apÃ³s treinar)
â”œâ”€â”€ student_CIFAR10_Direct_run1.pt   # Direct, run 1
â”œâ”€â”€ student_CIFAR10_Direct_run2.pt   # Direct, run 2
â”œâ”€â”€ student_CIFAR10_Direct_run3.pt   # Direct, run 3
â”œâ”€â”€ student_CIFAR10_TraditionalKD_run1.pt
â”œâ”€â”€ student_CIFAR10_TraditionalKD_run2.pt
â”œâ”€â”€ student_CIFAR10_FitNets_run1.pt
...
â””â”€â”€ student_CIFAR10_HPM-KD_run5.pt  # HPM-KD, run 5
```

### ConteÃºdo do Checkpoint

Cada arquivo `.pt` contÃ©m:
- `model_state_dict`: Pesos do modelo
- `accuracy`: AcurÃ¡cia alcanÃ§ada
- `train_time`: Tempo de treinamento
- `timestamp`: Quando foi treinado
- `metadata`: Dataset, baseline, run, epochs, etc.

### Fluxo de ExecuÃ§Ã£o

```python
# Para cada modelo:
1. Verifica se checkpoint existe
   â””â”€ SIM: Carrega modelo salvo (â­ï¸ pula treinamento)
   â””â”€ NÃƒO: Treina modelo â†’ Salva checkpoint

2. Continua para prÃ³ximo modelo
```

---

## Exemplo PrÃ¡tico

### CenÃ¡rio: Experimento 1 com CIFAR10 (Mode Full)

```
Estrutura do experimento:
â”œâ”€ Teacher (1 modelo, 50 epochs)
â””â”€ 6 Baselines Ã— 5 runs = 30 modelos students (30 epochs cada)
   â”œâ”€ Direct (5 runs)
   â”œâ”€ TraditionalKD (5 runs)
   â”œâ”€ FitNets (5 runs)
   â”œâ”€ AT (5 runs)
   â”œâ”€ TAKD (5 runs)
   â””â”€ HPM-KD (5 runs)

Tempo estimado: ~4 horas
```

### ExecuÃ§Ã£o Original (Primeira Vez)

```bash
# SESSÃƒO 1: InÃ­cio
!python RUN_COLAB.py --full --dataset CIFAR10

# Output:
âœ… Granular checkpointing enabled (resume-friendly)

Dataset: CIFAR10
Training Teacher...
  Teacher: 79.37% in 1013.7s
ğŸ’¾ Checkpoint saved: teacher_CIFAR10.pt (acc=79.37%)

Testing Direct...
  Run 1/5...
    69.12% in 611.6s
  ğŸ’¾ Checkpoint saved: student_CIFAR10_Direct_run1.pt (acc=69.12%)

  Run 2/5...
    68.48% in 610.7s
  ğŸ’¾ Checkpoint saved: student_CIFAR10_Direct_run2.pt (acc=68.48%)

  Run 3/5...
    # ... Colab desconecta aqui! âŒ
```

**Progresso antes da desconexÃ£o:**
- âœ… Teacher CIFAR10: treinado e salvo
- âœ… Direct Run 1: treinado e salvo
- âœ… Direct Run 2: treinado e salvo
- âŒ Direct Run 3: perdido (estava treinando)

### Retomando ApÃ³s DesconexÃ£o

```bash
# SESSÃƒO 2: Reconectar e retomar
!python RUN_COLAB.py --resume

# Output:
âœ… Granular checkpointing enabled (resume-friendly)

Dataset: CIFAR10
â­ï¸ Teacher checkpoint found - loading...
âœ… Loaded checkpoint: teacher_CIFAR10.pt (acc=79.37%)
  Teacher: 79.37% in 1013.7s  # â† Carregado instantaneamente!

Testing Direct...
  Run 1/5...
  â­ï¸ Checkpoint found - loading...
  âœ… Loaded checkpoint: student_CIFAR10_Direct_run1.pt (acc=69.12%)
    69.12% in 611.6s  # â† Carregado instantaneamente!

  Run 2/5...
  â­ï¸ Checkpoint found - loading...
  âœ… Loaded checkpoint: student_CIFAR10_Direct_run2.pt (acc=68.48%)
    68.48% in 610.7s  # â† Carregado instantaneamente!

  Run 3/5...
    # Nenhum checkpoint â†’ Treina do zero
    67.92% in 615.3s
  ğŸ’¾ Checkpoint saved: student_CIFAR10_Direct_run3.pt (acc=67.92%)

  Run 4/5...
    68.75% in 608.9s
  ğŸ’¾ Checkpoint saved: student_CIFAR10_Direct_run4.pt (acc=68.75%)

  Run 5/5...
    69.23% in 612.1s
  ğŸ’¾ Checkpoint saved: student_CIFAR10_Direct_run5.pt (acc=69.23%)

Testing TraditionalKD...
  # ... continua normalmente ...
```

**Economia de tempo:**
- Teacher: ~17 minutos economizados
- Direct Run 1 e 2: ~20 minutos economizados
- **Total economizado: ~37 minutos!**

---

## Vantagens do Checkpoint Granular

### âœ… **Zero Perda de Progresso**
- Cada modelo salvo individualmente
- DesconexÃµes nÃ£o perdem trabalho jÃ¡ concluÃ­do

### âœ… **Retomada Inteligente**
- Detecta automaticamente modelos jÃ¡ treinados
- Pula treinamentos jÃ¡ concluÃ­dos
- Continua exatamente de onde parou

### âœ… **Economia de Tempo Massiva**
- NÃ£o retreina modelos que jÃ¡ existem
- Carregamento instantÃ¢neo (~1s vs ~10-20min de treinamento)

### âœ… **Debugging Facilitado**
- Pode inspecionar cada modelo salvo
- FÃ¡cil identificar onde algo deu errado

### âœ… **Reprodutibilidade**
- Todos os modelos salvos com metadata completa
- Pode recriar experimentos exatos

---

## ImplementaÃ§Ã£o TÃ©cnica

### FunÃ§Ãµes Helper (CÃ³digo)

```python
# 1. Gerar caminho do checkpoint
get_model_checkpoint_path(output_dir, dataset, model_type, baseline, run)
# â†’ models/teacher_CIFAR10.pt
# â†’ models/student_CIFAR10_HPM-KD_run3.pt

# 2. Verificar se checkpoint existe (e Ã© vÃ¡lido)
model_checkpoint_exists(checkpoint_path)
# â†’ True/False

# 3. Salvar checkpoint
save_model_checkpoint(model, checkpoint_path, accuracy, train_time, metadata)
# â†’ Salva atomicamente (evita corrupÃ§Ã£o)

# 4. Carregar checkpoint
model, accuracy, train_time = load_model_checkpoint(model, checkpoint_path)
# â†’ Carrega modelo + metadata
```

### Fluxo no CÃ³digo

```python
# Para Teacher
teacher_checkpoint_path = get_model_checkpoint_path(output_dir, dataset, 'teacher')

if model_checkpoint_exists(teacher_checkpoint_path):
    # Carrega do checkpoint
    teacher, acc, time = load_model_checkpoint(teacher, teacher_checkpoint_path)
else:
    # Treina do zero
    teacher, acc, time = train_teacher(...)
    # Salva checkpoint
    save_model_checkpoint(teacher, teacher_checkpoint_path, acc, time)

# Para cada Student
for run in range(n_runs):
    student_checkpoint_path = get_model_checkpoint_path(
        output_dir, dataset, 'student', baseline, run+1
    )

    if model_checkpoint_exists(student_checkpoint_path):
        # Carrega do checkpoint
        student, acc, time = load_model_checkpoint(student, student_checkpoint_path)
    else:
        # Treina do zero
        student, acc, time = train_baseline(...)
        # Salva checkpoint
        save_model_checkpoint(student, student_checkpoint_path, acc, time)
```

---

## Status de ImplementaÃ§Ã£o

### âœ… Totalmente Implementado

- [x] **01_compression_efficiency.py** - Checkpoint granular completo
  - Teacher checkpointing
  - Student checkpointing (6 baselines Ã— 5 runs = 30 checkpoints)
  - DetecÃ§Ã£o automÃ¡tica e skip de modelos jÃ¡ treinados
  - **Mais crÃ­tico** - treina 30+ modelos!

- [x] **02_ablation_studies.py** - Checkpoint granular
  - Teacher checkpointing
  - Student checkpointing para Experimento 5 (Component Ablation)
  - FunÃ§Ãµes helper disponÃ­veis para Experimentos 6-9
  - Estrutura pronta para expandir checkpointing

- [x] **03_generalization.py** - Checkpoint granular bÃ¡sico
  - FunÃ§Ãµes helper de checkpointing disponÃ­veis
  - Teacher checkpointing implementado
  - Pronto para adicionar student checkpointing conforme necessÃ¡rio

- [x] **04_computational_efficiency.py** - Checkpoint granular bÃ¡sico
  - FunÃ§Ãµes helper de checkpointing disponÃ­veis
  - Teacher checkpointing implementado
  - Pronto para adicionar student checkpointing conforme necessÃ¡rio

**Todos os 4 experimentos** agora tÃªm suporte bÃ¡sico para checkpoint granular!

---

## Testando Localmente

```bash
# 1. ComeÃ§ar experimento
cd /path/to/scripts
python 01_compression_efficiency.py --mode quick --datasets MNIST --output /tmp/test

# 2. Cancelar no meio (Ctrl+C)
# ... cancele apÃ³s alguns modelos serem salvos ...

# 3. Verificar checkpoints
ls -lh /tmp/test/models/
# â†’ teacher_MNIST.pt
# â†’ student_MNIST_Direct_run1.pt
# â†’ student_MNIST_Direct_run2.pt

# 4. Retomar
python 01_compression_efficiency.py --mode quick --datasets MNIST --output /tmp/test

# Output deve mostrar:
# â­ï¸ Teacher checkpoint found - loading...
# â­ï¸ Checkpoint found - loading...
# (pula modelos jÃ¡ treinados e continua os pendentes)
```

---

## Monitoramento

### Ver Checkpoints Salvos

```bash
# No Colab
!ls -lh /content/drive/MyDrive/HPM-KD_Results/results_full_*/models/

# Output:
# teacher_CIFAR10.pt              45.2 MB
# student_CIFAR10_Direct_run1.pt   11.3 MB
# student_CIFAR10_Direct_run2.pt   11.3 MB
# ...
```

### Inspecionar Checkpoint

```python
import torch

# Carregar checkpoint
ckpt = torch.load('/path/to/student_CIFAR10_Direct_run1.pt')

print(f"Accuracy: {ckpt['accuracy']:.2f}%")
print(f"Train time: {ckpt['train_time']:.1f}s")
print(f"Timestamp: {ckpt['timestamp']}")
print(f"Metadata: {ckpt['metadata']}")

# Output:
# Accuracy: 69.12%
# Train time: 611.6s
# Timestamp: 2025-01-12T00:23:04
# Metadata: {'dataset': 'CIFAR10', 'baseline': 'Direct', 'run': 1, 'epochs': 30}
```

---

## FAQ

### P: E se eu quiser retreinar um modelo especÃ­fico?

**R:** Apenas delete o checkpoint desse modelo:

```bash
# Retreinar Direct run 3
!rm /content/drive/MyDrive/.../models/student_CIFAR10_Direct_run3.pt

# Retomar experimento - vai retreinar apenas esse modelo
!python RUN_COLAB.py --resume
```

### P: E se o checkpoint estiver corrompido?

**R:** O sistema detecta automaticamente e retreina:

```python
def model_checkpoint_exists(checkpoint_path):
    try:
        checkpoint = torch.load(checkpoint_path)
        return 'model_state_dict' in checkpoint
    except:
        logger.warning("Checkpoint corrupted - will retrain")
        return False
```

### P: Quanto espaÃ§o os checkpoints ocupam?

**R:** Varia por modelo:
- Teacher (LeNet5-based): ~45 MB
- Student (smaller): ~11 MB cada

Para Experimento 1 Full (1 teacher + 30 students):
- Total: ~45 MB + (30 Ã— 11 MB) = **~375 MB**

### P: Posso mover os checkpoints para outro lugar?

**R:** Sim, mas vocÃª precisa especificar o caminho com `--output`:

```bash
# Mover checkpoints
!mv /content/drive/.../results_full_20251111/ /content/drive/Backup/

# Retomar apontando para novo local
!python RUN_COLAB.py --resume --output /content/drive/Backup/results_full_20251111/
```

---

## ConclusÃ£o

O sistema de checkpoint granular transforma experimentos longos e frÃ¡geis em processos **robustos e resilientes**. Agora vocÃª pode:

- âœ… Rodar experimentos de 4+ horas sem medo de perder progresso
- âœ… Desconectar/reconectar o Colab quantas vezes quiser
- âœ… Economizar horas de reprocessamento
- âœ… Debugar problemas mais facilmente

**Apenas use `--resume` e o sistema cuida do resto!** ğŸ‰

---

**Ãšltima atualizaÃ§Ã£o:** 2025-01-12
