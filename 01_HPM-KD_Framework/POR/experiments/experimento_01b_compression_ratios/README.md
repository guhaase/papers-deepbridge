# Experimento 1B: Compression Ratios Maiores (CRÃTICO) â­â­â­

## ğŸ“‹ InformaÃ§Ãµes Gerais

| ParÃ¢metro | Valor |
|-----------|-------|
| **Experimento** | Experimento 1B - Compression Ratios Maiores |
| **Research Question** | RQ1: HPM-KD supera Direct Training com compression ratios â‰¥ 5Ã—? |
| **Status** | â³ **PRONTO PARA EXECUTAR** (Dezembro 2025) |
| **ImportÃ¢ncia** | â­â­â­ **CRÃTICO** - Valida RQ1 efetivamente |
| **Dataset** | CIFAR10 |
| **Compression Ratios** | **2.3Ã—, 5Ã—, 7Ã—** |
| **Modelos a Treinar** | 46 modelos (1 teacher + 45 students) |
| **Plataforma** | **Kaggle** (9-12h sessÃµes vs 90min Colab) |

---

## ğŸ¯ Objetivo

**Validar efetivamente a Research Question 1 (RQ1)** do paper HPM-KD testando compression ratios **REALISTAS** (5Ã—, 7Ã—) ao invÃ©s do compression insuficiente (2Ã—) do Experimento 1.

### **Por Que Este Experimento Ã‰ CRÃTICO:**

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  â­â­â­ EXPERIMENTO MAIS IMPORTANTE DO PAPER                      â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                   â•‘
â•‘  âœ… Experimento 1 FALHOU em validar RQ1 (compression 2Ã— baixo)  â•‘
â•‘  âœ… Experimento 1B CORRIGE com compression ratios â‰¥5Ã—           â•‘
â•‘  âœ… Testa hipÃ³tese: "KD Ã© efetivo com gaps MAIORES"            â•‘
â•‘  âœ… Arquiteturas MODERNAS (ResNet50 â†’ ResNet18/10/MobileNetV2) â•‘
â•‘  âœ… Dataset DESAFIADOR (CIFAR10 com 10 classes)                â•‘
â•‘  âœ… 100% PRONTO para executar no Kaggle                        â•‘
â•‘                                                                   â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

### **Research Question:**
> Com compression ratios maiores (5Ã—, 7Ã—), HPM-KD consegue superar Direct training e validar RQ1?

---

## ğŸ”¬ Metodologia

### **HipÃ³tese Central:**

> **"Knowledge Distillation (HPM-KD) Ã© mais efetivo que Direct Training quando o gap entre teacher e student Ã© GRANDE (compression â‰¥5Ã—)"**

### **DiferenÃ§as vs Experimento 1:**

| Aspecto | Experimento 1 âŒ | Experimento 1B âœ… |
|---------|------------------|-------------------|
| **Compression** | 2Ã— (insuficiente) | **2.3Ã—, 5Ã—, 7Ã—** (realista) |
| **Teacher** | LeNet5-Large (62K) | **ResNet50 (25M)** |
| **Student** | LeNet5-Small (30K) | **ResNet18/10/MobileNetV2** |
| **Dataset** | MNIST (simples) | **CIFAR10 (desafiador)** |
| **Gap** | Pequeno | **GRANDE** |
| **Resultado** | Direct venceu | **HPM-KD deve vencer** |
| **RQ1** | âŒ NÃ£o validada | âœ… **Deve validar** |

---

## ğŸ“Š ConfiguraÃ§Ã£o

### **Dataset: CIFAR10**
- **Treinamento**: 50,000 imagens
- **Teste**: 10,000 imagens
- **Classes**: 10 (airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck)
- **ResoluÃ§Ã£o**: 32Ã—32 pixels (RGB)
- **Dificuldade**: MÃ©dia-alta

### **Compression Ratios Testados (3 ratios):**

| Compression | Teacher | Student | Params Teacher | Params Student | Ratio Real | ImportÃ¢ncia |
|-------------|---------|---------|----------------|----------------|------------|-------------|
| **2.3Ã—** | ResNet50 | ResNet18 | 25.6M | 11.2M | **2.3Ã—** | Baseline |
| **5Ã—** â­ | ResNet50 | ResNet10 | 25.6M | 5.0M | **5.0Ã—** | **CrÃ­tico** |
| **7Ã—** â­â­ | ResNet50 | MobileNetV2 | 25.6M | 3.5M | **7.3Ã—** | **Mais crÃ­tico** |

### **MÃ©todos Comparados (3 mÃ©todos):**

| # | MÃ©todo | DescriÃ§Ã£o | HiperparÃ¢metros | ReferÃªncia |
|---|--------|-----------|-----------------|------------|
| 1 | **Direct** | Treinar student do zero | - | Baseline |
| 2 | **Traditional KD** | KD clÃ¡ssico | T=4.0, Î±=0.5 | Hinton et al. (2015) |
| 3 | **HPM-KD** | Nossa proposta | T=6.0, Î±=0.7 | **Ours** â­ |

**Nota:** Reduzido de 6 para 3 mÃ©todos para focar nos mais importantes e economizar tempo.

---

## âš™ï¸ HiperparÃ¢metros

### **Quick Mode (Teste - 2-3h):**

| ParÃ¢metro | Valor |
|-----------|-------|
| **Teacher Epochs** | 50 |
| **Student Epochs** | 20 |
| **Runs por mÃ©todo** | 3 |
| **Batch Size** | 128 |
| **Learning Rate** | 0.1 |
| **Optimizer** | SGD (momentum=0.9, weight_decay=5e-4) |
| **Scheduler** | MultiStepLR [60, 120, 160] |
| **Data Augmentation** | RandomCrop, RandomHorizontalFlip |

**Modelos:** 1 teacher + (3 compression Ã— 3 mÃ©todos Ã— 3 runs) = **28 modelos**

**Tempo:** 2-3h (Kaggle GPU T4)

### **Full Mode (Paper - 8-10h):**

| ParÃ¢metro | Valor |
|-----------|-------|
| **Teacher Epochs** | 100 |
| **Student Epochs** | 50 |
| **Runs por mÃ©todo** | **5** (maior robustez) |
| **Batch Size** | 128 |
| **Learning Rate** | 0.1 |
| **Optimizer** | SGD (momentum=0.9, weight_decay=5e-4) |
| **Scheduler** | MultiStepLR [60, 120, 160] |
| **Data Augmentation** | RandomCrop, RandomHorizontalFlip |

**Modelos:** 1 teacher + (3 compression Ã— 3 mÃ©todos Ã— 5 runs) = **46 modelos**

**Tempo:** 8-10h (Kaggle GPU T4) ou 5-7h (Kaggle GPU P100)

---

## ğŸ“ˆ Resultados Esperados

### **HipÃ³tese:**

| Compression | Direct | Traditional KD | HPM-KD | Î” (HPM-KD - Direct) | ConclusÃ£o |
|-------------|--------|----------------|--------|---------------------|-----------|
| **2.3Ã—** | ~88.5% | ~88.6% | ~88.7% | **+0.2pp** | â‰ˆ Empate (gap pequeno) |
| **5Ã—** â­ | ~85.0% | ~86.5% | **~87.5%** | **+2.5pp** âœ… | **HPM-KD vence** |
| **7Ã—** â­â­ | ~82.0% | ~84.5% | **~86.0%** | **+4.0pp** âœ…âœ… | **HPM-KD vence forte** |

**Teacher Accuracy esperado:** ~92-93% (ResNet50 em CIFAR10)

### **AnÃ¡lise "When Does KD Help?":**

```
Compression 2.3Ã—:  Gap pequeno  â†’ Direct â‰ˆ HPM-KD (empate)
Compression 5Ã—:    Gap mÃ©dio   â†’ HPM-KD > Direct (+2.5pp) âœ…
Compression 7Ã—:    Gap grande  â†’ HPM-KD >> Direct (+4.0pp) âœ…âœ…

CONCLUSÃƒO: KD (HPM-KD) Ã© efetivo quando gap â‰¥ 5Ã—
```

### **Se Confirmado:**
- âœ… **RQ1 VALIDADA**: HPM-KD supera baselines com compression â‰¥5Ã—
- âœ… **Paper fortalecido**: Identificamos quando KD Ã© vantajoso
- âœ… **Figuras prontas**: accuracy_vs_compression.png para Section 5
- âœ… **PublicaÃ§Ã£o viÃ¡vel**: Resultados robustos e significativos

---

## ğŸš€ Como Executar (Kaggle)

### **Por Que Kaggle e NÃ£o Colab:**

| Aspecto | Google Colab | Kaggle âœ… |
|---------|--------------|-----------|
| **SessÃ£o** | 90 minutos | **9-12 horas** |
| **GPU/semana** | ~12h | **30h** |
| **DesconexÃµes** | Frequentes | Raras |
| **Experimento 1B** | âŒ NÃ£o completa | âœ… **Completa** |

**DecisÃ£o:** Migrado para Kaggle devido a sessÃµes longas (experimento leva 8-10h).

### **Passo 1: Setup Kaggle (2 minutos)**

1. Acesse: https://www.kaggle.com/code
2. Clique em **New Notebook**
3. **Settings** â†’ **Accelerator** â†’ **GPU T4 x2** â†’ **Save**
4. **Settings** â†’ **Internet** â†’ **ON** â†’ **Save**

### **Passo 2: Upload Script (1 minuto)**

1. Baixe: `scripts/run_exp1b_kaggle.py`
2. Kaggle â†’ **Add Data** â†’ **Upload**
3. Execute em cÃ©lula:
```python
!cp /kaggle/input/*/run_exp1b_kaggle.py /kaggle/working/
```

### **Passo 3: Executar (2-10 horas)**

#### **Quick Mode (2-3h) - Testar Pipeline:**
```python
!python /kaggle/working/run_exp1b_kaggle.py --mode quick --dataset CIFAR10
```

#### **Full Mode (8-10h) - Resultados para Paper:**
```python
!python /kaggle/working/run_exp1b_kaggle.py --mode full --dataset CIFAR10
```

#### **Compression EspecÃ­fico (1h) - Apenas 5Ã—:**
```python
!python /kaggle/working/run_exp1b_kaggle.py --mode quick --compression 5x
```

#### **Retomar se Desconectar (raro):**
```python
!python /kaggle/working/run_exp1b_kaggle.py --mode full --resume
```

### **Monitoramento:**
```python
# Ver progresso
!tail -50 /kaggle/working/experiment.log

# GPU usage
!nvidia-smi

# Checkpoints salvos
!ls -lh /kaggle/working/exp1b_*/checkpoints/
```

---

## ğŸ’¾ Sistema de Checkpoints

### **Features:**

- âœ… **Teacher reutilizado**: Treinado UMA VEZ e usado para todos os students (economia 30min-1h!)
- âœ… **Granular**: Checkpoint por experimento/mÃ©todo/run
- âœ… **Resume automÃ¡tico**: `--resume` flag retoma de onde parou
- âœ… **Robusto**: Salva estado completo (pickle) apÃ³s cada run

### **Estrutura:**
```python
checkpoints/
â”œâ”€â”€ experiment_state.pkl              # Estado completo (resume)
â”œâ”€â”€ teacher_resnet50_CIFAR10.pt      # 2.6 MB (reutilizado!)
â””â”€â”€ student_*.pt                      # 27 (quick) ou 45 (full) modelos
```

### **Se Kaggle Desconectar (raro):**
```python
!python run_exp1b_kaggle.py --mode full --resume
# Retoma de onde parou! Teacher jÃ¡ treinado nÃ£o Ã© retreinado.
```

---

## ğŸ“Š Outputs Gerados

### **Estrutura de SaÃ­da:**
```
/kaggle/working/exp1b_full_YYYYMMDD_HHMMSS/
â”œâ”€â”€ results.csv                       ğŸ“Š Dados numÃ©ricos (CSV)
â”œâ”€â”€ experiment_report.md              ğŸ“„ RelatÃ³rio completo (Markdown)
â”œâ”€â”€ experiment.log                    ğŸ“‹ Log de execuÃ§Ã£o detalhado
â”‚
â”œâ”€â”€ figures/                          ğŸ“ˆ VisualizaÃ§Ãµes (PNG 300 DPI)
â”‚   â”œâ”€â”€ accuracy_vs_compression.png  â­â­â­ FIGURA PRINCIPAL (paper)
â”‚   â”œâ”€â”€ hpmkd_vs_direct.png          â­â­ "When does KD help?"
â”‚   â””â”€â”€ retention_analysis.png       ğŸ“Š RetenÃ§Ã£o de conhecimento
â”‚
â”œâ”€â”€ checkpoints/                      ğŸ’¾ Para retomar se desconectar
â”‚   â”œâ”€â”€ experiment_state.pkl         Estado completo
â”‚   â”œâ”€â”€ teacher_resnet50_CIFAR10.pt  2.6 MB (reutilizado!)
â”‚   â””â”€â”€ student_*.pt                 27 ou 45 modelos (227 KB cada)
â”‚
â””â”€â”€ data/                             ğŸ“¦ CIFAR10 (auto-download)
    â””â”€â”€ cifar-10-batches-py/
```

**Tamanho Total:**
- Quick Mode: ~500 MB
- Full Mode: ~2 GB

### **Download:**
```
Output tab (canto superior direito) â†’ Download All (ZIP)
```

### **Figuras Geradas (PNG 300 DPI):**

1. **`accuracy_vs_compression.png`** â­â­â­ **PRINCIPAL**
   - Accuracy vs Compression Ratio
   - 3 mÃ©todos (Direct, TraditionalKD, HPM-KD)
   - Error bars (desvio padrÃ£o)
   - **USO:** Section 5 (Results) do paper

2. **`hpmkd_vs_direct.png`** â­â­
   - Delta (HPM-KD - Direct) vs Compression
   - Mostra onde KD ajuda
   - **USO:** Analysis "When does KD help?"

3. **`retention_analysis.png`** ğŸ“Š
   - Knowledge retention (%)
   - Por mÃ©todo e compression

---

## ğŸ“ Estrutura de Arquivos

```
experimento_01b_compression_ratios/
â”œâ”€â”€ README.md                          â† Este arquivo
â”‚
â”œâ”€â”€ scripts/                           â† Scripts Python
â”‚   â”œâ”€â”€ 01b_compression_ratios.py     Script original (822 linhas)
â”‚   â””â”€â”€ run_exp1b_kaggle.py           â­ Script Kaggle (810 linhas) - USAR ESTE
â”‚
â””â”€â”€ results/                           â† Resultados (vazio - aguardando execuÃ§Ã£o)
    â””â”€â”€ (outputs serÃ£o salvos aqui apÃ³s execuÃ§Ã£o)
```

---

## â±ï¸ Estimativa de Tempo

### **Kaggle GPU T4:**

| Modo | Tempo | Breakdown |
|------|-------|-----------|
| **Quick** | 2-3h | Teacher: 30min, Students: 1.5-2.5h |
| **Full** | 8-10h | Teacher: 1h, Students: 7-9h |
| **5Ã— only** | 45-60min | Teacher: 30min, Students 5Ã—: 15-30min |

### **Kaggle GPU P100 (40% mais rÃ¡pido):**

| Modo | Tempo | Breakdown |
|------|-------|-----------|
| **Quick** | 1.5-2h | Teacher: 20min, Students: 1-1.5h |
| **Full** | 5-7h | Teacher: 40min, Students: 4.5-6.5h |
| **5Ã— only** | 30-45min | Teacher: 20min, Students 5Ã—: 10-25min |

**Limite Kaggle:** 9-12h por sessÃ£o â†’ **Suficiente para Full Mode!**

**Quota Kaggle:** 30h GPU/semana grÃ¡tis

---

## ğŸ¯ AnÃ¡lise de Resultados (PÃ³s-ExecuÃ§Ã£o)

### **MÃ©tricas Principais:**

1. **Accuracy (%)**: AcurÃ¡cia no test set
2. **Retention (%)**: `(Student Acc / Teacher Acc) Ã— 100%`
3. **Î” (pp)**: DiferenÃ§a HPM-KD - Direct
4. **Statistical Significance**: t-test (p < 0.05)

### **CritÃ©rios de Sucesso (RQ1):**

```
âœ… RQ1 VALIDADA se:
  1. HPM-KD > Direct em compression 5Ã— (Î” > +1.5pp, p < 0.05)
  2. HPM-KD > Direct em compression 7Ã— (Î” > +2.5pp, p < 0.05)
  3. Figura accuracy_vs_compression mostra tendÃªncia clara

âŒ RQ1 NÃƒO VALIDADA se:
  1. Direct â‰¥ HPM-KD em todos os compression ratios
  2. DiferenÃ§as nÃ£o sÃ£o estatisticamente significativas (p > 0.05)
```

### **PossÃ­veis CenÃ¡rios:**

| CenÃ¡rio | Resultado | AÃ§Ã£o |
|---------|-----------|-------|
| **A** | HPM-KD > Direct (5Ã— e 7Ã—) | âœ… **RQ1 validada! Incluir no paper** |
| **B** | HPM-KD > Direct (apenas 7Ã—) | âš ï¸ Validado parcialmente, discutir no paper |
| **C** | Direct â‰¥ HPM-KD (todos) | âŒ RQ1 falhou, rever mÃ©todo ou hipÃ³tese |

---

## ğŸ“š DocumentaÃ§Ã£o Relacionada

### **Guias Kaggle:**
- **Quick Start:** `../../kaggle/QUICK_START_KAGGLE.md` (3 passos)
- **Guia Completo:** `../../kaggle/README_KAGGLE.md` (516 linhas)
- **Ãndice:** `../../kaggle/INDEX.md`

### **ComparaÃ§Ã£o de Plataformas:**
- **Kaggle vs Colab:** `../../README_PLATAFORMAS.md`

### **DocumentaÃ§Ã£o Geral:**
- **SumÃ¡rio Completo:** `../../SUMARIO_COMPLETO_EXPERIMENTOS.md`
- **Contagem de Modelos:** `../../CONTAGEM_MODELOS.md`

---

## âœ… Checklist de ExecuÃ§Ã£o

### **Antes de Executar:**
- [ ] Conta Kaggle criada
- [ ] Telefone verificado (libera GPU)
- [ ] Lido `../../kaggle/QUICK_START_KAGGLE.md`
- [ ] Script `run_exp1b_kaggle.py` baixado
- [ ] Notebook Kaggle criado
- [ ] GPU ativada (Settings â†’ GPU T4)
- [ ] Internet ON (Settings â†’ Internet)

### **Durante ExecuÃ§Ã£o:**
- [ ] GPU P100 ou T4 detectada
- [ ] Dataset CIFAR10 baixando
- [ ] Teacher ResNet50 treinando
- [ ] Progress bars aparecendo
- [ ] Checkpoints salvando automaticamente
- [ ] NÃ£o fechar aba do navegador

### **ApÃ³s ExecuÃ§Ã£o:**
- [ ] Ver `results.csv` (dados numÃ©ricos)
- [ ] Ler `experiment_report.md` (relatÃ³rio)
- [ ] Analisar `accuracy_vs_compression.png` â­â­â­
- [ ] Download All (Output tab)
- [ ] Save Version (guardar outputs permanentemente)
- [ ] Incluir figuras no paper (Section 5)
- [ ] Atualizar paper com resultados
- [ ] Validar RQ1 âœ… ou âŒ

---

## ğŸ‰ ConclusÃ£o

### **Por Que Este Experimento Ã‰ Essencial:**

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                            â•‘
â•‘  Este Ã© o EXPERIMENTO MAIS IMPORTANTE do paper HPM-KD!   â•‘
â•‘                                                            â•‘
â•‘  âœ… Corrige o problema do Experimento 1 (compression 2Ã—) â•‘
â•‘  âœ… Testa compression ratios REALISTAS (5Ã—, 7Ã—)          â•‘
â•‘  âœ… Valida efetivamente RQ1 do paper                     â•‘
â•‘  âœ… 100% pronto para executar no Kaggle                  â•‘
â•‘  âœ… Resultados em 8-10h (Full Mode)                      â•‘
â•‘  âœ… Figuras prontas para publicaÃ§Ã£o                      â•‘
â•‘                                                            â•‘
â•‘  SEM ESTE EXPERIMENTO, O PAPER NÃƒO TEM VALIDAÃ‡ÃƒO DE RQ1! â•‘
â•‘                                                            â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

### **PrÃ³ximo Passo:**
**EXECUTAR AGORA NO KAGGLE!** ğŸš€

1. Leia `../../kaggle/QUICK_START_KAGGLE.md` (5 minutos)
2. Upload `scripts/run_exp1b_kaggle.py` no Kaggle
3. Execute Quick Mode (2-3h) para testar
4. Execute Full Mode (8-10h) para o paper
5. Aguarde resultados e valide RQ1

---

**Criado:** Dezembro 2025
**Ãšltima AtualizaÃ§Ã£o:** Dezembro 2025
**Status:** â³ Pronto para Executar
**ImportÃ¢ncia:** â­â­â­ **CRÃTICO**
**Autor:** Gustavo Haase
**Paper:** HPM-KD Framework
