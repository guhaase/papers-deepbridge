# Experimento 1: Compression Efficiency

## ğŸ“‹ InformaÃ§Ãµes Gerais

| ParÃ¢metro | Valor |
|-----------|-------|
| **Experimento** | Experimento 1 - Compression Efficiency |
| **Research Question** | RQ1: HPM-KD consegue alcanÃ§ar maiores taxas de compressÃ£o mantendo acurÃ¡cia vs baselines? |
| **Status** | âœ… **CONCLUÃDO** (Novembro 2025) |
| **Dataset** | MNIST |
| **Compression Ratio** | **2Ã— (LeNet5-Large â†’ LeNet5-Small)** |
| **Modelos Treinados** | 31 modelos (1 teacher + 30 students) |

---

## ğŸ¯ Objetivo

Validar a **Research Question 1 (RQ1)** do paper HPM-KD, comparando a eficiÃªncia de compressÃ£o do mÃ©todo proposto (HPM-KD) contra 5 baselines estado-da-arte.

### **Research Question:**
> HPM-KD consegue alcanÃ§ar maiores taxas de compressÃ£o mantendo acurÃ¡cia comparado aos mÃ©todos estado-da-arte?

---

## ğŸ”¬ Metodologia

### **Experimentos IncluÃ­dos:**
1. **Baseline Comparison** - Compara HPM-KD vs 5 baselines em MNIST
2. **Compression Ratio Scaling** - Testa ratio de 2Ã—
3. **Statistical Significance** - Testes t para validar diferenÃ§as

### **Baselines Comparados (6 mÃ©todos):**

| # | MÃ©todo | DescriÃ§Ã£o | ReferÃªncia |
|---|--------|-----------|------------|
| 1 | **Direct** | Treinar student do zero (baseline) | - |
| 2 | **Traditional KD** | Knowledge Distillation clÃ¡ssico | Hinton et al. (2015) |
| 3 | **FitNets** | Hint-based KD | Romero et al. (2015) |
| 4 | **AT** | Attention Transfer | Zagoruyko & Komodakis (2017) |
| 5 | **TAKD** | Teacher Assistant KD | Mirzadeh et al. (2020) |
| 6 | **HPM-KD** | Nossa proposta (DeepBridge Library) | **Ours** â­ |

---

## ğŸ“Š ConfiguraÃ§Ã£o

### **Dataset:**
- **MNIST**: 60,000 imagens de treinamento, 10,000 de teste
- **Classes**: 10 dÃ­gitos (0-9)
- **ResoluÃ§Ã£o**: 28Ã—28 pixels (grayscale)

### **Arquiteturas:**

| Modelo | Arquitetura | ParÃ¢metros | DescriÃ§Ã£o |
|--------|-------------|------------|-----------|
| **Teacher** | LeNet5-Large | 62,006 | Modelo maior (professor) |
| **Student** | LeNet5-Small | 30,206 | Modelo menor (aluno) |

### **Compression Ratio:**
```
Compression = Teacher Params / Student Params
            = 62,006 / 30,206
            = 2.05Ã—
```

### **HiperparÃ¢metros (Full Mode):**

| ParÃ¢metro | Valor |
|-----------|-------|
| **Runs por mÃ©todo** | 5 (para robustez estatÃ­stica) |
| **Teacher Epochs** | 100 |
| **Student Epochs** | 50 |
| **Batch Size** | 128 |
| **Learning Rate** | 0.1 |
| **Optimizer** | SGD com momentum 0.9 |
| **Loss** | CrossEntropyLoss |

### **Modos de ExecuÃ§Ã£o:**

| Modo | Teacher Epochs | Student Epochs | Runs | Tempo Estimado |
|------|----------------|----------------|------|----------------|
| **Quick** | 50 | 20 | 3 | 45 minutos |
| **Full** | 100 | 50 | 5 | 3-4 horas |

---

## ğŸ“ˆ Resultados Obtidos

### **Accuracy dos MÃ©todos (MNIST):**

| Rank | MÃ©todo | Accuracy (%) | Desvio PadrÃ£o | Status |
|------|--------|--------------|---------------|--------|
| **1Âº** ğŸ¥‡ | **Direct** | **68.10%** | Â±0.15 | **MELHOR** |
| 2Âº | HPM-KD | 67.74% | Â±0.18 | -0.36pp vs Direct |
| 3Âº | TAKD | 67.70% | Â±0.12 | -0.40pp vs Direct |
| 4Âº | FitNets | 67.52% | Â±0.20 | -0.58pp vs Direct |
| 5Âº | AT | 67.38% | Â±0.16 | -0.72pp vs Direct |
| 6Âº | TraditionalKD | 67.28% | Â±0.14 | -0.82pp vs Direct |

**Teacher Accuracy:** 90.50%

### **RetenÃ§Ã£o de Conhecimento:**

```
Retention = (Student Acc / Teacher Acc) Ã— 100%

Direct:        75.2% retention
HPM-KD:        74.8% retention
TAKD:          74.8% retention
```

---

## âš ï¸ AnÃ¡lise CrÃ­tica

### **PROBLEMA IDENTIFICADO:**

#### **Compression Ratio Insuficiente (2Ã—)**

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  âš ï¸  PROBLEMA: Compression 2Ã— Ã© MUITO PEQUENO!              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

LeNet5-Large:   62,006 parÃ¢metros
LeNet5-Small:   30,206 parÃ¢metros
Compression:    2.05Ã— apenas

Com compression tÃ£o pequeno:
  âŒ Student tem capacidade SUFICIENTE para aprender sozinho
  âŒ Direct training alcanÃ§a melhor performance
  âŒ Knowledge Distillation nÃ£o traz vantagem (overhead)
  âŒ HPM-KD nÃ£o demonstra superioridade
```

### **Por Que Direct Venceu:**

1. **Gap muito pequeno** entre teacher e student
2. **Student capacitado** (30K params suficiente para MNIST)
3. **Overhead de KD** nÃ£o compensa com compression baixo
4. **Direct training** mais simples e efetivo neste cenÃ¡rio

### **Insight Importante:**

> **"Knowledge Distillation Ã© mais efetivo com compression ratios MAIORES (â‰¥5Ã—)"**

Quando o gap entre teacher e student Ã© pequeno (2Ã—), o student consegue aprender diretamente dos dados sem precisar da "orientaÃ§Ã£o" do teacher.

---

## âœ… ValidaÃ§Ã£o Sklearn (MNIST)

Antes do experimento principal, foi realizada validaÃ§Ã£o com modelos sklearn:

| MÃ©trica | Valor |
|---------|-------|
| **Accuracy** | 91.67% |
| **F1-Score** | 91.50% |
| **Precision** | 91.80% |
| **Recall** | 91.67% |

**Status:** âœ… ValidaÃ§Ã£o bem-sucedida

**LocalizaÃ§Ã£o:** `results/sklearn/`

---

## ğŸ“ Estrutura de Arquivos

```
experimento_01_compression_efficiency/
â”œâ”€â”€ README.md                          â† Este arquivo
â”‚
â”œâ”€â”€ scripts/                           â† Scripts Python
â”‚   â””â”€â”€ 01_compression_efficiency.py   (810 linhas, 44 KB)
â”‚
â””â”€â”€ results/                           â† Resultados
    â”œâ”€â”€ results_full_20251112_111138/  â† Experimento principal
    â”‚   â”œâ”€â”€ exp_01_01_compression_efficiency/
    â”‚   â”‚   â”œâ”€â”€ results_comparison.csv
    â”‚   â”‚   â”œâ”€â”€ experiment_report.md
    â”‚   â”‚   â”œâ”€â”€ 01_compression_efficiency.log
    â”‚   â”‚   â”œâ”€â”€ figures/
    â”‚   â”‚   â”‚   â”œâ”€â”€ accuracy_comparison.png
    â”‚   â”‚   â”‚   â”œâ”€â”€ retention_analysis.png
    â”‚   â”‚   â”‚   â””â”€â”€ statistical_significance.png
    â”‚   â”‚   â””â”€â”€ models/
    â”‚   â”‚       â”œâ”€â”€ teacher_lenet5large_MNIST.pt
    â”‚   â”‚       â””â”€â”€ student_*.pt (30 modelos)
    â”‚   â””â”€â”€ run_all_experiments.log
    â”‚
    â””â”€â”€ sklearn/                       â† ValidaÃ§Ã£o sklearn
        â”œâ”€â”€ experiment_results.json
        â”œâ”€â”€ confusion_matrix.png
        â””â”€â”€ classification_report.txt
```

---

## ğŸš€ Como Executar

### **PrÃ©-requisitos:**
```bash
pip install torch torchvision numpy pandas matplotlib seaborn scipy tqdm
pip install deepbridge  # DeepBridge Library (HPM-KD)
```

### **ExecuÃ§Ã£o Quick Mode (45 min):**
```bash
cd scripts/
python 01_compression_efficiency.py --mode quick --datasets MNIST
```

### **ExecuÃ§Ã£o Full Mode (3-4h):**
```bash
cd scripts/
python 01_compression_efficiency.py --mode full --datasets MNIST
```

### **OpÃ§Ãµes:**
```bash
--mode {quick,full}        # Modo de execuÃ§Ã£o
--datasets {MNIST,FashionMNIST,CIFAR10}  # Datasets (mÃºltiplos)
--gpu 0                    # GPU a usar (default: 0)
--seed 42                  # Seed para reprodutibilidade
```

---

## ğŸ“Š Modelos Treinados

### **Total de Modelos:**

| Tipo | Quantidade | DescriÃ§Ã£o |
|------|------------|-----------|
| **Teachers** | 1 | LeNet5-Large (62K params) |
| **Students** | 30 | 6 mÃ©todos Ã— 5 runs |
| **TOTAL** | **31** | |

### **Breakdown por MÃ©todo:**

```
Direct:        5 modelos (1 por run)
TraditionalKD: 5 modelos (1 por run)
FitNets:       5 modelos (1 por run)
AT:            5 modelos (1 por run)
TAKD:          5 modelos (1 por run)
HPM-KD:        5 modelos (1 por run)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TOTAL:        30 students + 1 teacher = 31 modelos
```

---

## ğŸ¯ ConclusÃµes

### **âœ… Experimento Executado com Sucesso**
- 31 modelos treinados corretamente
- Resultados estatisticamente robustos (5 runs por mÃ©todo)
- Todos os baselines implementados e testados

### **âŒ RQ1 NÃƒO Validada**
- Compression ratio 2Ã— muito pequeno
- Direct training superou todos os mÃ©todos de KD
- HPM-KD nÃ£o demonstrou superioridade esperada

### **ğŸ’¡ Insight Obtido:**
> **Knowledge Distillation (incluindo HPM-KD) Ã© mais efetivo com compression ratios MAIORES (â‰¥5Ã—)**

### **ğŸš¨ AÃ§Ã£o NecessÃ¡ria:**
**EXECUTAR EXPERIMENTO 1B** com compression ratios maiores:
- 2.3Ã— (ResNet50 â†’ ResNet18)
- **5Ã—** (ResNet50 â†’ ResNet10) â­
- **7Ã—** (ResNet50 â†’ MobileNetV2) â­â­

**LocalizaÃ§Ã£o:** `../experimento_01b_compression_ratios/`

---

## ğŸ“š ReferÃªncias

1. **Hinton et al. (2015)** - "Distilling the Knowledge in a Neural Network"
2. **Romero et al. (2015)** - "FitNets: Hints for Thin Deep Nets"
3. **Zagoruyko & Komodakis (2017)** - "Paying More Attention to Attention"
4. **Mirzadeh et al. (2020)** - "Improved Knowledge Distillation via Teacher Assistant"

---

## ğŸ“ InformaÃ§Ãµes Adicionais

### **Status do Experimento:**
- âœ… ImplementaÃ§Ã£o completa
- âœ… ExecuÃ§Ã£o bem-sucedida
- âœ… Resultados reproduzÃ­veis
- âš ï¸ RQ1 nÃ£o validada (compression insuficiente)

### **PrÃ³ximos Passos:**
1. âœ… Experimento 1 concluÃ­do (este experimento)
2. â³ **EXECUTAR EXPERIMENTO 1B** (CRÃTICO) - Compression ratios maiores
3. ğŸ“‹ Experimento 2 (Ablation Studies)
4. ğŸ“‹ Experimento 3 (Generalization)
5. ğŸ“‹ Experimento 4 (Computational Efficiency)

### **Relacionado:**
- **Experimento 1B:** `../experimento_01b_compression_ratios/` - **CRÃTICO PARA RQ1**
- **DocumentaÃ§Ã£o Geral:** `../SUMARIO_COMPLETO_EXPERIMENTOS.md`
- **Contagem de Modelos:** `../CONTAGEM_MODELOS.md`

---

**Criado:** Dezembro 2025
**Ãšltima AtualizaÃ§Ã£o:** Dezembro 2025
**Status:** âœ… Experimento ConcluÃ­do
**Autor:** Gustavo Haase
**Paper:** HPM-KD Framework - Hierarchical Progressive Multi-Teacher Knowledge Distillation
