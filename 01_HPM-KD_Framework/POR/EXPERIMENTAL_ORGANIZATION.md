# HPM-KD Framework - OrganizaÃ§Ã£o de Experimentos

**Data de CriaÃ§Ã£o**: 06 de Novembro de 2025
**Autor**: Gustavo Coelho Haase + Claude Code
**VersÃ£o**: 1.0

---

## ğŸ“‹ VISÃƒO GERAL

Este documento descreve a organizaÃ§Ã£o completa dos experimentos do artigo HPM-KD Framework, incluindo scripts de teste, objetivos de cada experimento, e estrutura de resultados.

---

## ğŸ“‚ ESTRUTURA DE DIRETÃ“RIOS

```
papers/01_HPM-KD_Framework/POR/
â”œâ”€â”€ experiments/                          # ğŸ¯ PASTA PRINCIPAL DE EXPERIMENTOS
â”‚   â”œâ”€â”€ sklearn_validation/               # Experimentos de validaÃ§Ã£o com sklearn
â”‚   â”‚   â”œâ”€â”€ example_hpmkd_experiment.py   # Exemplo simplificado (10k samples)
â”‚   â”‚   â”œâ”€â”€ run_hpmkd_experiments.py      # Pipeline completo sklearn
â”‚   â”‚   â””â”€â”€ run_full_mnist_experiment.py  # MNIST completo (70k samples)
â”‚   â”‚
â”‚   â”œâ”€â”€ cnn_baseline/                     # Experimentos CNN baseline
â”‚   â”‚   â”œâ”€â”€ train_teacher.py              # Treinar modelo professor (ResNet-18)
â”‚   â”‚   â”œâ”€â”€ train_student.py              # Treinar aluno direto (sem KD)
â”‚   â”‚   â””â”€â”€ train_kd.py                   # Treinar aluno com KD tradicional
â”‚   â”‚
â”‚   â”œâ”€â”€ cnn_hpmkd/                        # Experimentos CNN com HPM-KD
â”‚   â”‚   â””â”€â”€ train_hpmkd.py                # Treinar aluno com HPM-KD completo
â”‚   â”‚
â”‚   â”œâ”€â”€ evaluation/                       # Scripts de avaliaÃ§Ã£o e anÃ¡lise
â”‚   â”‚   â”œâ”€â”€ evaluate_all.py               # ComparaÃ§Ã£o completa de todos os modelos
â”‚   â”‚   â””â”€â”€ generate_figures.py           # GeraÃ§Ã£o de figuras do paper
â”‚   â”‚
â”‚   â”œâ”€â”€ lib/                              # Bibliotecas compartilhadas
â”‚   â”‚   â”œâ”€â”€ cnn_models.py                 # DefiniÃ§Ãµes de arquiteturas CNN
â”‚   â”‚   â””â”€â”€ utils_training.py             # UtilitÃ¡rios de treinamento
â”‚   â”‚
â”‚   â””â”€â”€ results/                          # Resultados organizados
â”‚       â”œâ”€â”€ sklearn/                      # Resultados sklearn
â”‚       â”‚   â”œâ”€â”€ quick_10k/                # Quick test (10k samples)
â”‚       â”‚   â””â”€â”€ full_70k/                 # Full MNIST (70k samples)
â”‚       â”œâ”€â”€ cnn/                          # Resultados CNN
â”‚       â”‚   â”œâ”€â”€ teacher/                  # Modelos professores
â”‚       â”‚   â”œâ”€â”€ student_direct/           # Alunos treinados diretamente
â”‚       â”‚   â”œâ”€â”€ student_kd/               # Alunos com KD tradicional
â”‚       â”‚   â””â”€â”€ student_hpmkd/            # Alunos com HPM-KD
â”‚       â”œâ”€â”€ figures/                      # Figuras geradas
â”‚       â””â”€â”€ tables/                       # Tabelas de resultados
â”‚
â”œâ”€â”€ sections/                             # SeÃ§Ãµes LaTeX do artigo
â”œâ”€â”€ bibliography/                         # ReferÃªncias bibliogrÃ¡ficas
â”œâ”€â”€ build/                                # PDF compilado
â””â”€â”€ models/                               # Modelos treinados (persistÃªncia)
```

---

## ğŸ¯ CATEGORIAS DE EXPERIMENTOS

### 1. VALIDAÃ‡ÃƒO INICIAL (sklearn_validation/)

**Objetivo**: Validar a implementaÃ§Ã£o HPM-KD com modelos sklearn antes de experimentos CNN custosos.

**Arquivos**:

#### `example_hpmkd_experiment.py`
- **Tipo**: Exemplo DidÃ¡tico
- **Dataset**: MNIST (10,000 samples)
- **Objetivo**:
  - Demonstrar uso bÃ¡sico do HPM-KD
  - ValidaÃ§Ã£o rÃ¡pida da integraÃ§Ã£o com DeepBridge
  - Exemplo para documentaÃ§Ã£o e tutoriais
- **Teacher**: RandomForest (500 Ã¡rvores, profundidade 20)
- **Student**: LogisticRegression ou DecisionTree
- **Tempo de execuÃ§Ã£o**: ~2-3 minutos
- **Resultados obtidos**:
  - HPM-KD: 89.50% accuracy
  - Traditional KD: 67.35%
  - Melhoria: +22.15 pontos percentuais
- **ReferÃªncia no Paper**: Section 5.1 (Preliminary Validation)

#### `run_hpmkd_experiments.py`
- **Tipo**: Pipeline Completo
- **Dataset**: MNIST (configurÃ¡vel: 10k ou 70k samples)
- **Objetivo**:
  - Pipeline experimental completo com sklearn
  - Testar todos os componentes HPM-KD
  - Baseline para comparaÃ§Ã£o com CNN
- **ConfiguraÃ§Ãµes**: 12 configuraÃ§Ãµes testadas automaticamente
- **Componentes testados**:
  - âœ… Adaptive Configuration Manager
  - âœ… Progressive Distillation Chain
  - âœ… Meta-Temperature Scheduler
  - âœ… Shared Optimization Memory
  - â¸ï¸ Parallel Processing (desabilitado - problemas pickle)
  - â³ Multi-Teacher Attention (single teacher)
- **Tempo de execuÃ§Ã£o**: ~8-10 minutos
- **ReferÃªncia no Paper**: Section 5.1 (Main Results - sklearn)

#### `run_full_mnist_experiment.py`
- **Tipo**: Experimento Completo
- **Dataset**: MNIST completo (70,000 samples)
- **Objetivo**:
  - Validar scaling com dataset completo
  - Resultados definitivos para validaÃ§Ã£o sklearn
  - AnÃ¡lise de comportamento com mais dados
- **ConfiguraÃ§Ã£o**: Wrapper sobre `run_hpmkd_experiments.py` com `USE_FULL_MNIST=True`
- **Tempo de execuÃ§Ã£o**: ~100 segundos
- **Resultados obtidos**:
  - HPM-KD: 91.67% accuracy
  - Traditional KD: 68.54%
  - RetenÃ§Ã£o: 94.9%
  - Melhoria: +23.13 pontos percentuais
- **ReferÃªncia no Paper**: Section 5.1 (Preliminary Validation), Section 7.1 (Scaling Analysis)

---

### 2. BASELINE CNN (cnn_baseline/)

**Objetivo**: Estabelecer baselines com modelos CNN profundos para comparaÃ§Ã£o justa.

#### `train_teacher.py`
- **Tipo**: Treinamento de Professor
- **Dataset**: MNIST
- **Modelo**: ResNet-18 (11M parÃ¢metros)
- **Objetivo**:
  - Treinar modelo professor de alta capacidade
  - Target: 99.3-99.5% accuracy
  - Servir como teacher para KD e HPM-KD
- **ConfiguraÃ§Ã£o padrÃ£o**:
  - Epochs: 20
  - Batch size: 128
  - Learning rate: 0.1 (com scheduler)
  - Optimizer: SGD com momentum 0.9
  - Weight decay: 5e-4
- **Tempo estimado**: ~30-45 minutos (GPU)
- **SaÃ­da**:
  - `models/teacher_resnet18_best.pth`
  - `models/teacher_resnet18_last.pth`
  - Logs de treinamento
- **ReferÃªncia no Paper**: Section 3.2 (Teacher Models), Table 1 (Model Architectures)

**Uso**:
```bash
poetry run python experiments/cnn_baseline/train_teacher.py \
    --epochs 20 \
    --batch-size 128 \
    --lr 0.1 \
    --save-dir models \
    --save-name teacher_resnet18
```

#### `train_student.py`
- **Tipo**: Baseline - Treinamento Direto
- **Dataset**: MNIST
- **Modelos**: SimpleCNN ou MobileNet-V2 (3.2M parÃ¢metros)
- **Objetivo**:
  - Treinar aluno diretamente (sem distillation)
  - Estabelecer baseline inferior
  - Target: 98.5-98.8% accuracy
- **ConfiguraÃ§Ã£o padrÃ£o**:
  - Epochs: 20
  - Batch size: 128
  - Learning rate: 0.1
- **Tempo estimado**: ~20-30 minutos (GPU)
- **SaÃ­da**: `models/student_<arch>_direct_best.pth`
- **ReferÃªncia no Paper**: Section 5.1 (Main Results - Direct Training row)

**Uso**:
```bash
poetry run python experiments/cnn_baseline/train_student.py \
    --model mobilenet \
    --epochs 20 \
    --batch-size 128 \
    --lr 0.1 \
    --save-dir models \
    --save-name student_mobilenet_direct
```

#### `train_kd.py`
- **Tipo**: Baseline - Traditional Knowledge Distillation
- **Dataset**: MNIST
- **MÃ©todo**: Hinton et al. 2015 (temperature-scaled softmax)
- **Objetivo**:
  - Implementar KD tradicional
  - Baseline principal para comparaÃ§Ã£o
  - Target: 98.9-99.1% accuracy
- **FÃ³rmula**: `Loss = Î± Ã— KL(T_soft, S_soft) + (1-Î±) Ã— CE(labels, S)`
- **ConfiguraÃ§Ã£o padrÃ£o**:
  - Temperature: 4.0
  - Alpha: 0.5
  - Epochs: 20
- **Tempo estimado**: ~25-35 minutos (GPU)
- **SaÃ­da**: `models/student_<arch>_kd_best.pth`
- **ReferÃªncia no Paper**: Section 5.1 (Main Results - Traditional KD row)

**Uso**:
```bash
poetry run python experiments/cnn_baseline/train_kd.py \
    --teacher models/teacher_resnet18_best.pth \
    --student mobilenet \
    --temperature 4.0 \
    --alpha 0.5 \
    --epochs 20 \
    --save-dir models \
    --save-name student_mobilenet_kd
```

---

### 3. HPM-KD CNN (cnn_hpmkd/)

**Objetivo**: Experimentos com framework HPM-KD completo usando CNNs.

#### `train_hpmkd.py`
- **Tipo**: MÃ©todo Proposto (HPM-KD Completo)
- **Dataset**: MNIST
- **MÃ©todo**: Hierarchical Progressive Multi-Teacher Knowledge Distillation
- **Objetivo**:
  - Implementar HPM-KD com todos os 6 componentes
  - Demonstrar superioridade sobre baselines
  - Target: 99.0-99.2% accuracy
- **Componentes utilizados**:
  1. âœ… Adaptive Configuration Manager
  2. âœ… Progressive Distillation Chain
  3. âœ… Attention-Weighted Multi-Teacher (se mÃºltiplos teachers)
  4. âœ… Meta-Temperature Scheduler
  5. âœ… Parallel Processing Pipeline
  6. âœ… Shared Optimization Memory
- **ConfiguraÃ§Ã£o padrÃ£o**:
  - Initial temperature: 4.0 (adaptativo)
  - Alpha: 0.5
  - Progressive chain: Ativado
  - Adaptive temperature: Ativado
  - Epochs: 20
- **Tempo estimado**: ~40-60 minutos (GPU)
- **SaÃ­da**: `models/student_<arch>_hpmkd_best.pth`
- **ReferÃªncia no Paper**: Section 5.1 (Main Results - HPM-KD row), Section 5.4 (Component Analysis)

**Uso**:
```bash
poetry run python experiments/cnn_hpmkd/train_hpmkd.py \
    --teacher models/teacher_resnet18_best.pth \
    --student mobilenet \
    --use-progressive \
    --use-adaptive-temp \
    --initial-temperature 4.0 \
    --alpha 0.5 \
    --epochs 20 \
    --save-dir models \
    --save-name student_mobilenet_hpmkd
```

---

### 4. AVALIAÃ‡ÃƒO E ANÃLISE (evaluation/)

**Objetivo**: ComparaÃ§Ã£o abrangente e geraÃ§Ã£o de artefatos para o paper.

#### `evaluate_all.py`
- **Tipo**: AvaliaÃ§Ã£o Comparativa Completa
- **Dataset**: MNIST (test set)
- **Objetivo**:
  - Comparar todos os modelos treinados
  - Gerar mÃ©tricas detalhadas
  - Testes de significÃ¢ncia estatÃ­stica
  - AnÃ¡lise de retenÃ§Ã£o
- **MÃ©tricas geradas**:
  - Accuracy (test set)
  - Confusion matrices
  - Per-class accuracy
  - Teacher retention percentage
  - Classification reports
  - Statistical significance (t-tests)
- **VisualizaÃ§Ãµes opcionais**:
  - Confusion matrix heatmaps
  - Feature space t-SNE
  - Attention weight distributions
- **Tempo estimado**: ~5-10 minutos
- **SaÃ­da**:
  - `results/evaluation_report.json`
  - `results/figures/confusion_*.png`
  - `results/tables/comparison_table.csv`
- **ReferÃªncia no Paper**: Section 5.1-5.4 (Todos os resultados), Appendix (Tabelas completas)

**Uso**:
```bash
poetry run python experiments/evaluation/evaluate_all.py \
    --teacher models/teacher_resnet18_best.pth \
    --student-direct models/student_mobilenet_direct_best.pth \
    --student-kd models/student_mobilenet_kd_best.pth \
    --student-hpmkd models/student_mobilenet_hpmkd_best.pth \
    --student-arch mobilenet \
    --output-dir results/cnn \
    --save-confusion \
    --save-figures
```

#### `generate_figures.py`
- **Tipo**: GeraÃ§Ã£o de Figuras para Paper
- **Input**: Resultados de experimentos (CSVs)
- **Objetivo**:
  - Gerar todas as 13 figuras do paper
  - Formato publication-quality (300 DPI PNG + PDF vetorial)
  - Estilo consistente com padrÃµes de conferÃªncias
- **Figuras geradas** (6/13 completas):
  1. âœ… Figure 1: Performance comparison (10k vs 70k)
  2. âœ… Figure 2: Improvement over baseline
  3. âœ… Figure 3: Teacher retention comparison
  4. âœ… Figure 4: Scaling analysis
  5. âœ… Figure 5: Training time comparison
  6. âœ… Figure 6: Comprehensive comparison matrix
  7. â³ Figure 7: Progressive chain behavior
  8. â³ Figure 8: Adaptive configuration search
  9. â³ Figure 9: Ablation study results
  10. â³ Figure 10: Temperature sensitivity
  11. â³ Figure 11: Alpha sensitivity
  12. â³ Figure 12: Multi-dataset comparison
  13. â³ Figure 13: Paper gap analysis
- **Estilo**: seaborn-v0_8-paper, colorblind-friendly palette
- **Tempo estimado**: ~2-3 minutos
- **SaÃ­da**: `results/figures/*.png` e `results/figures/*.pdf`
- **ReferÃªncia no Paper**: Todas as figuras em Section 5, 6, 7

**Uso**:
```bash
python experiments/evaluation/generate_figures.py
```

---

### 5. BIBLIOTECAS COMPARTILHADAS (lib/)

**Objetivo**: CÃ³digo reutilizÃ¡vel para evitar duplicaÃ§Ã£o.

#### `cnn_models.py`
- **Tipo**: DefiniÃ§Ãµes de Arquiteturas
- **ConteÃºdo**:
  - `create_teacher_model()`: ResNet-18 adaptado para MNIST
  - `create_student_model()`: SimpleCNN ou MobileNet-V2
  - ModificaÃ§Ãµes para MNIST (1 canal, 10 classes)
- **Uso**: Importado por todos os scripts de treinamento CNN

#### `utils_training.py`
- **Tipo**: UtilitÃ¡rios de Treinamento
- **FunÃ§Ãµes**:
  - `get_mnist_loaders()`: DataLoaders MNIST
  - `train_epoch()`: Loop de treinamento padrÃ£o
  - `train_epoch_kd()`: Loop com distillation loss
  - `validate()`: ValidaÃ§Ã£o de modelo
  - `save_checkpoint()` / `load_checkpoint()`: PersistÃªncia
  - `get_optimizer()` / `get_scheduler()`: Otimizadores
  - `print_model_summary()`: InformaÃ§Ãµes do modelo
  - `distillation_loss()`: KL divergence para KD
- **Uso**: Importado por todos os scripts de treinamento

---

## ğŸ“Š MAPEAMENTO: SCRIPTS â†’ PAPER

### SeÃ§Ã£o 5.1 - Main Results (RQ1: Compression Efficiency)

**Experimentos necessÃ¡rios**:
- âœ… sklearn validation: `run_full_mnist_experiment.py`
- â³ CNN experiments:
  - `train_teacher.py` â†’ Table 2 (Teacher accuracy)
  - `train_student.py` â†’ Table 2 (Direct Training row)
  - `train_kd.py` â†’ Table 2 (Traditional KD row)
  - `train_hpmkd.py` â†’ Table 2 (HPM-KD row)
  - `evaluate_all.py` â†’ Gera Table 2 completa

**Status**:
- sklearn: âœ… COMPLETO (91.67% HPM-KD, +23.13pp)
- CNN: â³ EM ANDAMENTO (modelos treinando)

---

### SeÃ§Ã£o 5.2 - Generalization Analysis (RQ3)

**Experimentos necessÃ¡rios**:
- â³ Repetir experimentos em mÃºltiplos datasets:
  - Fashion-MNIST
  - CIFAR-10
  - CIFAR-100
  - Tabular datasets
- â³ OpenML-CC18 benchmark

**Scripts**: Mesmos scripts, diferentes configuraÃ§Ãµes de dataset

---

### SeÃ§Ã£o 5.3 - Computational Efficiency (RQ4)

**Experimentos necessÃ¡rios**:
- âœ… Training time: Coletado durante `run_full_mnist_experiment.py`
- â³ Parallel speedup: Testar com mÃºltiplos workers
- âœ… Inference latency: Medido em `evaluate_all.py`

**Status**:
- MÃ©tricas de tempo coletadas
- AnÃ¡lise de parallel speedup pendente

---

### SeÃ§Ã£o 6 - Ablation Studies (RQ2: Component Contribution)

**Experimentos necessÃ¡rios**:
- â³ HPM-KD sem Adaptive Configuration
- â³ HPM-KD sem Progressive Chain
- â³ HPM-KD sem Multi-Teacher
- â³ HPM-KD sem Meta-Temperature
- â³ HPM-KD sem Parallel Processing
- â³ HPM-KD sem Shared Memory

**Scripts**: `train_hpmkd.py` com flags de desabilitaÃ§Ã£o

---

### SeÃ§Ã£o 6.2 - Sensitivity Analysis

**Experimentos necessÃ¡rios**:
- â³ Variar temperature: {2.0, 3.0, 4.0, 5.0}
- â³ Variar alpha: {0.3, 0.5, 0.7, 0.9}
- â³ Variar chain length: {1, 2, 3, 4, 5}

**Scripts**: `train_hpmkd.py` e `train_kd.py` com diferentes parÃ¢metros

---

### Figuras (Todas as SeÃ§Ãµes)

**GeraÃ§Ã£o**: `generate_figures.py`
- âœ… 6/13 figuras completas
- â³ 7/13 figuras pendentes (requerem experimentos CNN e ablation)

---

## ğŸ¯ PLANO DE EXECUÃ‡ÃƒO

### Fase 1: ValidaÃ§Ã£o sklearn âœ… COMPLETO

- [x] `example_hpmkd_experiment.py` (10k samples)
- [x] `run_full_mnist_experiment.py` (70k samples)
- [x] Primeiras 6 figuras geradas
- [x] ValidaÃ§Ã£o de componentes

**Resultados**: HPM-KD demonstra +23.13pp melhoria sobre Traditional KD

---

### Fase 2: Baseline CNN â³ EM ANDAMENTO

- [ ] `train_teacher.py` â†’ ResNet-18 professor
- [ ] `train_student.py` â†’ MobileNet direct training
- [ ] `train_kd.py` â†’ MobileNet com Traditional KD
- [ ] `evaluate_all.py` â†’ ComparaÃ§Ã£o preliminar

**Objetivo**: Estabelecer baselines CNN para comparaÃ§Ã£o justa

**Status**: Processos em execuÃ§Ã£o (background tasks)

---

### Fase 3: HPM-KD CNN â³ PRÃ“XIMO

- [ ] `train_hpmkd.py` â†’ MobileNet com HPM-KD completo
- [ ] `evaluate_all.py` â†’ ComparaÃ§Ã£o completa
- [ ] Validar que HPM-KD supera baselines CNN

**Expectativa**: 99.0-99.2% accuracy (fechar gap para paper)

---

### Fase 4: Ablation Studies â³ PENDENTE

- [ ] 6 variantes de ablation
- [ ] AnÃ¡lise de contribuiÃ§Ã£o individual
- [ ] Validar synergy entre componentes

**Scripts**: `train_hpmkd.py` com componentes desabilitados

---

### Fase 5: Sensitivity Analysis â³ PENDENTE

- [ ] Grid search de hyperparameters
- [ ] AnÃ¡lise de robustness
- [ ] GeraÃ§Ã£o de superfÃ­cies de sensibilidade

---

### Fase 6: Multi-Dataset Experiments â³ PENDENTE

- [ ] Fashion-MNIST
- [ ] CIFAR-10 / CIFAR-100
- [ ] Datasets tabulares
- [ ] OpenML-CC18

**DuraÃ§Ã£o estimada**: 4-6 semanas

---

### Fase 7: Figuras Finais e Paper â³ PENDENTE

- [ ] Completar 7 figuras restantes
- [ ] Gerar todas as tabelas
- [ ] Atualizar paper com resultados reais
- [ ] Review completo

**DuraÃ§Ã£o estimada**: 2 semanas

---

## ğŸ“ˆ STATUS ATUAL (06/11/2025)

### âœ… COMPLETO

1. **ValidaÃ§Ã£o sklearn**:
   - Quick test (10k): 89.50% HPM-KD
   - Full MNIST (70k): 91.67% HPM-KD
   - Melhoria: +23.13pp sobre Traditional KD
   - Figuras: 6/13 geradas

2. **Estrutura de cÃ³digo**:
   - Todos os scripts implementados
   - Bibliotecas compartilhadas organizadas
   - IntegraÃ§Ã£o com DeepBridge validada

3. **DocumentaÃ§Ã£o**:
   - Scripts documentados
   - Estrutura de experimentos definida
   - Mapeamento para paper completo

### â³ EM ANDAMENTO

1. **Baseline CNN** (8 processos em background):
   - Teacher training (ResNet-18)
   - Student direct training (MobileNet)
   - Traditional KD training
   - HPM-KD training (2 versÃµes)
   - Evaluation pipeline

### â³ PENDENTE

1. **Completar experimentos CNN**
2. **Ablation studies** (6 variantes)
3. **Sensitivity analysis** (temperature, alpha, chain length)
4. **Multi-dataset experiments** (7 datasets adicionais)
5. **Figuras restantes** (7/13)
6. **AtualizaÃ§Ã£o do paper**

---

## ğŸ”§ COMANDOS RÃPIDOS

### ValidaÃ§Ã£o sklearn (completo):
```bash
# Quick test
python experiments/sklearn_validation/example_hpmkd_experiment.py

# Full MNIST
python experiments/sklearn_validation/run_full_mnist_experiment.py
```

### Baseline CNN:
```bash
# 1. Treinar professor
poetry run python experiments/cnn_baseline/train_teacher.py --epochs 20

# 2. Treinar aluno direto
poetry run python experiments/cnn_baseline/train_student.py --model mobilenet --epochs 20

# 3. Treinar com KD tradicional
poetry run python experiments/cnn_baseline/train_kd.py \
    --teacher models/teacher_resnet18_best.pth --student mobilenet --epochs 20
```

### HPM-KD CNN:
```bash
# Treinar com HPM-KD completo
poetry run python experiments/cnn_hpmkd/train_hpmkd.py \
    --teacher models/teacher_resnet18_best.pth \
    --student mobilenet \
    --use-progressive --use-adaptive-temp \
    --epochs 20
```

### AvaliaÃ§Ã£o:
```bash
# Comparar todos os modelos
poetry run python experiments/evaluation/evaluate_all.py \
    --teacher models/teacher_resnet18_best.pth \
    --student-hpmkd models/student_mobilenet_hpmkd_best.pth \
    --student-arch mobilenet \
    --output-dir results/cnn \
    --save-confusion --save-figures

# Gerar figuras
python experiments/evaluation/generate_figures.py
```

---

## ğŸ“ NOTAS IMPORTANTES

### 1. DependÃªncias entre Scripts

**Ordem de execuÃ§Ã£o necessÃ¡ria**:
1. `train_teacher.py` (gera teacher model)
2. Paralelo:
   - `train_student.py`
   - `train_kd.py` (depende do teacher)
   - `train_hpmkd.py` (depende do teacher)
3. `evaluate_all.py` (depende de todos os modelos)
4. `generate_figures.py` (depende dos resultados)

### 2. Recursos Computacionais

**sklearn experiments**:
- CPU: Suficiente
- RAM: 4-8 GB
- Tempo: minutos

**CNN experiments**:
- GPU: Recomendado (CUDA)
- RAM: 8-16 GB
- VRAM: 4-8 GB
- Tempo: horas

### 3. Paths Relativos

Todos os scripts assumem execuÃ§Ã£o a partir do diretÃ³rio raiz do DeepBridge:
```bash
cd /home/guhaase/projetos/DeepBridge
poetry run python papers/01_HPM-KD_Framework/POR/experiments/.../script.py
```

### 4. Resultados IntermediÃ¡rios

- Modelos salvos em: `models/`
- Resultados sklearn em: `experiments/results/sklearn/`
- Resultados CNN em: `experiments/results/cnn/`
- Figuras em: `experiments/results/figures/`

### 5. Git Ignore

Adicionar ao `.gitignore`:
```
models/*.pth
experiments/results/**/*.csv
experiments/results/**/*.json
experiments/results/figures/*.png
!experiments/results/figures/*.pdf  # Manter PDFs versionados
```

---

## ğŸ“š REFERÃŠNCIAS

### Paper Sections Mapping

- **Section 3**: Methodology â†’ CÃ³digo em `deepbridge/distillation/techniques/hpm/`
- **Section 5.1**: Main Results â†’ `train_*.py` + `evaluate_all.py`
- **Section 5.2**: Generalization â†’ Multi-dataset experiments
- **Section 5.3**: Efficiency â†’ Training time logs + `evaluate_all.py`
- **Section 5.4**: Component Analysis â†’ Experimentos base
- **Section 6**: Ablation â†’ `train_hpmkd.py` com componentes desabilitados
- **Section 7**: Discussion â†’ AnÃ¡lise agregada de todos os resultados

### Arquivos de DocumentaÃ§Ã£o Relacionados

- `FINAL_STATUS.md`: Status geral do projeto
- `FULL_MNIST_RESULTS.md`: Resultados detalhados sklearn
- `EXPERIMENTS_COMPARISON.md`: ComparaÃ§Ã£o quick vs full
- `FIGURES_SUMMARY.md`: DocumentaÃ§Ã£o de figuras geradas
- `IMPLEMENTATION_GUIDE.md`: Guia paper-to-code

---

## âœ… CHECKLIST DE VALIDAÃ‡ÃƒO

Antes de submeter paper, verificar:

- [ ] Todos os scripts executam sem erros
- [ ] Resultados replicÃ¡veis (mÃºltiplas seeds)
- [ ] Figuras em alta resoluÃ§Ã£o (300 DPI)
- [ ] Tabelas com todos os dados preenchidos
- [ ] Testes estatÃ­sticos realizados
- [ ] SignificÃ¢ncia validada (p-values)
- [ ] Ablation studies completos
- [ ] Multi-dataset experiments completos
- [ ] CÃ³digo versionado no GitHub
- [ ] Modelos salvos e documentados
- [ ] README atualizado
- [ ] Reprodutibilidade garantida

---

**Ãšltima atualizaÃ§Ã£o**: 06 de Novembro de 2025
**Status**: Fase 1 completa, Fase 2 em andamento
**PrÃ³ximo milestone**: Completar baseline CNN (Fase 2)

---

## ğŸ¯ PRÃ“XIMAS AÃ‡Ã•ES

1. **Monitorar processos background** (8 jobs rodando)
2. **Aguardar conclusÃ£o dos treinamentos CNN**
3. **Executar `evaluate_all.py`** com todos os modelos
4. **Analisar resultados CNN** vs sklearn
5. **Decidir sobre necessidade de ajustes**
6. **Iniciar Fase 3** (HPM-KD CNN) se baselines ok
