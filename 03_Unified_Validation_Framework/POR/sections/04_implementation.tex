\section{Implementação}
\label{sec:implementation}

DeepBridge é implementado em Python (~80K linhas de código) seguindo princípios de design para modularidade, extensibilidade e performance.

\subsection{Princípios de Design}

\textbf{1. Modularidade}

Cada componente é independente e testável:
\begin{itemize}
    \item DBDataset: Abstração de dados (500 testes unitários)
    \item Test Managers: Um por dimensão (300 testes cada)
    \item Experiment: Orquestração (200 testes de integração)
\end{itemize}

\textbf{2. Extensibilidade}

Interface \texttt{BaseTestManager} permite adicionar novas dimensões:
\begin{lstlisting}[language=Python]
class CustomTestManager(BaseTestManager):
    def run_tests(self, dataset, config):
        # Implementar testes customizados
        pass
\end{lstlisting}

\textbf{3. Performance}

Otimizações críticas para escala:
\begin{itemize}
    \item Lazy loading: -42\% uso de memória
    \item Caching inteligente: -30s em experimentos
    \item Execução paralela: -40\% tempo total
\end{itemize}

\subsection{Otimizações de Performance}

\subsubsection{Lazy Loading}

Modelos carregados sob demanda:
\begin{lstlisting}[language=Python]
class DBDataset:
    def _get_predictions(self):
        if self._predictions is None:
            self._predictions = self.model.predict(self.data)
        return self._predictions
\end{lstlisting}

\textbf{Impacto}: 30-50s economia + 42\% menos memória.

\subsubsection{Model Caching}

Predições reutilizadas entre testes:
\begin{itemize}
    \item Fairness + Uncertainty compartilham predições
    \item Cache invalidado se modelo muda
    \item LRU eviction para datasets grandes
\end{itemize}

\subsubsection{Execução Paralela}

Testes independentes executam em paralelo via ThreadPoolExecutor:
\begin{lstlisting}[language=Python]
from concurrent.futures import ThreadPoolExecutor

with ThreadPoolExecutor(max_workers=5) as executor:
    futures = [
        executor.submit(run_robustness, dataset),
        executor.submit(run_fairness, dataset),
        executor.submit(run_uncertainty, dataset),
        # ...
    ]
\end{lstlisting}

\textbf{Speedup}: 40\% vs. execução sequencial.

\subsection{Integração com Ecossistema ML}

\textbf{Suporte a Frameworks}:
\begin{itemize}
    \item \textbf{Scikit-learn}: Suporte nativo completo
    \item \textbf{XGBoost/LightGBM/CatBoost}: Via interface sklearn
    \item \textbf{Custom models}: Interface \texttt{predict()} + \texttt{predict\_proba()}
    \item \textbf{ONNX}: Suporte via onnxruntime
\end{itemize}

\textbf{Pipelines}:
\begin{lstlisting}[language=Python]
from sklearn.pipeline import Pipeline
from deepbridge import DBDataset

pipeline = Pipeline([
    ('preprocessor', StandardScaler()),
    ('classifier', RandomForestClassifier())
])

# DeepBridge aceita pipelines diretamente
dataset = DBDataset(X_test, y_test, model=pipeline)
\end{lstlisting}
