\section{Avaliacão Experimental}
\label{sec:evaluation}

Avaliamos o framework em três dimensões: (1) escalabilidade, (2) qualidade dos dados sintéticos, e (3) estudos de caso em aplicacões reais.

\subsection{Setup Experimental}

\textbf{Hardware}:
\begin{itemize}
    \item Single-node: 64GB RAM, 16-core CPU (AMD EPYC 7543)
    \item Cluster: 4 nodes (256GB RAM total)
    \item Storage: NVMe SSD 2TB
\end{itemize}

\textbf{Datasets}:
\begin{itemize}
    \item \textbf{Synthetic benchmarks}: 1GB, 10GB, 50GB, 100GB (dados controlados)
    \item \textbf{Real datasets}: Healthcare (10M pacientes), Finance (50M transacões), E-commerce (100M interacões)
\end{itemize}

\textbf{Baselines}:
\begin{itemize}
    \item SDV Gaussian Copula (in-memory)
    \item CTGAN (GPU-based)
    \item TVAE (GPU-based)
\end{itemize}

\subsection{Escalabilidade}

\textbf{Experimento}: Medir tempo e memória vs. tamanho do dataset.

\begin{table}[h]
\centering
\caption{Escalabilidade: Tempo de fitting (minutos)}
\label{tab:scalability_time}
\small
\begin{tabular}{@{}lcccc@{}}
\toprule
\textbf{Método} & \textbf{1GB} & \textbf{10GB} & \textbf{50GB} & \textbf{100GB} \\
\midrule
SDV & 3.2 & 42 & OOM & OOM \\
CTGAN & 18 & 240 & OOM & OOM \\
TVAE & 12 & 180 & OOM & OOM \\
\midrule
\textbf{DeepBridge} & \textbf{1.8} & \textbf{12} & \textbf{58} & \textbf{115} \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Speedup}:
\begin{itemize}
    \item \textbf{1GB}: 1.8x vs. SDV, 10x vs. CTGAN
    \item \textbf{10GB}: 3.5x vs. SDV, 20x vs. CTGAN
    \item \textbf{100GB}: \textbf{Apenas DeepBridge completa} (SDV/CTGAN OOM)
\end{itemize}

\begin{table}[h]
\centering
\caption{Escalabilidade: Peak memory (GB)}
\label{tab:scalability_memory}
\small
\begin{tabular}{@{}lcccc@{}}
\toprule
\textbf{Método} & \textbf{1GB} & \textbf{10GB} & \textbf{50GB} & \textbf{100GB} \\
\midrule
SDV & 8 & 85 & >64 & >64 \\
CTGAN & 12 & 48 & >64 & >64 \\
TVAE & 10 & 52 & >64 & >64 \\
\midrule
\textbf{DeepBridge} & \textbf{2} & \textbf{4} & \textbf{6} & \textbf{8} \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Conclusão}: DeepBridge usa \textbf{-95\% memória} (8GB vs. 85GB para 10GB dataset).

\subsection{Qualidade: Métricas Estatísticas}

\textbf{Métricas}:
\begin{itemize}
    \item \textbf{Kolmogorov-Smirnov (KS)}: Distância entre CDFs (por feature)
    \item \textbf{Jensen-Shannon Divergence (JSD)}: Similaridade de distribuições
    \item \textbf{Correlation Diff}: $||\Sigma_{real} - \Sigma_{synth}||_F / ||\Sigma_{real}||_F$
\end{itemize}

\begin{table}[h]
\centering
\caption{Qualidade estatística (dataset 10GB, média de 50 features)}
\label{tab:statistical_quality}
\small
\begin{tabular}{@{}lcccc@{}}
\toprule
\textbf{Método} & \textbf{KS} $\downarrow$ & \textbf{JSD} $\downarrow$ & \textbf{Corr Diff} $\downarrow$ \\
\midrule
SDV & 0.023 & 0.012 & 0.018 \\
CTGAN & 0.019 & 0.010 & 0.025 \\
TVAE & 0.021 & 0.011 & 0.022 \\
\midrule
\textbf{DeepBridge} & \textbf{0.024} & \textbf{0.013} & \textbf{0.019} \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Observacão}: Qualidade estatística é \textbf{comparável} a SDV (ambos Copula-based), ligeiramente inferior a CTGAN (esperado, GANs são mais expressivos).

\textbf{Trade-off}: DeepBridge sacrifica 5-10\% de qualidade para ganhar 20x+ escalabilidade.

\subsection{Qualidade: ML Utility}

\textbf{Protocolo}:
\begin{enumerate}
    \item Train modelo em dados sintéticos
    \item Test em dados reais (held-out)
    \item Compare accuracy com modelo trained em real
\end{enumerate}

\begin{table}[h]
\centering
\caption{ML Utility: Accuracy (dataset 10GB)}
\label{tab:ml_utility}
\small
\begin{tabular}{@{}lccc@{}}
\toprule
\textbf{Train Data} & \textbf{Test Data} & \textbf{Accuracy} & \textbf{Degradacão} \\
\midrule
Real & Real & 89.2\% & - \\
\midrule
SDV Synth & Real & 87.8\% & -1.4pp \\
CTGAN Synth & Real & 88.1\% & -1.1pp \\
TVAE Synth & Real & 87.5\% & -1.7pp \\
\midrule
\textbf{DeepBridge Synth} & Real & \textbf{87.3\%} & \textbf{-1.9pp} \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Conclusão}: Degradacão de \textbf{-1.9pp} é aceitável (< 3pp threshold para producao).

\subsection{Privacidade}

\textbf{Métricas}:
\begin{itemize}
    \item \textbf{Nearest Neighbor Distance (NND)}: Distância média da amostra sintética mais próxima à amostra real
    \item \textbf{k-Anonymity}: Nenhuma amostra sintética é cópia exata de real
\end{itemize}

\begin{table}[h]
\centering
\caption{Privacidade (dataset 10GB)}
\label{tab:privacy}
\small
\begin{tabular}{@{}lccc@{}}
\toprule
\textbf{Método} & \textbf{NND} $\uparrow$ & \textbf{k-Anon} & \textbf{Copies} \\
\midrule
SDV & 0.18 & Yes & 0 \\
CTGAN & 0.22 & Yes & 0 \\
TVAE & 0.20 & Yes & 0 \\
\midrule
\textbf{DeepBridge} & \textbf{0.17} & \textbf{Yes} & \textbf{0} \\
\textbf{DeepBridge + DP} & \textbf{0.28} & \textbf{Yes} & \textbf{0} \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Threshold}: NND > 0.10 (regra prática).

\textbf{Conclusão}: DeepBridge garante k-anonymity. Opcao DP aumenta NND (+65\%) mas degrada utility (-3pp).

\subsection{Estudos de Caso}

\subsubsection{Case 1: Healthcare (10M Pacientes)}

\textbf{Dataset}: Electronic Health Records (EHR), 10M pacientes, 80 features (demográficos, diagnósticos, medicacões).

\textbf{Objetivo}: Compartilhar dados para pesquisa sem violar HIPAA.

\textbf{Resultados}:
\begin{itemize}
    \item \textbf{Fitting time}: 18 min (vs. SDV OOM)
    \item \textbf{Statistical similarity}: KS = 0.028 (alta)
    \item \textbf{ML utility}: Readmissão prediction 84\% (synth) vs. 86\% (real) = -2pp
    \item \textbf{Privacy}: k-anonymity > 5, NND = 0.21
\end{itemize}

\textbf{Validacão Expert}: Médicos validaram que distribuições de diagnósticos e co-morbidades são realistas.

\subsubsection{Case 2: Finance (50M Transacões)}

\textbf{Dataset}: Transacões de cartão de crédito, 50M rows, 40 features.

\textbf{Objetivo}: Data augmentation para fraud detection (classe desbalanceada: 0.1\% fraudes).

\textbf{Approach}:
\begin{enumerate}
    \item Separate fraud vs. legit
    \item Oversample fraud via synthetic (10x)
    \item Combine com legit
\end{enumerate}

\textbf{Resultados}:
\begin{itemize}
    \item \textbf{Fraud detection F1}: 0.72 (real only) $\rightarrow$ 0.78 (real + synth) = +0.06
    \item \textbf{Fitting time}: 52 min
    \item \textbf{Preservacão de correlacões}: 97\% agreement
\end{itemize}

\subsubsection{Case 3: E-commerce (100M Interacões)}

\textbf{Dataset}: User-item interactions, 100M rows, 25 features.

\textbf{Objetivo}: Compartilhar dados de comportamento para parceiros sem expor usuários.

\textbf{Resultados}:
\begin{itemize}
    \item \textbf{Fitting time}: 115 min (100GB dataset)
    \item \textbf{Click-through-rate (CTR) prediction}: 0.89 AUC (synth) vs. 0.91 (real) = -0.02
    \item \textbf{Privacy}: Zero copies, NND = 0.19
\end{itemize}

\subsection{Ablation Study}

\textbf{Questão}: Qual contribuicao de cada componente?

\textbf{Variantes}:
\begin{itemize}
    \item \textbf{Full}: Dask + streaming algorithms + optimizacões
    \item \textbf{-Dask}: In-memory (como SDV)
    \item \textbf{-Streaming}: Load chunks mas aggregate naively
    \item \textbf{-Optimizations}: Sem sparsification, sem parallel inverse transform
\end{itemize}

\begin{table}[h]
\centering
\caption{Ablation study (dataset 10GB)}
\label{tab:ablation}
\small
\begin{tabular}{@{}lccc@{}}
\toprule
\textbf{Variante} & \textbf{Time (min)} & \textbf{Memory (GB)} & \textbf{Quality (KS)} \\
\midrule
Full & 12 & 4 & 0.024 \\
-Dask & OOM & >64 & - \\
-Streaming & 38 & 42 & 0.023 \\
-Optimizations & 18 & 4 & 0.024 \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Conclusões}:
\begin{itemize}
    \item \textbf{Dask é essencial}: Sem ele, OOM em 10GB
    \item \textbf{Streaming algorithms}: 3.2x speedup, 10.5x menos memória
    \item \textbf{Optimizations}: 1.5x speedup adicional
\end{itemize}
