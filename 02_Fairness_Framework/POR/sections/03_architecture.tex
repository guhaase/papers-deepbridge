\section{DeepBridge Fairness Framework}
\label{sec:architecture}

O DeepBridge Fairness Framework está organizado em sete componentes principais que trabalham em conjunto para fornecer análise de fairness automatizada, verificação de conformidade regulatória e suporte à decisão de deployment. Esta seção detalha cada componente.

\subsection{Visão Geral da Arquitetura}

A arquitetura do DeepBridge Fairness (Figura~\ref{fig:fairness_architecture}) segue um pipeline em três estágios:

\begin{enumerate}
    \item \textbf{Detecção Automática}: Identifica atributos sensíveis via fuzzy matching
    \item \textbf{Análise Multi-Dimensional}: Computa 15 métricas (4 pré-treino + 11 pós-treino)
    \item \textbf{Verificação \& Otimização}: Verifica conformidade EEOC/ECOA e otimiza thresholds
\end{enumerate}

\begin{lstlisting}[language=Python, caption=Workflow completo do DeepBridge Fairness]
from deepbridge import DBDataset, FairnessTestManager

# Estágio 1: Criar dataset com auto-detecção
dataset = DBDataset(
    data=df,
    target_column='approved',
    model=trained_model
)
# Atributos detectados: ['gender', 'race', 'age']

# Estágio 2: Análise multi-dimensional
ftm = FairnessTestManager(dataset)
results = ftm.run_all_tests()
# 15 métricas computadas automaticamente

# Estágio 3: Verificação EEOC/ECOA + otimização
compliance = ftm.check_eeoc_compliance()
optimal_threshold = ftm.optimize_threshold(
    fairness_metric='disparate_impact',
    min_accuracy=0.80
)
\end{lstlisting}

\subsection{Auto-Detecção de Atributos Sensíveis}

\subsubsection{Algoritmo de Fuzzy Matching}

DeepBridge utiliza fuzzy string matching para detectar automaticamente atributos sensíveis em nomes de colunas, eliminando especificação manual.

\textbf{Categorias de Atributos Protegidos}: EEOC e ECOA definem 7 categorias:
\begin{enumerate}
    \item \textbf{Gender}: gender, sex, female, male, gender\_identity
    \item \textbf{Race}: race, ethnicity, african\_american, hispanic, asian, white
    \item \textbf{Age}: age, dob, date\_of\_birth, birth\_year, yob
    \item \textbf{Religion}: religion, faith, religious\_affiliation
    \item \textbf{Disability}: disability, handicap, disabled, impairment
    \item \textbf{Nationality}: nationality, country\_of\_birth, citizenship, national\_origin
    \item \textbf{Marital Status}: marital\_status, married, single, divorced
\end{enumerate}

\textbf{Algoritmo}:
\begin{algorithm}
\caption{Auto-Detecção de Atributos Sensíveis}
\begin{algorithmic}[1]
\REQUIRE Dataset $D$ com features $F = \{f_1, ..., f_n\}$
\REQUIRE Dicionário de keywords $K$ por categoria
\REQUIRE Threshold de similaridade $\theta$ (default: 0.85)
\ENSURE Conjunto $S$ de atributos sensíveis detectados
\STATE $S \leftarrow \emptyset$
\FOR{cada feature $f_i \in F$}
    \STATE $f_{\text{clean}} \leftarrow$ normalizar($f_i$) // lowercase, remove underscores
    \FOR{cada categoria $c \in K$}
        \FOR{cada keyword $k \in K[c]$}
            \STATE $\text{sim} \leftarrow$ Levenshtein\_similarity($f_{\text{clean}}$, $k$)
            \IF{$\text{sim} \geq \theta$}
                \STATE $S \leftarrow S \cup \{(f_i, c, \text{sim})\}$
            \ENDIF
        \ENDFOR
    \ENDFOR
\ENDFOR
\RETURN $S$
\end{algorithmic}
\end{algorithm}

\textbf{Calibração de Threshold}: Threshold $\theta=0.85$ foi calibrado em 500 datasets reais para maximizar F1-score:
\begin{itemize}
    \item \textbf{Precisão}: 92\% (baixo false positive rate)
    \item \textbf{Recall}: 89\% (detecta a maioria dos atributos)
    \item \textbf{F1-Score}: 0.90
\end{itemize}

\textbf{Override Manual}: Usuários podem sobrescrever detecção automática:
\begin{lstlisting}[language=Python]
# Aceitar detecção automática
dataset.protected_attributes = dataset.detected_sensitive_attributes

# Ou override manual
dataset.protected_attributes = ['gender', 'race']
\end{lstlisting}

\subsection{Suite de Métricas de Fairness}

\subsubsection{Métricas Pré-Treinamento (4)}

Analisam bias nos \textit{dados de treinamento} antes de treinar modelo:

\textbf{(1) Class Balance}:
\[
\text{CB}(A) = \min_{a \in A} \frac{P(Y=1|A=a)}{\max_{a' \in A} P(Y=1|A=a')}
\]
Detecta desequilíbrio em taxas de labels positivos entre grupos. Threshold: CB < 0.80 indica bias.

\textbf{(2) Concept Balance}:
\[
\text{ConceptB}(A) = \frac{\text{H}(Y|A)}{\text{H}(Y)}
\]
onde H é entropia. Mede se atributo protegido é preditivo de label (redundância).

\textbf{(3-4) KL e JS Divergence}:
\[
\text{KL}(P_{A=0}(X) || P_{A=1}(X)), \quad \text{JS}(P_{A=0}(X), P_{A=1}(X))
\]
Medem diferença na distribuição de features entre grupos protegidos.

\textbf{Uso Prático}: Métricas pré-treino orientam estratégias de mitigação (resampling, reweighting) \textit{antes} de treinar modelos custosos.

\subsubsection{Métricas Pós-Treinamento (11)}

Analisam bias nas \textit{predições do modelo} após treinamento:

\textbf{(1) Statistical Parity (Demographic Parity)}:
\[
\text{SP} = P(\hat{Y}=1|A=1) - P(\hat{Y}=1|A=0)
\]
Ideal: $|\text{SP}| < 0.1$ (10pp difference).

\textbf{(2) Disparate Impact}:
\[
\text{DI} = \frac{P(\hat{Y}=1|A=1)}{P(\hat{Y}=1|A=0)}
\]
\textbf{Conexão EEOC}: DI < 0.80 viola regra 80\%.

\textbf{(3) Equal Opportunity}:
\[
\text{EO} = P(\hat{Y}=1|Y=1, A=1) - P(\hat{Y}=1|Y=1, A=0)
\]
Iguala True Positive Rates. Ideal: $|\text{EO}| < 0.1$.

\textbf{(4) Equalized Odds}:
\[
\text{EOdds} = \max(|\text{TPR}_{A=1} - \text{TPR}_{A=0}|, |\text{FPR}_{A=1} - \text{FPR}_{A=0}|)
\]
Iguala TPR \textit{e} FPR. Ideal: EOdds < 0.1.

\textbf{(5) FNR Difference}:
\[
\Delta \text{FNR} = \text{FNR}_{A=1} - \text{FNR}_{A=0}
\]
Detecta bias em erros de False Negatives (e.g., negar crédito a candidatos qualificados).

\textbf{(6-7) Conditional Acceptance/Rejection Parity}:
\[
P(Y=1|\hat{Y}=1, A=1) = P(Y=1|\hat{Y}=1, A=0)
\]
Precision parity: entre predições positivas, mesma taxa de verdadeiros positivos.

\textbf{(8-9) Precision/Accuracy Difference}:
\[
\Delta \text{Prec} = \text{Prec}_{A=1} - \text{Prec}_{A=0}, \quad \Delta \text{Acc} = \text{Acc}_{A=1} - \text{Acc}_{A=0}
\]

\textbf{(10) Treatment Equality}:
\[
\text{TE} = \frac{\text{FN}_{A=1}}{\text{FP}_{A=1}} - \frac{\text{FN}_{A=0}}{\text{FP}_{A=0}}
\]
Razão de erros (FN/FP) deve ser igual entre grupos.

\textbf{(11) Entropy Index}:
\[
\text{EI} = \sum_{a \in A} P(A=a) \cdot \text{H}(\hat{Y}|A=a)
\]
Mede heterogeneidade de predições intra-grupo.

\subsection{Módulo de Verificação de Conformidade EEOC}

\subsubsection{Regra 80\% (Disparate Impact)}

Verifica automaticamente se $\text{DI} \geq 0.80$:

\begin{lstlisting}[language=Python, caption=Verificação automática da regra 80\%]
def check_80_rule(y_pred, sensitive_attr):
    groups = sensitive_attr.unique()
    selection_rates = {}

    for group in groups:
        mask = (sensitive_attr == group)
        selection_rates[group] = y_pred[mask].mean()

    reference = max(selection_rates.values())
    violations = {}

    for group, rate in selection_rates.items():
        di = rate / reference
        if di < 0.80:
            violations[group] = {
                'DI': di,
                'selection_rate': rate,
                'reference_rate': reference,
                'shortfall': 0.80 - di
            }

    return {
        'compliant': len(violations) == 0,
        'violations': violations
    }
\end{lstlisting}

\textbf{Relatório Gerado}:
\begin{verbatim}
EEOC 80% Rule Verification:
- Female: DI = 0.72 [VIOLATION] (shortfall: 8pp)
- Male: DI = 1.00 [COMPLIANT]
Recommendation: Adjust threshold or retrain model
\end{verbatim}

\subsubsection{Question 21 (Representação Mínima 2\%)}

EEOC Question 21 estipula que grupos com <2\% de representação não têm validade estatística:

\begin{lstlisting}[language=Python, caption=Verificação Question 21]
def check_question_21(sensitive_attr, min_representation=0.02):
    total = len(sensitive_attr)
    warnings = {}

    for group in sensitive_attr.unique():
        count = (sensitive_attr == group).sum()
        representation = count / total

        if representation < min_representation:
            warnings[group] = {
                'count': count,
                'representation': representation,
                'required': min_representation,
                'warning': 'Insufficient sample size for statistical validity'
            }

    return {
        'valid': len(warnings) == 0,
        'warnings': warnings
    }
\end{lstlisting}

\textbf{Ação Automática}: Grupos com <2\% são excluídos de análise de disparate impact, evitando falsos positivos.

\subsection{Otimização de Threshold}

\subsubsection{Análise de Trade-offs Fairness-Acurácia}

DeepBridge analisa range de thresholds (10-90\%) e computa métricas de fairness e acurácia para cada threshold:

\begin{lstlisting}[language=Python, caption=Otimização de threshold multi-objetivo]
from deepbridge import FairnessTestManager

ftm = FairnessTestManager(dataset)

# Análise de trade-offs em range 0.1-0.9
threshold_analysis = ftm.analyze_thresholds(
    thresholds=np.arange(0.1, 0.9, 0.05),
    fairness_metrics=['disparate_impact', 'equal_opportunity'],
    performance_metrics=['accuracy', 'f1_score']
)

# Pareto frontier: thresholds não dominados
pareto_thresholds = threshold_analysis['pareto_frontier']

# Recomendação baseada em constraints
optimal = ftm.recommend_threshold(
    min_disparate_impact=0.80,
    min_accuracy=0.75,
    objective='maximize_f1'
)
\end{lstlisting}

\subsubsection{Pareto Frontier}

Threshold $t_1$ domina $t_2$ se:
\begin{itemize}
    \item $\text{DI}(t_1) \geq \text{DI}(t_2)$ (melhor fairness)
    \item $\text{Acc}(t_1) \geq \text{Acc}(t_2)$ (melhor acurácia)
    \item Pelo menos uma desigualdade é estrita
\end{itemize}

Pareto frontier contém thresholds não dominados, permitindo stakeholders escolherem trade-off apropriado.

\subsection{Representatividade Estatística}

DeepBridge implementa validações de representatividade para evitar conclusões espúrias:

\textbf{(1) Tamanho Mínimo de Grupo}: Grupos com n < 30 recebem warning (regra de thumb estatística).

\textbf{(2) Intervalos de Confiança}: Métricas reportadas com IC 95\% usando bootstrap:
\begin{lstlisting}[language=Python]
def compute_with_ci(metric_fn, y_true, y_pred, n_bootstrap=1000):
    bootstrap_scores = []
    n = len(y_true)

    for _ in range(n_bootstrap):
        indices = np.random.choice(n, n, replace=True)
        score = metric_fn(y_true[indices], y_pred[indices])
        bootstrap_scores.append(score)

    return {
        'mean': np.mean(bootstrap_scores),
        'ci_lower': np.percentile(bootstrap_scores, 2.5),
        'ci_upper': np.percentile(bootstrap_scores, 97.5)
    }
\end{lstlisting}

\textbf{(3) Testes de Significância}: Diferenças entre grupos testadas via permutation test (p-value < 0.05).

\subsection{Sistema de Visualizações}

DeepBridge gera 6 tipos de visualizações automaticamente:

\textbf{(1) Distribution by Group}: Histogramas de features por grupo protegido

\textbf{(2) Metrics Comparison}: Barplot comparando 15 métricas entre grupos

\textbf{(3) Threshold Impact Analysis}: Curvas mostrando como métricas variam com threshold

\textbf{(4) Confusion Matrices per Group}: Matrizes de confusão lado a lado para cada grupo

\textbf{(5) Fairness Radar Chart}: Radar chart com 11 métricas pós-treino normalizadas

\textbf{(6) Group Performance Comparison}: Boxplots de performance metrics (accuracy, precision, recall, F1) por grupo

\textbf{Formato de Relatórios}:
\begin{itemize}
    \item \textbf{HTML Interativo}: Plotly charts, filtros dinâmicos
    \item \textbf{HTML Estático}: Para auditoria (anexável a emails)
    \item \textbf{PDF}: Formato corporativo com branding customizável
    \item \textbf{JSON}: Para integração programática
\end{itemize}

\subsection{Integração com Pipeline de Validação DeepBridge}

FairnessTestManager integra-se com Experiment orchestrator do DeepBridge:

\begin{lstlisting}[language=Python, caption=Integração com pipeline completo]
from deepbridge import DBDataset, Experiment

dataset = DBDataset(df, target='approved', model=model)

# Validação multi-dimensional (fairness + robustness + uncertainty)
exp = Experiment(
    dataset=dataset,
    tests=['fairness', 'robustness', 'uncertainty']
)

results = exp.run_tests()

# Relatório unificado com todas dimensões
exp.save_pdf('complete_validation_report.pdf')
\end{lstlisting}

\textbf{Benefícios da Integração}:
\begin{itemize}
    \item \textbf{Consistência}: Mesmo DBDataset usado em fairness, robustness, uncertainty
    \item \textbf{Eficiência}: Predições do modelo computadas uma vez e reutilizadas
    \item \textbf{Relatórios Unificados}: Stakeholders veem fairness no contexto de outras dimensões de validação
\end{itemize}
