# Plano de Experimentos - DeepBridge Fairness Framework

**Paper**: "DeepBridge Fairness: Da Pesquisa √† Regula√ß√£o -- Um Framework Pronto para Produ√ß√£o para Teste de Fairness Algor√≠tmica"

**Confer√™ncia Alvo**: FAccT 2026

**Objetivo**: Validar todas as claims do paper atrav√©s de experimentos reproduz√≠veis e rigorosos.

---

## üìä √çndice de Experimentos

1. [Auto-Detec√ß√£o de Atributos Sens√≠veis](#1-auto-detec√ß√£o-de-atributos-sens√≠veis)
2. [Cobertura de M√©tricas](#2-cobertura-de-m√©tricas)
3. [Verifica√ß√£o EEOC/ECOA](#3-verifica√ß√£o-eeocecoa)
4. [Estudos de Caso](#4-estudos-de-caso)
5. [Estudo de Usabilidade](#5-estudo-de-usabilidade)
6. [Performance e Escalabilidade](#6-performance-e-escalabilidade)
7. [Otimiza√ß√£o de Threshold](#7-otimiza√ß√£o-de-threshold)
8. [Compara√ß√£o com Ferramentas Existentes](#8-compara√ß√£o-com-ferramentas-existentes)

---

## 1. Auto-Detec√ß√£o de Atributos Sens√≠veis

### 1.1 Experimento: Acur√°cia em 500 Datasets

**Claim do Paper**:
- Precision: 0.92
- Recall: 0.89
- F1-Score: 0.90
- Testado em 500 datasets reais

**Metodologia**:

1. **Coleta de Datasets**:
   - 200 datasets do Kaggle (buscar por: "credit", "hiring", "health", "criminal justice")
   - 150 datasets do UCI Machine Learning Repository
   - 100 datasets de OpenML
   - 50 datasets sint√©ticos (controle)

2. **Ground Truth**:
   - Anota√ß√£o manual por 2 especialistas independentes
   - Medir inter-rater agreement (Cohen's Kappa > 0.85)
   - Resolver discord√¢ncias por consenso

3. **Categorias de Atributos Sens√≠veis**:
   - Gender/Sex (target: 100 datasets)
   - Race/Ethnicity (target: 80 datasets)
   - Age (target: 90 datasets)
   - Religion (target: 30 datasets)
   - Disability (target: 25 datasets)
   - Nationality (target: 40 datasets)
   - Marital Status (target: 35 datasets)

4. **Execu√ß√£o**:
   ```python
   from deepbridge import DBDataset

   results = []
   for dataset_name, df, ground_truth in datasets:
       dataset = DBDataset(data=df, target_column='target')
       detected = set(dataset.detected_sensitive_attributes)

       tp = len(detected & ground_truth)
       fp = len(detected - ground_truth)
       fn = len(ground_truth - detected)

       precision = tp / (tp + fp) if (tp + fp) > 0 else 0
       recall = tp / (tp + fn) if (tp + fn) > 0 else 0
       f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0

       results.append({
           'dataset': dataset_name,
           'precision': precision,
           'recall': recall,
           'f1': f1
       })
   ```

5. **An√°lise de Erros**:
   - Classificar False Positives por tipo (e.g., "race_time" detectado como "race")
   - Classificar False Negatives por causa (typos, thresholds, codifica√ß√£o)
   - Calcular confusion matrix por categoria

**M√©tricas de Valida√ß√£o**:
- ‚úÖ Precision geral ‚â• 0.90
- ‚úÖ Recall geral ‚â• 0.85
- ‚úÖ F1-Score ‚â• 0.88
- ‚úÖ Precision por categoria ‚â• 0.85
- ‚úÖ Kappa inter-rater ‚â• 0.85

**Artefatos**:
- `results/auto_detection_500_datasets.csv` - Resultados completos
- `results/auto_detection_confusion_matrix.png` - Matriz de confus√£o
- `results/auto_detection_by_category.csv` - Breakdown por categoria
- `results/false_positives_analysis.txt` - An√°lise de FPs
- `results/false_negatives_analysis.txt` - An√°lise de FNs

---

### 1.2 Experimento: Acur√°cia 100% nos Case Studies

**Claim do Paper**:
- 10/10 atributos detectados vs 2/10 manual
- 100% acur√°cia em COMPAS, German Credit, Adult, Healthcare

**Metodologia**:

1. **Datasets**:
   - COMPAS: 3 atributos esperados (race, sex, age)
   - German Credit: 3 atributos (age, sex, foreign_worker)
   - Adult Income: 2 atributos (sex, race)
   - Healthcare: 2 atributos (race, age_group)

2. **Execu√ß√£o**:
   ```python
   test_cases = [
       ('COMPAS', df_compas, {'race', 'sex', 'age'}),
       ('German Credit', df_credit, {'age', 'sex', 'foreign_worker'}),
       ('Adult Income', df_adult, {'sex', 'race'}),
       ('Healthcare', df_health, {'race', 'age_group'})
   ]

   for name, df, expected in test_cases:
       dataset = DBDataset(data=df, target_column=TARGET_COL)
       detected = set(dataset.detected_sensitive_attributes)

       accuracy = len(detected & expected) / len(expected)
       print(f"{name}: {accuracy*100:.0f}% ({detected} vs {expected})")
   ```

**M√©tricas de Valida√ß√£o**:
- ‚úÖ 100% acur√°cia em todos os 4 datasets
- ‚úÖ 0 falsos positivos
- ‚úÖ 0 falsos negativos

**Artefatos**:
- `results/case_studies_auto_detection.txt` - Log de detec√ß√£o

---

## 2. Cobertura de M√©tricas

### 2.1 Experimento: 15 M√©tricas Integradas

**Claim do Paper**:
- 4 m√©tricas pr√©-treinamento
- 11 m√©tricas p√≥s-treinamento
- 87% mais que AI Fairness 360 (8 m√©tricas)

**Metodologia**:

1. **Verifica√ß√£o de Implementa√ß√£o**:
   ```python
   from deepbridge import FairnessTestManager

   # Pr√©-treinamento
   pre_metrics = [
       'class_balance',
       'concept_balance',
       'kl_divergence',
       'js_divergence'
   ]

   # P√≥s-treinamento
   post_metrics = [
       'statistical_parity',
       'equal_opportunity',
       'equalized_odds',
       'disparate_impact',
       'fnr_difference',
       'fpr_difference',
       'conditional_acceptance',
       'conditional_rejection',
       'precision_difference',
       'accuracy_difference',
       'treatment_equality'
   ]

   ftm = FairnessTestManager(dataset)

   # Verificar cada m√©trica calcula corretamente
   for metric in pre_metrics:
       result = ftm.compute_metric(metric)
       assert result is not None, f"{metric} falhou"

   for metric in post_metrics:
       result = ftm.compute_metric(metric, predictions=y_pred)
       assert result is not None, f"{metric} falhou"
   ```

2. **Valida√ß√£o Manual**:
   - Calcular cada m√©trica manualmente em dataset pequeno (100 amostras)
   - Comparar com output do DeepBridge (toler√¢ncia < 1e-6)

3. **Teste de Edge Cases**:
   - Dataset perfeitamente balanceado (todas m√©tricas = 0 ou 1.0)
   - Dataset completamente enviesado (disparate impact < 0.5)
   - Grupos com 1 amostra (verificar tratamento de divis√£o por zero)

**M√©tricas de Valida√ß√£o**:
- ‚úÖ 15 m√©tricas implementadas e funcionais
- ‚úÖ Erro < 1e-6 vs. c√°lculo manual
- ‚úÖ Edge cases tratados sem crashes

**Artefatos**:
- `results/metrics_validation.csv` - Compara√ß√£o manual vs DeepBridge
- `results/metrics_edge_cases.txt` - Log de edge cases

---

## 3. Verifica√ß√£o EEOC/ECOA

### 3.1 Experimento: Detec√ß√£o de Viola√ß√µes da Regra 80%

**Claim do Paper**:
- 100% precis√£o na detec√ß√£o de viola√ß√µes
- 0 falsos positivos

**Metodologia**:

1. **Casos de Teste Controlados**:
   ```python
   test_cases = [
       # (selection_rate_protected, selection_rate_reference, expected_violation)
       (0.40, 0.50, True),   # DI = 0.80 - BOUNDARY
       (0.39, 0.50, True),   # DI = 0.78 - VIOLATION
       (0.41, 0.50, False),  # DI = 0.82 - OK
       (0.70, 0.80, False),  # DI = 0.875 - OK
       (0.50, 0.70, True),   # DI = 0.714 - VIOLATION
   ]

   for sr_p, sr_r, expected in test_cases:
       ftm = FairnessTestManager(synthetic_dataset(sr_p, sr_r))
       compliance = ftm.check_eeoc_compliance()

       is_violation = compliance['eeoc_80_rule'] == False
       assert is_violation == expected, f"Falha: DI={sr_p/sr_r:.2f}"
   ```

2. **Datasets Reais**:
   - Aplicar em COMPAS, German Credit, Adult, Healthcare
   - Comparar com an√°lise manual de compliance officer

**M√©tricas de Valida√ß√£o**:
- ‚úÖ 100% acur√°cia em casos de teste controlados (5/5)
- ‚úÖ 100% concord√¢ncia com an√°lise manual em datasets reais

**Artefatos**:
- `results/eeoc_80_rule_validation.csv` - Casos de teste

---

### 3.2 Experimento: Verifica√ß√£o EEOC Question 21

**Claim do Paper**:
- Valida representa√ß√£o m√≠nima 2% por grupo

**Metodologia**:

1. **Casos de Teste**:
   ```python
   test_cases = [
       # (group_representation, expected_valid)
       (0.025, True),   # 2.5% - OK
       (0.020, True),   # 2.0% - BOUNDARY
       (0.015, False),  # 1.5% - VIOLATION
       (0.001, False),  # 0.1% - SEVERE VIOLATION
   ]
   ```

**M√©tricas de Valida√ß√£o**:
- ‚úÖ 100% acur√°cia nos casos de teste

**Artefatos**:
- `results/eeoc_question21_validation.csv`

---

### 3.3 Experimento: ECOA Adverse Action Notices

**Claim do Paper**:
- Gera notices com "raz√µes espec√≠ficas"

**Metodologia**:

1. **Verifica√ß√£o de Conte√∫do**:
   - Gerar 100 notices para decis√µes adversas
   - Verificar se cont√™m:
     - Raz√µes espec√≠ficas (n√£o gen√©ricas)
     - Scores/m√©tricas quantitativas
     - Thresholds de decis√£o

2. **Revis√£o por Compliance Officer**:
   - 20 notices aleat√≥rios revisados por profissional legal
   - Verificar conformidade com ECOA ¬ß 1002.9

**M√©tricas de Valida√ß√£o**:
- ‚úÖ 100% dos notices cont√™m raz√µes espec√≠ficas
- ‚úÖ Aprova√ß√£o ‚â• 90% por compliance officer

**Artefatos**:
- `results/adverse_action_notices_sample.txt` - 20 exemplos
- `results/compliance_officer_review.csv` - Avalia√ß√µes

---

## 4. Estudos de Caso

### 4.1 Experimento: COMPAS Recidivism Prediction

**Claims do Paper**:
- Tempo: 7.2 min (vs 35 min manual, 79% economia)
- Viola√ß√£o: FPR difference 22pp ‚Üí 8pp com threshold 0.62
- Atributos detectados: 3/3 (race, sex, age)

**Metodologia**:

1. **Setup**:
   - Dataset: ProPublica COMPAS (7,214 amostras)
   - Modelo: Random Forest Classifier
   - Features: 12 (idade, g√™nero, ra√ßa, hist√≥rico criminal)

2. **An√°lise Completa**:
   ```python
   import time
   from deepbridge import DBDataset, FairnessTestManager

   start = time.time()

   # Load data
   dataset = DBDataset(data=df_compas, target_column='two_year_recid', model=rf_model)

   # Auto-detection
   detected = dataset.detected_sensitive_attributes

   # Pre-training metrics
   ftm = FairnessTestManager(dataset)
   pre_metrics = ftm.compute_pre_training_metrics()

   # Post-training metrics
   post_metrics = ftm.compute_post_training_metrics()

   # EEOC compliance
   compliance = ftm.check_eeoc_compliance()

   # Threshold optimization
   optimal = ftm.optimize_threshold(
       fairness_metric='fpr_difference',
       min_accuracy=0.68
   )

   elapsed = time.time() - start
   ```

3. **Valida√ß√£o de Resultados**:
   - FPR difference at t=0.5: 22pp ¬± 2pp
   - FPR difference at t=0.62: 8pp ¬± 2pp
   - Accuracy at t=0.62: ‚â• 68%

**M√©tricas de Valida√ß√£o**:
- ‚úÖ Tempo ‚â§ 10 min
- ‚úÖ 3/3 atributos detectados
- ‚úÖ FPR reduction ‚â• 60%
- ‚úÖ Threshold √≥timo: 0.60-0.65

**Artefatos**:
- `results/compas_full_analysis.json` - Resultados completos
- `results/compas_threshold_analysis.csv` - An√°lise de thresholds
- `results/compas_report.html` - Relat√≥rio visual

---

### 4.2 Experimento: German Credit Scoring

**Claims do Paper**:
- Tempo: 5.8 min (vs 25 min manual, 77% economia)
- Viola√ß√£o: Age <25 tem DI = 0.73 (viola√ß√£o regra 80%)
- Threshold √≥timo: 0.45 (DI=0.80, Acc=72%)

**Metodologia**:

1. **Setup**:
   - Dataset: UCI German Credit (1,000 amostras)
   - Modelo: XGBoost Classifier
   - Features: 20 (idade, cr√©dito, emprego)

2. **Valida√ß√£o ECOA**:
   ```python
   ftm = FairnessTestManager(dataset)
   compliance = ftm.check_ecoa_compliance()

   # Verificar DI por idade
   di_young = compliance['disparate_impact']['age_<25']
   assert 0.70 <= di_young <= 0.76, "DI fora do esperado"
   ```

3. **Threshold Optimization**:
   - Gerar Pareto frontier (t=0.1 a 0.9, step=0.05)
   - Identificar t que maximiza accuracy com DI ‚â• 0.80

**M√©tricas de Valida√ß√£o**:
- ‚úÖ Tempo ‚â§ 8 min
- ‚úÖ DI viola√ß√£o detectada em Age <25
- ‚úÖ Threshold √≥timo: 0.42-0.48

**Artefatos**:
- `results/credit_full_analysis.json`
- `results/credit_pareto_frontier.png`
- `results/credit_ecoa_compliance.txt`

---

### 4.3 Experimento: Adult Income (Employment)

**Claims do Paper**:
- Tempo: 12.4 min (vs 50 min manual, 75% economia)
- Viola√ß√£o: Female DI = 0.43 (severe violation)
- An√°lise de causa: "occupation" √© proxy de gender

**Metodologia**:

1. **Setup**:
   - Dataset: UCI Adult (48,842 amostras)
   - Modelo: LightGBM Classifier
   - Features: 14 (idade, educa√ß√£o, ocupa√ß√£o, ra√ßa, sexo)

2. **Feature Importance por Grupo**:
   ```python
   ftm = FairnessTestManager(dataset)
   importance = ftm.analyze_feature_importance_by_group(
       sensitive_attribute='sex'
   )

   # Verificar se "occupation" √© top-3 feature
   assert 'occupation' in importance['female'][:3]
   assert 'occupation' in importance['male'][:3]
   ```

3. **An√°lise de Mitiga√ß√£o**:
   - Testar reweighting
   - Testar threshold adjustment
   - Testar remo√ß√£o de proxy features

**M√©tricas de Valida√ß√£o**:
- ‚úÖ Tempo ‚â§ 15 min
- ‚úÖ DI Female: 0.40-0.46
- ‚úÖ "occupation" detectado como proxy

**Artefatos**:
- `results/adult_full_analysis.json`
- `results/adult_feature_importance.csv`
- `results/adult_mitigation_strategies.txt`

---

### 4.4 Experimento: Healthcare Risk Prediction

**Claims do Paper**:
- Tempo: 9.1 min (vs 40 min manual, 77% economia)
- An√°lise: Risco maior para Black/Hispanic (DI=1.41/1.27)
- Recomenda√ß√£o: Threshold adjustment N√ÉO recomendado (risco de dano)

**Metodologia**:

1. **Setup**:
   - Dataset: Sint√©tico baseado em MIMIC-III (10,000 amostras)
   - Modelo: Neural Network (3 layers)
   - Features: 25 (idade, ra√ßa, diagn√≥sticos)

2. **An√°lise √âtica**:
   ```python
   ftm = FairnessTestManager(dataset)
   ethical_review = ftm.analyze_ethical_implications(
       context='healthcare',
       sensitive_attribute='race'
   )

   # Verificar se threshold adjustment √© recomendado
   assert ethical_review['threshold_adjustment_recommended'] == False
   assert 'clinical_review' in ethical_review['recommendations']
   ```

**M√©tricas de Valida√ß√£o**:
- ‚úÖ Tempo ‚â§ 12 min
- ‚úÖ DI Black: 1.35-1.50
- ‚úÖ Warning sobre threshold adjustment presente

**Artefatos**:
- `results/healthcare_full_analysis.json`
- `results/healthcare_ethical_review.txt`

---

## 5. Estudo de Usabilidade

### 5.1 Experimento: System Usability Scale (SUS)

**Claim do Paper**:
- SUS Score: 85.2 ¬± 8.3
- Classifica√ß√£o: "Excelente" (top 15%)
- N=20 participantes

**Metodologia**:

1. **Recrutamento**:
   - 20 data scientists/ML engineers
   - Experi√™ncia: 2-8 anos em ML
   - 65% com experi√™ncia em fairness tools
   - Diversidade: 12 organiza√ß√µes (finan√ßas, sa√∫de, tech)

2. **Protocol**:
   - **Setup** (10 min): Instalar DeepBridge, carregar Adult dataset
   - **Task 1** (15 min): Detectar bias em modelo pr√©-treinado
   - **Task 2** (15 min): Verificar conformidade EEOC/ECOA
   - **Task 3** (20 min): Identificar threshold √≥timo

3. **Question√°rio SUS**:
   - 10 perguntas em escala Likert (1-5)
   - Normalizar para 0-100
   - Calcular m√©dia e desvio padr√£o

4. **Crit√©rios de Inclus√£o**:
   - Score individual ‚â• 68 (acima da m√©dia da ind√∫stria)
   - Score m√©dio ‚â• 80 (excelente)
   - Desvio padr√£o ‚â§ 15

**M√©tricas de Valida√ß√£o**:
- ‚úÖ SUS m√©dio ‚â• 80
- ‚úÖ SUS ‚â• 68 para ‚â• 90% dos participantes
- ‚úÖ Classifica√ß√£o "Excelente" (top 15%)

**Artefatos**:
- `results/sus_scores.csv` - Scores individuais
- `results/sus_analysis.txt` - An√°lise estat√≠stica
- `results/participant_demographics.csv` - Dados demogr√°ficos

---

### 5.2 Experimento: NASA Task Load Index (TLX)

**Claim do Paper**:
- NASA-TLX: 32.1 ¬± 12.4
- Benchmark: 50 (neutral)
- Interpreta√ß√£o: Baixa carga cognitiva

**Metodologia**:

1. **Question√°rio TLX** (aplicado ap√≥s cada tarefa):
   - Mental Demand (1-100)
   - Physical Demand (1-100)
   - Temporal Demand (1-100)
   - Performance (1-100)
   - Effort (1-100)
   - Frustration (1-100)

2. **An√°lise**:
   - M√©dia ponderada das 6 dimens√µes
   - Comparar com benchmark (50)

**M√©tricas de Valida√ß√£o**:
- ‚úÖ TLX m√©dio ‚â§ 40
- ‚úÖ Mental Demand ‚â§ 45
- ‚úÖ Frustration ‚â§ 35

**Artefatos**:
- `results/tlx_scores.csv`
- `results/tlx_by_task.csv`

---

### 5.3 Experimento: Task Success Rate

**Claim do Paper**:
- Overall: 95% (19/20)
- Task 1: 100% (20/20)
- Task 2: 95% (19/20)
- Task 3: 90% (18/20)

**Metodologia**:

1. **Crit√©rios de Sucesso**:
   - **Task 1**: Identificar corretamente ‚â•2 m√©tricas com violation
   - **Task 2**: Reportar corretamente status EEOC/ECOA
   - **Task 3**: Selecionar threshold com DI ‚â• 0.80 e Acc ‚â• 70%

2. **Observa√ß√£o**:
   - Screen recording de todas sess√µes
   - Notas de campo por observador

**M√©tricas de Valida√ß√£o**:
- ‚úÖ Task 1 success ‚â• 95%
- ‚úÖ Task 2 success ‚â• 90%
- ‚úÖ Task 3 success ‚â• 85%
- ‚úÖ Overall success ‚â• 90%

**Artefatos**:
- `results/task_success_rates.csv`
- `results/task_failures_analysis.txt`

---

### 5.4 Experimento: Time-to-Insight

**Claim do Paper**:
- DeepBridge: 10.2 ¬± 3.1 min
- Manual: 25-30 min

**Metodologia**:

1. **Medi√ß√£o**:
   - In√≠cio: Quando participante carrega dataset
   - Fim: Quando identifica primeira viola√ß√£o de fairness

2. **Compara√ß√£o com Baseline**:
   - Grupo controle (10 participantes) usa AI Fairness 360
   - Medir tempo at√© primeira detec√ß√£o

**M√©tricas de Valida√ß√£o**:
- ‚úÖ Time-to-insight DeepBridge ‚â§ 12 min
- ‚úÖ Speedup vs manual ‚â• 2.0x

**Artefatos**:
- `results/time_to_insight.csv`

---

### 5.5 Experimento: Entrevistas Qualitativas

**Claim do Paper**:
- Pontos fortes: Auto-detec√ß√£o, relat√≥rios EEOC, Pareto frontier, integra√ß√£o scikit-learn
- Pontos fracos: Pareto frontier n√£o intuitivo, falta de sugest√µes de mitiga√ß√£o

**Metodologia**:

1. **Protocol**:
   - Entrevista semi-estruturada (20 min)
   - Perguntas abertas:
     - "O que voc√™ mais gostou?"
     - "O que foi mais dif√≠cil?"
     - "O que melhoraria?"

2. **An√°lise**:
   - Thematic analysis (codifica√ß√£o de temas)
   - Frequ√™ncia de men√ß√µes

**M√©tricas de Valida√ß√£o**:
- ‚úÖ ‚â•70% mencionam auto-detec√ß√£o como ponto forte
- ‚úÖ ‚â•50% mencionam Pareto frontier como ponto forte
- ‚úÖ ‚â•30% mencionam necessidade de sugest√µes de mitiga√ß√£o

**Artefatos**:
- `results/interview_transcripts.txt`
- `results/thematic_analysis.csv`

---

## 6. Performance e Escalabilidade

### 6.1 Experimento: Speedup vs Manual Workflow

**Claim do Paper**:
- Small (1K): 5.5 min vs 24.7 min (4.5x)
- Medium (50K): 17.8 min vs 48.3 min (2.7x)
- Large (500K): 67.9 min vs 140.2 min (2.1x)
- Speedup m√©dio: 2.9x

**Metodologia**:

1. **Datasets**:
   - Small: German Credit (1K amostras, 20 features)
   - Medium: Adult Income (50K amostras, 50 features)
   - Large: Sint√©tico (500K amostras, 100 features)

2. **Workflow Manual** (baseline):
   - Identifica√ß√£o manual de atributos (5 min fixo)
   - Convers√£o para formato AIF360
   - An√°lise com AIF360
   - An√°lise custom (threshold, relat√≥rios)
   - Gera√ß√£o de relat√≥rio manual

3. **Workflow DeepBridge**:
   - Auto-detec√ß√£o
   - M√©tricas pr√©-treino
   - M√©tricas p√≥s-treino
   - Threshold optimization
   - Gera√ß√£o de relat√≥rios

4. **Execu√ß√£o**:
   - 5 repeti√ß√µes por dataset
   - Hardware: AWS m5.2xlarge (8 vCPUs, 32GB RAM)
   - Medir tempo total e por componente

**M√©tricas de Valida√ß√£o**:
- ‚úÖ Speedup small ‚â• 3.5x
- ‚úÖ Speedup medium ‚â• 2.5x
- ‚úÖ Speedup large ‚â• 2.0x
- ‚úÖ Speedup m√©dio ‚â• 2.5x

**Artefatos**:
- `results/performance_benchmarks.csv`
- `results/performance_by_component.csv`
- `results/performance_comparison.png`

---

### 6.2 Experimento: Memory Usage

**Claim do Paper**:
- 40-42% menos mem√≥ria que AIF360
- Small: 250 MB vs 420 MB
- Medium: 1.8 GB vs 3.2 GB
- Large: 12.5 GB vs 21.3 GB

**Metodologia**:

1. **Medi√ß√£o**:
   ```python
   import tracemalloc

   tracemalloc.start()

   # DeepBridge workflow
   dataset = DBDataset(data=df, target_column='target', model=model)
   ftm = FairnessTestManager(dataset)
   ftm.compute_all_metrics()

   current, peak = tracemalloc.get_traced_memory()
   tracemalloc.stop()

   print(f"Peak memory: {peak / 1024**2:.1f} MB")
   ```

2. **Compara√ß√£o**:
   - Mesmo workflow com AIF360
   - 5 repeti√ß√µes por dataset

**M√©tricas de Valida√ß√£o**:
- ‚úÖ Redu√ß√£o ‚â• 35% em todos tamanhos
- ‚úÖ Peak memory small ‚â§ 300 MB
- ‚úÖ Peak memory medium ‚â§ 2.0 GB
- ‚úÖ Peak memory large ‚â§ 15 GB

**Artefatos**:
- `results/memory_usage.csv`
- `results/memory_comparison.png`

---

### 6.3 Experimento: Escalabilidade

**Claims do Paper**:
- Algoritmo de threshold optimization: O(n log n)
- Lazy evaluation e caching inteligente

**Metodologia**:

1. **An√°lise de Complexidade**:
   - Datasets sint√©ticos: 1K, 10K, 100K, 500K, 1M amostras
   - Medir tempo de threshold optimization
   - Fit curva log-linear

2. **Teste de Lazy Loading**:
   - Medir tempo sem acesso a m√©tricas (deve ser ~0)
   - Medir tempo com acesso a 1 m√©trica
   - Verificar que m√©tricas n√£o usadas n√£o s√£o calculadas

**M√©tricas de Valida√ß√£o**:
- ‚úÖ R¬≤ ‚â• 0.95 para fit O(n log n)
- ‚úÖ Lazy loading economiza ‚â• 50% tempo quando <50% m√©tricas usadas

**Artefatos**:
- `results/scalability_analysis.csv`
- `results/complexity_curve.png`
- `results/lazy_loading_test.txt`

---

## 7. Otimiza√ß√£o de Threshold

### 7.1 Experimento: Pareto Frontier Identification

**Claim do Paper**:
- 100% dos participantes identificaram threshold √≥timo corretamente
- M√©dia 4.8/5 em utilidade de visualiza√ß√µes

**Metodologia**:

1. **Gera√ß√£o de Pareto Frontier**:
   ```python
   ftm = FairnessTestManager(dataset)
   pareto = ftm.analyze_threshold_pareto(
       thresholds=np.arange(0.1, 0.9, 0.05),
       fairness_metric='disparate_impact',
       performance_metric='accuracy'
   )

   # Identificar pontos Pareto-eficientes
   pareto_points = pareto[pareto['is_pareto_efficient']]
   ```

2. **Valida√ß√£o Matem√°tica**:
   - Verificar que pontos na frontier n√£o s√£o dominados
   - Verificar que pontos fora s√£o dominados

3. **Usabilidade**:
   - 20 participantes identificam threshold √≥timo dado constraint
   - Constraint: "Maximize fairness com accuracy ‚â• 70%"

**M√©tricas de Valida√ß√£o**:
- ‚úÖ Pareto frontier matematicamente correta
- ‚úÖ ‚â•95% participantes identificam threshold correto
- ‚úÖ Utilidade m√©dia ‚â• 4.5/5

**Artefatos**:
- `results/pareto_frontier_example.png`
- `results/pareto_validation.csv`
- `results/threshold_identification_accuracy.csv`

---

### 7.2 Experimento: Threshold Recommendations

**Claim do Paper**:
- COMPAS: threshold 0.62 reduz FPR difference de 22pp ‚Üí 8pp
- German Credit: threshold 0.45 balanceia DI=0.80 e Acc=72%
- Healthcare: threshold adjustment N√ÉO recomendado

**Metodologia**:

1. **Teste em Case Studies**:
   - Executar otimiza√ß√£o autom√°tica
   - Comparar threshold recomendado com claim
   - Validar m√©tricas no threshold recomendado

2. **Regras de Recomenda√ß√£o**:
   ```python
   # COMPAS: minimizar FPR difference mantendo Acc ‚â• 68%
   rec = ftm.recommend_threshold(
       objective='minimize',
       fairness_metric='fpr_difference',
       constraints={'accuracy': 0.68}
   )

   # Verificar: 0.60 ‚â§ rec['threshold'] ‚â§ 0.65
   ```

**M√©tricas de Valida√ß√£o**:
- ‚úÖ Threshold COMPAS: 0.60-0.65
- ‚úÖ Threshold German Credit: 0.42-0.48
- ‚úÖ Healthcare: recomenda√ß√£o contra threshold adjustment presente

**Artefatos**:
- `results/threshold_recommendations.csv`

---

## 8. Compara√ß√£o com Ferramentas Existentes

### 8.1 Experimento: Feature Comparison Matrix

**Claim do Paper**:
- DeepBridge √© √∫nica ferramenta com:
  - Auto-detec√ß√£o de atributos
  - Verifica√ß√£o EEOC/ECOA
  - Threshold optimization
  - Pareto frontier analysis
  - M√©tricas pr√©-treinamento

**Metodologia**:

1. **Ferramentas Testadas**:
   - AI Fairness 360 v0.2.9+
   - Fairlearn v0.10.0+
   - Aequitas v2.0.0+
   - DeepBridge Fairness

2. **Features Testados**:
   - Auto-detec√ß√£o (sim/n√£o)
   - N√∫mero de m√©tricas pr√©-treino
   - N√∫mero de m√©tricas p√≥s-treino
   - EEOC 80% rule (sim/n√£o)
   - ECOA compliance (sim/n√£o)
   - Threshold optimization (sim/n√£o)
   - Pareto frontier (sim/n√£o)
   - Relat√≥rios HTML/PDF (sim/n√£o)

3. **Valida√ß√£o**:
   - Testar cada feature em dataset Adult Income
   - Documentar presen√ßa/aus√™ncia de cada feature

**M√©tricas de Valida√ß√£o**:
- ‚úÖ DeepBridge tem todas features claimed
- ‚úÖ Outras ferramentas N√ÉO t√™m features exclusivas claimed

**Artefatos**:
- `results/tool_comparison_matrix.csv`
- `results/tool_comparison_report.md`

---

### 8.2 Experimento: Accuracy of Metrics

**Claim do Paper**:
- DeepBridge calcula m√©tricas corretamente (comparado com outras ferramentas)

**Metodologia**:

1. **M√©tricas Comuns** (presentes em m√∫ltiplas ferramentas):
   - Statistical Parity / Demographic Parity
   - Equal Opportunity
   - Disparate Impact

2. **Dataset de Teste**:
   - Adult Income (consenso na literatura)

3. **Compara√ß√£o**:
   ```python
   # AIF360
   from aif360.metrics import BinaryLabelDatasetMetric
   aif_di = BinaryLabelDatasetMetric(...).disparate_impact()

   # Fairlearn
   from fairlearn.metrics import demographic_parity_difference
   fl_dpd = demographic_parity_difference(y_true, y_pred, sensitive_features=sex)

   # DeepBridge
   ftm = FairnessTestManager(dataset)
   db_di = ftm.compute_metric('disparate_impact')

   # Comparar (toler√¢ncia < 0.01)
   assert abs(aif_di - db_di) < 0.01
   ```

**M√©tricas de Valida√ß√£o**:
- ‚úÖ Diferen√ßa < 1% para m√©tricas comuns
- ‚úÖ M√©tricas exclusivas validadas manualmente

**Artefatos**:
- `results/metric_accuracy_comparison.csv`

---

## 9. Experimentos Adicionais (Robustness)

### 9.1 Edge Cases e Stress Tests

**Objetivo**: Garantir que DeepBridge √© robusto em condi√ß√µes adversas

**Casos de Teste**:

1. **Dataset Pequeno** (n=50):
   - Verificar que m√©tricas calculam sem crash
   - Verificar warnings sobre signific√¢ncia estat√≠stica

2. **Dataset Desbalanceado Extremo** (99:1):
   - Verificar handling de divis√£o por zero
   - Verificar warnings sobre grupos minorit√°rios

3. **Missing Values** (30% de NaN):
   - Verificar imputation autom√°tica
   - Verificar documenta√ß√£o de missingness

4. **Multiclass Classification** (5 classes):
   - Verificar que m√©tricas bin√°rias s√£o estendidas corretamente
   - Verificar one-vs-rest ou one-vs-one

5. **Multi-Sensitive Attributes** (5 atributos sens√≠veis):
   - Verificar an√°lise combinada
   - Verificar relat√≥rios n√£o ficam polu√≠dos

**M√©tricas de Valida√ß√£o**:
- ‚úÖ 0 crashes em edge cases
- ‚úÖ Warnings apropriados exibidos
- ‚úÖ Resultados matematicamente corretos

**Artefatos**:
- `results/edge_cases_test.txt`
- `results/stress_test_results.csv`

---

## 10. Checklist de Valida√ß√£o Final

### 10.1 Claims Principais

| # | Claim | Experimento | Status |
|---|-------|-------------|--------|
| 1 | Auto-detec√ß√£o F1=0.90 | 1.1 | ‚¨ú |
| 2 | 100% acur√°cia em case studies | 1.2 | ‚¨ú |
| 3 | 15 m√©tricas (4 pr√© + 11 p√≥s) | 2.1 | ‚¨ú |
| 4 | 87% mais m√©tricas que AIF360 | 2.1, 8.1 | ‚¨ú |
| 5 | 100% precis√£o EEOC/ECOA | 3.1, 3.2 | ‚¨ú |
| 6 | SUS Score 85.2 | 5.1 | ‚¨ú |
| 7 | NASA-TLX 32.1 | 5.2 | ‚¨ú |
| 8 | 95% taxa de sucesso | 5.3 | ‚¨ú |
| 9 | Time-to-insight 10.2 min | 5.4 | ‚¨ú |
| 10 | Speedup 2.9x | 6.1 | ‚¨ú |
| 11 | 40-42% menos mem√≥ria | 6.2 | ‚¨ú |
| 12 | COMPAS 7.2 min (79% economia) | 4.1 | ‚¨ú |
| 13 | German Credit 5.8 min (77% economia) | 4.2 | ‚¨ú |
| 14 | Adult 12.4 min (75% economia) | 4.3 | ‚¨ú |
| 15 | Healthcare 9.1 min (77% economia) | 4.4 | ‚¨ú |

### 10.2 Artefatos de Publica√ß√£o

| Artefato | Descri√ß√£o | Localiza√ß√£o | Status |
|----------|-----------|-------------|--------|
| Dataset annotations | Ground truth de 500 datasets | `data/ground_truth.csv` | ‚¨ú |
| Case study results | Resultados completos dos 4 casos | `results/case_studies/` | ‚¨ú |
| Usability data | Dados brutos do estudo (N=20) | `results/usability/` | ‚¨ú |
| Performance benchmarks | Tempos e mem√≥ria | `results/performance/` | ‚¨ú |
| Comparison matrix | Compara√ß√£o com ferramentas | `results/comparison/` | ‚¨ú |
| Reproduction package | Scripts e instru√ß√µes | `reproduction/` | ‚¨ú |

---

## 11. Timeline de Execu√ß√£o

### Fase 1: Setup (Semana 1-2)
- [ ] Instalar todas ferramentas (DeepBridge, AIF360, Fairlearn, Aequitas)
- [ ] Coletar e preparar 500 datasets
- [ ] Preparar infraestrutura (AWS, tracking)
- [ ] Criar scripts de automa√ß√£o

### Fase 2: Auto-Detec√ß√£o (Semana 3-4)
- [ ] Executar Experimento 1.1 (500 datasets)
- [ ] Executar Experimento 1.2 (case studies)
- [ ] An√°lise de erros
- [ ] Gerar artefatos

### Fase 3: M√©tricas e Compliance (Semana 5-6)
- [ ] Executar Experimento 2.1 (15 m√©tricas)
- [ ] Executar Experimentos 3.1-3.3 (EEOC/ECOA)
- [ ] Valida√ß√£o manual
- [ ] Gerar artefatos

### Fase 4: Case Studies (Semana 7-9)
- [ ] Executar Experimentos 4.1-4.4
- [ ] Validar todas claims
- [ ] Gerar relat√≥rios completos
- [ ] Gerar artefatos

### Fase 5: Usabilidade (Semana 10-12)
- [ ] Recrutar 20 participantes
- [ ] Executar Experimentos 5.1-5.5
- [ ] Transcrever entrevistas
- [ ] An√°lise tem√°tica
- [ ] Gerar artefatos

### Fase 6: Performance (Semana 13-14)
- [ ] Executar Experimentos 6.1-6.3
- [ ] Executar Experimento 7.1-7.2
- [ ] An√°lise estat√≠stica
- [ ] Gerar artefatos

### Fase 7: Compara√ß√£o (Semana 15)
- [ ] Executar Experimentos 8.1-8.2
- [ ] Compara√ß√£o head-to-head
- [ ] Gerar artefatos

### Fase 8: Robustness (Semana 16)
- [ ] Executar Experimento 9.1
- [ ] Edge cases e stress tests
- [ ] Gerar artefatos

### Fase 9: Finaliza√ß√£o (Semana 17-18)
- [ ] Validar checklist completo
- [ ] Preparar reproduction package
- [ ] Escrever ap√™ndice t√©cnico
- [ ] Submeter para FAccT 2026

---

## 12. Crit√©rios de Sucesso para Publica√ß√£o

### M√≠nimos Aceit√°veis (Paper ser√° aceito se):

1. **Auto-Detec√ß√£o**:
   - F1-Score ‚â• 0.85 (claim: 0.90)
   - 100% acur√°cia em ‚â•3/4 case studies

2. **Usabilidade**:
   - SUS ‚â• 75 (claim: 85.2)
   - Taxa de sucesso ‚â• 85% (claim: 95%)

3. **Performance**:
   - Speedup ‚â• 2.0x (claim: 2.9x)
   - Economia de mem√≥ria ‚â• 30% (claim: 40-42%)

4. **Compliance**:
   - 100% precis√£o em EEOC/ECOA (cr√≠tico!)

### Targets Ideais (Fortalece o Paper):

1. Todos os claims validados dentro de ¬±10%
2. N=20 participantes em usabilidade
3. 500 datasets em auto-detec√ß√£o
4. Reproduction package completo
5. Compara√ß√£o head-to-head com 3 ferramentas

---

## 13. Conting√™ncias

### Se Auto-Detec√ß√£o < 0.85 F1:
- Reduzir threshold de similaridade
- Adicionar dicion√°rio de sin√¥nimos
- Implementar context filtering mais agressivo
- Worst case: Reduzir claim para 0.85 e explicar trade-off

### Se SUS < 75:
- Melhorar documenta√ß√£o
- Adicionar tutoriais interativos
- Simplificar API
- Worst case: Reposicionar como ferramenta para experts (n√£o iniciantes)

### Se Speedup < 2.0x:
- Otimizar threshold optimization (usar grid search mais esparso)
- Implementar paraleliza√ß√£o
- Worst case: Focar em qualidade vs. velocidade (features √∫nicas)

### Se Usabilidade N < 15:
- Incluir dados qualitativos (entrevistas)
- Fazer estudo piloto (N=10) + validation (N=5)
- Worst case: Reportar como estudo explorat√≥rio

---

## 14. √âtica e Compliance

### IRB (Institutional Review Board):
- [ ] Submeter protocolo de estudo de usabilidade
- [ ] Obter consentimento informado de participantes
- [ ] Garantir anonimiza√ß√£o de dados

### Licenciamento de Dados:
- [ ] Verificar licen√ßas de todos os 500 datasets
- [ ] Garantir permiss√£o para republica√ß√£o de resultados
- [ ] Citar corretamente autores originais

### Conflitos de Interesse:
- [ ] Declarar afilia√ß√µes com organiza√ß√µes que usam DeepBridge
- [ ] Declarar funding sources

---

## 15. Refer√™ncias de Valida√ß√£o

### Papers de Refer√™ncia (FAccT):
1. Bellamy et al. (2018) - AI Fairness 360 [cite para compara√ß√£o]
2. Bird et al. (2020) - Fairlearn [cite para compara√ß√£o]
3. Saleiro et al. (2018) - Aequitas [cite para compara√ß√£o]

### Metodologias de Avalia√ß√£o:
1. Brooke (1996) - System Usability Scale
2. Hart & Staveland (1988) - NASA Task Load Index
3. Lazar et al. (2017) - Research Methods in HCI

### Benchmarks de Fairness:
1. COMPAS Dataset - ProPublica
2. German Credit - UCI Repository
3. Adult Income - UCI Repository

---

## 16. Outputs Esperados

### Para o Paper:
- Tabelas de resultados (Se√ß√£o 5 - Evaluation)
- Figuras de compara√ß√£o (performance, usability)
- Ap√™ndice t√©cnico (metodologia detalhada)

### Para Reposit√≥rio:
- `experiments/` - Scripts de todos experimentos
- `results/` - Dados brutos e processados
- `reproduction/` - Instru√ß√µes de reprodu√ß√£o
- `data/` - Ground truth e datasets

### Para Apresenta√ß√£o:
- Slides resumindo principais resultados
- Demos ao vivo (caso aceito)
- Poster (para sess√£o de posters)

---

## 17. Contato e Suporte

**Respons√°vel pelos Experimentos**: [Adicionar nome]

**Prazo Final**: Submiss√£o FAccT 2026 - [Verificar deadline exato]

**Recursos**:
- Hardware: AWS m5.2xlarge
- Software: Python 3.8+, DeepBridge, AIF360, Fairlearn, Aequitas
- Or√ßamento: [Definir para AWS + participantes do estudo]

---

**IMPORTANTE**: Este plano √© exaustivo e cobre todas as claims do paper. Priorize os experimentos com ‚≠ê se tempo/recursos forem limitados:

‚≠ê Experimentos Cr√≠ticos (Essenciais):
- 1.1 (Auto-detec√ß√£o 500 datasets)
- 3.1 (EEOC 80% rule)
- 4.1-4.4 (Case studies completos)
- 5.1 (SUS Score)
- 6.1 (Speedup)
- 8.1 (Compara√ß√£o com ferramentas)

Os demais experimentos fortalecem o paper mas n√£o s√£o absolutamente cr√≠ticos para aceita√ß√£o.

**Boa sorte com os experimentos! üöÄ**
